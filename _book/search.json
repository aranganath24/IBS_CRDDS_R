[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A Crash Course in R for Social Scientists",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\ntesting\n1 2 3\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "session1.html",
    "href": "session1.html",
    "title": "2  R Foundations",
    "section": "",
    "text": "2.1 R and R Studio Installation\nIn this lesson, we’ll learn some important foundational concepts related to the R programming language. We will discuss R as a calculator, and object assignment, but will spend most of our time learning about three fundamental data structures that you will use all the time when working on applied social science research projects in R: vectors, data frames, and lists.\nIf you haven’t already, please go ahead and install both the R and RStudio applications. R and RStudio must be installed separately; you should install R first, and then RStudio. The R application is a bare-bones computing environment that supports statistical computing using the R programming language; RStudio is a visually appealing, feature-rich, and user-friendly interface that allows users to interact with this environment in an intuitive way. Once you have both applications installed, you don’t need to open up R and RStudio separately; you only need to open and interact with RStudio (which will run R in the background).\nPlease follow these instructions to download R and R Studio; make sure you download the version of R appropriate for your operating system.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R Foundations</span>"
    ]
  },
  {
    "objectID": "session1.html#the-r-studio-interface",
    "href": "session1.html#the-r-studio-interface",
    "title": "2  R Foundations",
    "section": "2.2 The R Studio Interface",
    "text": "2.2 The R Studio Interface\nNow that we’ve installed and opened up RStudio, let’s familiarize ourselves with the RStudio interface. When we open up RStudio, we’ll see a window that looks something like this:\nNow that we’ve installed and opened up RStudio, let’s familiarize ourselves with the RStudio interface. When we open up RStudio, we’ll see a window that looks something like this:\n\n\n\n\n\n\n\n\nFigure 2.1: The R Studio Interface\n\n\n\n\n\nIf your interface doesn’t look exactly like this, it shouldn’t be a problem; we would expect to see minor cosmetic differences in the appearance of the interface across operating systems and computers (based on how they’re configured). However, you should see four distinct windows within the larger RStudio interface:\n\nThe top-left window is known as the Source window.\n\nThe Source window is where we can write our R scripts (including the code associated with this tutorial), and execute those scripts. We can also type in R code into the “Console” window (bottom-left window), but it is preferable to write our code in a script within the source window. That’s because scripts can be saved (while code written into the console cannot); writing scripts therefore allows us to keep track of what we’re doing, and facilitates the reproducibility of our work. Note that in some cases, we may not see a Source window when we first open RStudio. In that case, to start a new script, simply click the File button on the RStudio menu bar, scroll down to New File button, and then select R Script from the menu bar that opens up.\nIt’s also worth noting that the outputs of certain functions will appear in the Source window. In the context of our tutorial, when we want to view our datasets, we will use the View() function, which will display the relevant data within a new tab in the Source window.\n\nThe top-right window is the Environment/History pane of the RStudio interface.\n\nThe “Environment” tab of this window provides information on the datasets we’ve loaded into RStudio, as well as objects we have defined (we’ll talk about objects more later in the tutorial). -The “History” tab of the window provides a record of the R commands we’ve run in a given session.\n\nThe bottom-right window is the Files/Plots/Packages/Help/Viewer window.\n\nThe “Files” tab displays our computer’s directories and file structures and allows us to navigate through them without having to leave the R environment.\nThe “Plots” tab is the tab where we can view any visualizations that we create. Within the “Plots” tab, make note of the “Zoom” button, which we can use to enlarge the display of our visualizations if they’re too compressed in the “Plots” window. Also, note the “Export” button within the “Plots” tab (next to the “Zoom” button); we can use this button to export the displayed visualization to a .png or .jpeg file that can be used outside of RStudio.\nThe “Packages” tab provides information on which packages have been installed, as well as which packages are currently loaded (more on packages in Sections 2.3 and 2.4 below)\nThe “Help” tab displays documentation for R packages and functions. If you want to know more about how a package or function work, we can simply type a “?” followed by the package or function’s name (no space between the question mark and the name) and relevant information will be displayed within the “Help” tab.\nThe “Viewer” tab displays HTML output. If we write code that generates an HTML file, we can view it within the “Viewer” tab.\n\nThe bottom-left window is the Console/Terminal/Jobs window.\n\nThe “Console” tab is where we can see our code execute when we run our scripts, as well as certain outputs produced by those scripts. In addition, if there are any error or warning messages, they will be printed to the “Console” tab. We can also type code directly into the console, but as we noted earlier, it is better practice to write our code in a script and then run it from there.\nThe “Terminal”, “Jobs” tabs are not relevant for our workshop. We’ll briefly provide an overview of “R Markdown” towards the end of the lesson.\n\n\nWe’re now ready to begin writing some basic code in R. Please go ahead and open up a new script, and follow along by typing the code as we go. To open up a new script, go to File, then click New File, then select R Script.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R Foundations</span>"
    ]
  },
  {
    "objectID": "session1.html#r-as-a-calculator",
    "href": "session1.html#r-as-a-calculator",
    "title": "2  R Foundations",
    "section": "2.3 R as a Calculator",
    "text": "2.3 R as a Calculator\nAt its most basic level, R can be used as a calculator. For instance:\n\n# calculates 2+2\n2+2\n\n[1] 4\n\n\nWhen you type this code out in your script, it should look something like this:\n\n\n\n\n\n\n\n\nFigure 2.2: Starting an R Studio Script\n\n\n\n\n\nTo run the code, you can highlight it and click the Run button (boxed in red). Alternatively, you can place the cursor on the line of code you’d like to run, and use a keyboard shortcut to run the code. On a Mac, the shortcut is clicking Command + Shift + Return. If you are using Windows, the keyboard shortcut to run the current line of code should be Ctrl + Enter.\nYou should go ahead and save the script in a convenient location by clicking File and then Save As. You should periodically save your work. After you close your R Session, you can always open your saved script, and quickly run the entire script to reproduce your work from prior sessions. To reproduce more than one line of code, or even an entire script, simply highlight the code yoou want to run and click the Run button in the R Studio interface. On a Mac, the shortcut for running all of the code in your script is Cmd + Option + R. On a Windows machine, the shortcut to run the entirety of a script is Ctrl + Shift + Enter.\nBefore proceeding, one final thing you should note is that the actual code, 2+2, was preceded by a “comment” that was in turn preceded by a #; above, the comment was rather trivial, since it’s fairly self evident what the code was doing. But pretty soon, our code will become more complex and challenging to interpret, and code comments will be an essential way of documenting our work. These comment are an essential way we can communicate with others who might read our code, as well as our future selves. The # sign is always used to introduce a comment, and ensures that any text that comes after it will indeed be interpreted as a comment, rather than as code.\nNow, let’s try some more mathematical operations:\n\n# calculates 65 to the power of 4\n65^4\n\n[1] 17850625\n\n\n\n# calculates the sum of 24 and 4, divided by 7\n(24+4)/7\n\n[1] 4\n\n\n\n# calculates 2.78 subtracted from 10.453\n10.453-2.78\n\n[1] 7.673\n\n\nWhile this is a useful and logical starting point, the possibility of assigning values to objects (or variables) considerably increases the scope of the operations we are able to carry out. We turn to object assignment in the next sub-section.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R Foundations</span>"
    ]
  },
  {
    "objectID": "session1.html#object-assignment-and-manipulation",
    "href": "session1.html#object-assignment-and-manipulation",
    "title": "2  R Foundations",
    "section": "2.4 Object Assignment and Manipulation",
    "text": "2.4 Object Assignment and Manipulation\nThe concept of object (or variable) assignment is a fundamental concept when working in a scripting environment; indeed, the ability to easily assign values to objects is what allows us to easily and intuitively manipulate and process our data in a programmatic setting. To better understand the mechanics of object assignment, consider the following:\n\n# assign value 5 to new object named x\nx &lt;- 5\n\nIn the code above, we use R’s assignment operator, &lt;- (i.e. a left-pointing arrow) to assign the value 5 to an object named x. Now that an object named x has been created and assigned the value 5, printing x in our console (or printing x in our script and running it) will return the value that has been assigned to the x object, i.e. 5:\n\n# prints value assigned to \"x\"\nx\n\n[1] 5\n\n\nMore generally, the process of assignment effectively equates the output created by the code on the right side of the assignment operator (&lt;-) to an object with a name that is specified on the left side of the assignment operator. Whenever we want to look at the contents assigned to an object (i.e. the output created by the code to the right side of the assignment operator), we simply print the name of the object in the R console (or print the name and run it within a script).\nLet’s create another object, named y, and assign it the value “12”:\n\n# assign value 12 to new object named y\ny &lt;- 12\n\nAs we noted above, we can print the value that was assigned to y by printing the name of the object:\n\n# prints value assigned to \"y\"\ny\n\n[1] 12\n\n\nOnce objects are defined, it’s possible to use those objects in arithmetic operations. For example:\n\n# prints the value of x + y\nx+y\n\n[1] 17\n\n\nIt’s also possible to use existing objects to assign values to new ones. For example, we can assign the sum of x and y to a new object that we’ll name xy_sum:\n\n# creates a new object, named \"xy_sum\" whose value is the sum of \"x\" and \"y\"\nxy_sum &lt;- x+y\n\nNow, let’s print the value of xy_sumthat was created by the previous assignment operation:\n\n# prints value of of \"xy_sum\"\nxy_sum\n\n[1] 17\n\n\nAs expected, we see that the value assigned to xy_sum is “17” (i.e. the sum of the values assigned to x and y).\nIt is possible to change the value assigned to a given object. For example, let’s say we want to change the value assigned to x from “5” to “8”:\n\n# assign value of \"8\" to object named \"x\"\nx &lt;- 8\n\nWe can confirm that x is now associated with the value “8”, and the old value has been overwritten:\n\n# prints updated value of \"x\"\nx\n\n[1] 8\n\n\nIt’s worth noting that updating the value assigned to x will not automatically update the value assigned to xy_sum (which, recall, is the sum of x and y). If we print the value assigned to xy_sum, note that it is still “17”):\n\n# print value assigned to xy_sum\nxy_sum\n\n[1] 17\n\n\nIn order for the value assigned to xy_sum to be updated with the new value of x, we must run the assignment operation again, with the updated value of x:\n\n# assigns sum of \"y\" and newly updated value of \"x\" to \"xy_sum\" object\nxy_sum &lt;- x+y\n\nNow, the value of xy_sum should reflect the updated value of x, which we can confirm by printing the value of xy_sum:\n\n# prints value of \"xy_sum\"\nxy_sum\n\n[1] 20\n\n\nNote that the value assigned to xy_sum is now “20” (the sum of “8” and “12”), rather than “17” (the sum of “5” and “12”).\nThus far, we’ve been working with numeric values, but it’s also possible to assign non-numeric contents to objects. For example, we can assign strings (i.e. lines of text) to objects. Below, consider the string “Boulder, CO” assigned to an object named our_location:\n\n# assigns string \"Boulder, CO\" to object named \"our_location\"\nour_location &lt;- \"Boulder, CO\"\n\nWe can print the string that has been assigned to the our_location object by typing the name of the object in our console, or running it from our script:\n\n# prints contents assigned to \"our_location\" object\nour_location\n\n[1] \"Boulder, CO\"\n\n\n\n2.4.1 Naming Objects\nWhile the examples above were very simple, we can assign virtually any R code, and by extension, the data structure(s) generated by that code (such as datasets, vectors, graphs/plots, functions etc.) to an R object. When naming your objects, try to be descriptive, so that the name of the object signifies something about the code or outputs assigned to it.\nNote that generally speaking, you have a lot of flexibility in naming your R objects, but there are certain rules. For example, object names must start with a letter, and cannot contain any special symbols (they can only contain letters, numbers, underscores, and periods). Also, object names cannot contain multiple unconnected words; if you’d like to use multiple words or phrases, connect the discrete elements with an underscore (_), or use camel case (where different words are distinguished by beginning each discrete word with a capitalized letter). In addition, there are certain words that are “reserved” for other purposes, and therefore cannot be used in object names (i.e. if, else, TRUE , FALSE, etc).\nIt is also worth emphasizing that object names are case sensitive; in order to print the contents assigned to an object, that object’s name must be printed exactly as it was created. For example, if we were to type our_Location, we would get an error, since there is no our_Location object (only an our_location object):\n\n# prints contents of \"our_Location\"\nour_Location\n\nError: object 'our_Location' not found\n\n\nIn order to keep track of the objects we have created, we can use the handy ls() function, which will print the names of all the objects that are in memory:\n\n# prints objects in memory\nls()\n\n[1] \"our_location\" \"x\"            \"xy_sum\"       \"y\"           \n\n\nTo delete an object from memory, you can pass it to the rm() function. For example, the following will delete the our_location object from memory:\n\n# deletes \"our_location\" object from memory\nrm(our_location)\n\nNow, we can confirm that the our_location object has indeed been deleted by running ls() once again:\n\n# prints objects in memory\nls()\n\n[1] \"x\"      \"xy_sum\" \"y\"",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R Foundations</span>"
    ]
  },
  {
    "objectID": "session1.html#data-structures",
    "href": "session1.html#data-structures",
    "title": "2  R Foundations",
    "section": "2.5 Data Structures",
    "text": "2.5 Data Structures\nWe now turn to a brief overview of some important data structures that help us to work with data in R. We will consider three data structures that are particularly useful: vectors, data frames, and lists. Note that this is not an exhaustive treatment of data structures in R; there are other structures, such as matrices and arrays, that are also important, and which you may encounter or use in your future work. However, for now, we will limit our discussion to vectors, data frames, and lists, since they are the data structures that are essential for getting started with data-based social scientific research in R, and the data structures that you will likely use most frequently.\n\n2.5.1 Vectors\nIn R, a vector is a sequence of values of the same type (i.e. we can have a sequence of numbers or a sequence of strings, but cannot mix and match types in a vector). A vector is created using the c() function. We’ll discuss functions at greater later, but for now you can think of a function as a programmed command that takes input(s), and returns output(s).\nFor example, let’s make a vector to store the temperatures (in Celsius) of some cities in Asia. The c() function takes as its input a series of numbers, and returns as its output a numeric vector with those numbers as elements:\n\n# makes vector with values 32, 18, 41, 11\nc(32, 18, 41, 11)\n\n[1] 32 18 41 11\n\n\nRecall that we can assign vectors to objects with descriptive names. Let’s create a new vector object named asia_temperatures_celsius to store these values:\n\n# assigns vector of temperatures from Asian cities to a new object named \"asia_temperatures_celsius\"\nasia_temperatures_celsius&lt;-c(32, 18, 41, 11)\n\nNow, whenever we want to print the vector assigned to the asia_temperatures_celsius object, we can simply print the name of the object:\n\n# prints contents of \"asia_temperatures_celsius\"\nasia_temperatures_celsius\n\n[1] 32 18 41 11\n\n\nThough we have focused so far on numeric vectors (i.e. vectors where the elements are numbers), it is also possible to create vectors where the elements are strings (i.e. text). For example, let’s create a vector that contains the names of cities that have a University of Colorado campus, and assign it to an object named university_of_colorado_locations\n\n# defines new vector assigned to object named \"university_of_colorado_locations\" that contains locations of CU campuses\nuniversity_of_colorado_locations&lt;-c(\"Boulder\", \"Denver\", \"Colorado Springs\")\n\nNow let’s print out its contents:\n\n# prints contents of \"university_of_colorado_locations\"\nuniversity_of_colorado_locations\n\n[1] \"Boulder\"          \"Denver\"           \"Colorado Springs\"\n\n\n\n2.5.1.1 Vector labels\nSometimes, it can be useful to add text labels to numeric vectors, which can provide important context that helps us to keep track of the information stored within a vector. Let’s return to the asia_temperatures_celsius vector we created above and imagine that the first element in the vector represents the temperature for Mumbai; the second element represents the temperature in Hanoi; the third represents the temperature in Singapore; and the fourth represents the temperature in Beijing. Let’s add these country labels to their corresponding temperature values in the asia_temperatures_celsiusvector. First, we’ll create a vector that contains these text labels and assign it to a new object named country_labels_vector:\n\n# creates country labels vector and assigns it to a new object names \"country_labels_vector\"\ncountry_labels_vector&lt;-c(\"Mumbai\", \"Hanoi\", \"Singapore\", \"Beijing\")\n\nNow, we’ll use the names() function to assign the labels in country_labels_vector to the temperature values in asia_temperatures_celsius. The first label in country_labels_vector will be assigned to the first temperature value in asia_temperatures_celsius, to indicate that that the temperature of 37 degrees Celsius is associated with Mumbai; the second label in country_labels_vector will be assigned to the second temperature value in asia_temperatures_celsius to indicate that the temperature value of 17 degrees Celsius is associated with Hanoi; and so on.\n\n# uses the \"names\" function to assign the labels in \"country_labels_vector\" to the \"asia_temperatures_celsius\" numeric vector\nnames(asia_temperatures_celsius)&lt;-country_labels_vector\n\nNow, let’s view the contents of asia_temperatures_celsius, and note that the numeric values are labelled with the text strings contained in country_labels_vector:\n\n# prints updated \"asia_temperatures_celsius\" vector with labels\nasia_temperatures_celsius\n\n   Mumbai     Hanoi Singapore   Beijing \n       32        18        41        11 \n\n\nIt is also possible to add labels to a vector during the process of creating that vector, rather than doing so subsequently; creating labels concurrently with the vector is known as “inline naming”. Below, we create a vector of temperatures in some major North American cities in Celsius using inline naming:\n\n# creates new vector of temperatures in Celsius of major North American cities with labels created using inline naming\nnorth_america_temperatures_celsius&lt;-c(\"New York City\"=25, \"Toronto\"=15, \"Mexico City\"=8.5, \"Vancouver\"=10, \"Boston\"=12.5)\n\nLet’s print the contents of the newly created north_america_temperatures_celsius vector:\n\n# prints contents of \"north_america_temperatures_celsius\"\nnorth_america_temperatures_celsius\n\nNew York City       Toronto   Mexico City     Vancouver        Boston \n         25.0          15.0           8.5          10.0          12.5 \n\n\n\n\n2.5.1.2 Indexing, Subsetting, and Modifying Vectors\nIn many cases, it is useful to subset a vector, and extract specific element(s) from it. Each element in a given vector is assigned an index number, starting with 1; that is, the first element in a vector is assigned an index value of 1, the second element of a vector is assigned an index value of 2, and so on. We can use these index values to extract our desired vector elements. In particular, we can specify the desired index within square brackets after printing the name of the vector object of interest. For example, let’s say we want to extract the 3rd element of the vector in asia_temperature_difference_celsius. We can do so with the following, which returns the temperature value for Singapore, the third element in asia_temperature_difference_celsius:\n\n# Extracts the third element from the \"asia_temperatures_celsius\" vector\nasia_temperatures_celsius[3]\n\nSingapore \n       41 \n\n\nSince asia_temperatures_celsius has been labelled, it’s also possible to extract vector elements based on their label. For example, instead of extracting Singapore’s temperature with its corresponding index value of three, we can do so with the city label enclosed in quotation marks:\n\n# Extracts the third element from the \"asia_temperatures_celsius\" vector using its label\nasia_temperatures_celsius[\"Singapore\"]\n\nSingapore \n       41 \n\n\nIn some cases, we may want to extract more than one vector element. We can conveniently extract a range of vector elements using their index values.For example, let’s say we want to extract a new vector comprised of the first, second, and third numeric elements in asia_temperatures_celsius; we can do so with the following:\n\n# Extracts elements 1 through 3 in the \"asia_temperatures_celsius\" and deposits these elements in a new vector\nasia_temperatures_celsius[1:3]\n\n   Mumbai     Hanoi Singapore \n       32        18        41 \n\n\nThus far, we have not assigned our subsetted vectors to new objects, but we can easily do so if we want to call those vectors again down the road. Below, for example, we assign the vectors we just subsetted in the last line of code that we ran to a new object named asia_temperatures_subsetted_1to3:\n\n# Extracts elements 1 through 3 in the \"asia_temperatures_celsius\" and deposits these elements in a new vector assigned to the object \"asia_temperatures_subsetted_1to3\"\nasia_temperatures_subsetted_1to3&lt;-asia_temperatures_celsius[1:3]\n\n# prints contents of \"asia_temperatures_subsetted_1to3\"\nasia_temperatures_subsetted_1to3\n\n   Mumbai     Hanoi Singapore \n       32        18        41 \n\n\nWe can also use negative index numbers to subset vectors; in particular, while passing a positive index number will extract the vector element that corresponds with that number and creates a new vector with that subsetted element, passing a negative index number will return a vector that deletes the element that corresponds to the the absolute value of the negative index number. For example, the following removes the temperature associated with Hanoi (the second element in asia_temperatures_celsius) and returns a new vector with the remaining temperatures:\n\n# removes second element in \"asia_temperatures_celsius\" vector and returns a vector with the remaining values\nasia_temperatures_celsius[-2]\n\n   Mumbai Singapore   Beijing \n       32        41        11 \n\n\nIt’s also possible to delete a range of elements in a vector using negative index numbers. Below, for example, we delete the second and third elements from asia_temperatures_celsius and return a vector with the remaining values:\n\n# removes second and third elements in \"asia_temperatures_celsius\" vector (i.e. the temperatures associated with Hanoi and Singapore) and returns a vector with the remaining temperature values\nasia_temperatures_celsius[-2:-3]\n\n Mumbai Beijing \n     32      11 \n\n\nSometimes, we may want to subset our vectors by referencing non-consecutive elements. For example, instead of extracting the first through third elements of the asia_temperatures_celsius vector, perhaps we only want to extract the first and third elements, without also extracting the second. Intuitively, we could try the following:\n\n# tries to extract the first and third elements from \"asia_temperatures_celsius\" and deposit them into a new vector\nasia_temperatures_celsius[1,3]\n\nError in asia_temperatures_celsius[1, 3]: incorrect number of dimensions\n\n\nHowever, as you can see, this syntax throws an error. Instead, if we want to extract non-continuous elements from a vector, we have to pass the index numbers into their own vector, and enclose this vector of index numbers in square brackets. For example, to extract only the first and third elements from asia_temperatures_celsius, we would do the following:\n\n# extracts the first and third elements from \"asia_temperatures_celsius\" and deposits them into a new vector\nasia_temperatures_celsius[c(1,3)]\n\n   Mumbai Singapore \n       32        41 \n\n\nThe same syntax can be used when removing multiple non-consecutive elements; for example, let’s say we want to remove the first and third elements from the asia_temperatures_celsius vector, and create a new subsetted vector with the remaining elements. We can do so with the following:\n\n# Removes the first and third elements from \"asia_temperatures_celsius\" and makes a new vector with the remaining elements\nasia_temperatures_celsius[c(-1,-3)]\n\n  Hanoi Beijing \n     18      11 \n\n\nWe can also use this basic syntax to subset multiple vector elements using labels, rather than index numbers. For example:\n\n# extracts temperature values for Mumbai and Singapore and deposits them in a new vector using labels\nasia_temperatures_celsius[c(\"Mumbai\", \"Singapore\")]\n\n   Mumbai Singapore \n       32        41 \n\n\nThough we now have a sense of how to subset vectors, there might be instances in which you want to add new elements to a vector. For example, let’s say that we want to add temperature data (and associated labels) for some other cities to asia_temperatures_celsius. Let’s say we want to add the temperature of Jakarta, which was 32 degrees Celsius, and Manila, which was 26.5 degrees Celsius. We can do so with the following syntax:\n\n# Adds temperatures for Jakarta and Manila to the \"asia_temperatures_celsius\" vector\nasia_temperatures_celsius&lt;-c(asia_temperatures_celsius, \"Jakarta\"=32, \"Manila\"=26.5)\n\nIn particular, we call the function to make vectors (c()); the first argument is the name of the vector object to which we’re adding elements, and the subsequent arguments are the numeric elements along with their labels. We can confirm that the new elements have been added by printing out the contents of the updated asia_temperatures_celsius vector:\n\n# prints contents of updated \"asia_temperatures_celsius\" vector\nasia_temperatures_celsius\n\n   Mumbai     Hanoi Singapore   Beijing   Jakarta    Manila \n     32.0      18.0      41.0      11.0      32.0      26.5 \n\n\nIn some cases, we may have two or more vectors that we want to combine into a single, unified vector. For example, let’s say we want to combine our vector of temperatures in Asian cities (asia_temperatures_celsius) with our vector of temperatures in North American cities (north_america_temperatures_celsius). We can do so by passing the name of these vector objects to the c() function; below, we’ll assign this combined vector to a new object named asia_north_america_temperatures_celsius:\n\n# combines \"asia_temperatures_celsius\" vector and \"north_america_temperatures_celsius\" into a new combined vector that's assigned to an object named \"asia_north_america_temperatures_celsius\"\nasia_north_america_temperatures_celsius&lt;-c(asia_temperatures_celsius, north_america_temperatures_celsius)\n\nLet’s print the contents of asia_north_america_temperatures_celsius to confirm that the vectors have been combined as expected:\n\n# prints contents of \"asia_north_america_temperatures_celsius\"\nasia_north_america_temperatures_celsius\n\n       Mumbai         Hanoi     Singapore       Beijing       Jakarta \n         32.0          18.0          41.0          11.0          32.0 \n       Manila New York City       Toronto   Mexico City     Vancouver \n         26.5          25.0          15.0           8.5          10.0 \n       Boston \n         12.5 \n\n\nThe basic principles and code we’ve used to subset and modify numeric vectors (i.e. vectors comprised of numeric elements) can be applied to subset and modify character vectors (i.e. vectors comprised of string/text elements). Recall the character vector of University of Colorado locations, university_of_colorado locations. We can use index numbers to extract elements from character vectors in much the same way we do for numeric vectors.\n\n# extracts the second element from \"university_of_colorado_locations\"\nuniversity_of_colorado_locations[2]\n\n[1] \"Denver\"\n\n\nWe can also subset a character vector using index numbers to extract a range of elements:\n\n# extracts the second and third elements from \"university_of_colorado_locations\"\nuniversity_of_colorado_locations[2:3]\n\n[1] \"Denver\"           \"Colorado Springs\"\n\n\nWe could get the same result using a negative index number to delete the first element:\n\n# extracts the second and third elements from \"university_of_colorado_locations\" using a negative index number to remove the first element\nuniversity_of_colorado_locations[-1]\n\n[1] \"Denver\"           \"Colorado Springs\"\n\n\nWe can also combine character vectors. For example, let’s say we have a vector that contains the locations of Colorado State University campuses:\n\n# creates character vector of CSU campus locations and assigns it to a new vector named \"colorado_state_university_locations\"\ncolorado_state_university_locations&lt;-c(\"Fort Collins\", \"Pueblo\")\n\nAnd we want to combine colorado_state_university_locations with university_of_colorado_locations to form a new character vector. We can do so with the following:\n\n# creates new character vector that combines elements from \"university_of_colorado_locations\" and \"colorado_state_university_locations\" and assigns it to a new object named \"co_public_university_locations\"\nco_public_university_locations&lt;-c(university_of_colorado_locations, colorado_state_university_locations)\n\n# prints contents of \"co_public_university_locations\"\nco_public_university_locations\n\n[1] \"Boulder\"          \"Denver\"           \"Colorado Springs\" \"Fort Collins\"    \n[5] \"Pueblo\"          \n\n\nIt’s also possible to add labels to character vectors, which can be a useful way of embedding metadata in our character vectors. For example, let’s say we want to add labels to co_public_university_locations indicating whether a location corresponds to a UC or CSU institution. We can do so with the names() unction, as we did with numeric vectors:\n\n# uses the \"names\" function to assign labels to the \"co_public_university_locations\" vector elements\nnames(co_public_university_locations)&lt;-c(\"UC\", \"UC\", \"UC\", \"CSU\", \"CSU\")\n\n# prints contents of \"co_public_university_locations\" updated with labels\nco_public_university_locations\n\n                UC                 UC                 UC                CSU \n         \"Boulder\"           \"Denver\" \"Colorado Springs\"     \"Fort Collins\" \n               CSU \n          \"Pueblo\" \n\n\nWe can use the same procedure we used with numeric vectors to create “inline” (i.e. concurrent) labels. To see this, let’s create a vector with the location of the flagship institutions of the University of Colorado and Colorado State systems, respectively, with labels designating which system the university associated with that location is a part of:\n\n# creates vector of flagship university locations, with labels designating if a location is associated with the UC or CSU flagship\nflagship_university_locations&lt;-c(UC=\"Boulder\", CSU=\"Fort Collins\")\n\n# prints contents of \"flagship_university_locations\"\nflagship_university_locations\n\n            UC            CSU \n     \"Boulder\" \"Fort Collins\" \n\n\nFinally, if we want to add new elements to an existing character vector, we can use the same syntax we used for numeric vectors. The Colorado State University system also includes a Global online university that we didn’t include in our vectors above. Let’s say we want to add CSU-Global to the colorado_state_university_locations vector. We can do so with the following:\n\n# Adds \"Global\" campus to \"colorado_state_university_locations\" vector\ncolorado_state_university_locations&lt;-c(colorado_state_university_locations, \"Global\")\n\n# prints updated contents of \"colorado_state_university_locations\" \ncolorado_state_university_locations\n\n[1] \"Fort Collins\" \"Pueblo\"       \"Global\"      \n\n\nLet’s say we also want to add the global location to co_public_university_locations with a corresponding label. We can do so with the following:\n\n# adds global location to \"co_public_university_locations\" along with CSU label\nco_public_university_locations&lt;-c(co_public_university_locations, CSU=\"Global\")\n\n# prints updated contents of \"co_public_university_locations\"\nco_public_university_locations\n\n                UC                 UC                 UC                CSU \n         \"Boulder\"           \"Denver\" \"Colorado Springs\"     \"Fort Collins\" \n               CSU                CSU \n          \"Pueblo\"           \"Global\" \n\n\n\n\n2.5.1.3 Vectorized Operations\nOnce a vector has been created, it’s possible to carry out operations on its elements; it’s important to briefly get an intuitive sense for how such vector operations work. There are different types of vector operations to be aware of. There are scalar operations, which involve arithmetic operations apply a constant value to every element of a numeric vector (i.e. adding ten to each vector element). It’s also possible to carry out arithmetic operations with more than one vector (i.e. adding two vectors together); such operations are typically known as vector operations. More generally, one of R’s benefits is that it allows us to use vectors to carry out iterative (repeated) operations without using programming constructs such as loops. For example, if you have some data and want to apply a formula or function to all of your data points, you could simply put those data points into a vector, and apply the formula or function to that vector, which will implement the desired operation on each element of the vector. Such operations, along with scalar and vector operations, are collectively referred to as “vectorized operations.”\nLet’s first consider scalar operations. Let’s go back to the asia_temperatures_celsius vector and remind ourselves of it its contents:\n\n# prints contents of \"asia_temperatures_celsius\"\nasia_temperatures_celsius\n\n   Mumbai     Hanoi Singapore   Beijing   Jakarta    Manila \n     32.0      18.0      41.0      11.0      32.0      26.5 \n\n\nLet’s say that something went wrong in the transcription of temperatures, and all of the temperatures in asia_temperatures_celsius are understated by two degrees. We can add two to each element in the asia_temperatures_celsius vector, and thereby fix the error, with the following scalar operation:\n\n# adds two to each element of \"asia_temperatures_celsius\" vector\nasia_temperatures_celsius+2\n\n   Mumbai     Hanoi Singapore   Beijing   Jakarta    Manila \n     34.0      20.0      43.0      13.0      34.0      28.5 \n\n\nOf course, the above operation did not permanently add two to all of the elements in asia_temperatures_celsius, since we did not overwrite the existing vector by assigning the changes back to the object. We can do so with the following:\n\n# adds two to each element of \"asia_temperatures_celsius\" vector and assigns the changes back to the object\nasia_temperatures_celsius&lt;-asia_temperatures_celsius+2\n\nWe can now confirm that each of the temperature values in asia_temperatures_celsius have been increased by two:\n\n# prints updated contents of \"asia_temperatures_celsius\"\nasia_temperatures_celsius\n\n   Mumbai     Hanoi Singapore   Beijing   Jakarta    Manila \n     34.0      20.0      43.0      13.0      34.0      28.5 \n\n\nLet’s now consider another vectorized operation that’s slightly more complex. Let’s say we want to convert the Celsius temperatures in asia_temperatures_celsius to Fahrenheit values, which are stored in a new asia_temperatures_fahrenheit vector object. We can do so by applying the Celsius to Fahrenheit conversion formula to asia_temperatures_celsius with the following:\n\n# applies the Celsius to Fahrenheit conversion formula to all of the Celsius temperatures in \"asia_temperatures_fahrenheit\" and assigns the resulting vector of Fahrenheit temperatures to a new object named \"asia_temperatures_fahrenheit\"\nasia_temperatures_fahrenheit&lt;-asia_temperatures_celsius*(9/5)+32\n\nThe conversion formula of Celsius*(9/5)+32 is applied to the first element of asia_temperatures_celsius and the result is deposited as the first element in asia_temperatures_fahrenheit; the formula is then applied to the second element of asia_temperatures_celsius and the result is deposited as the second element in asia_temperatures_fahrenheit ; and so on. Let’s take a look at the contents of asia_temperatures_fahrenheit:\n\n# prints contents of \"asia_temperatures_fahrenheit\"\nasia_temperatures_fahrenheit\n\n   Mumbai     Hanoi Singapore   Beijing   Jakarta    Manila \n     93.2      68.0     109.4      55.4      93.2      83.3 \n\n\nThough we have been focused thus far on applying changes to a single vector, it is often the case that we may have information stored in multiple numeric vectors, and want to carry out mathematical operations that involves those vectors. For example, recall our vector of temperatures in North America:\n\n# prints contents of \"north_america_temperatures_celsius\"\nnorth_america_temperatures_celsius\n\nNew York City       Toronto   Mexico City     Vancouver        Boston \n         25.0          15.0           8.5          10.0          12.5 \n\n\nLet’s say we have another vector of North American temperatures for those same cities from a subsequent time period. Below, we’ll create this vector, and assign it to a new object named north_america_temperatures_celsius_B:\n\n# creates vector of temperatures in Celsius for the same North American cities as in the \"north_america_temperatures_celsius\" vector for a subsequent time period, and assigns the vector to a new object named \"north_america_temperatures_celsius_B\"\nnorth_america_temperatures_celsius_B&lt;-c(\"New York City\"=27, \"Toronto\"=11, \"Mexico City\"=8.5, \"Vancouver\"=10.5, \"Boston\"=17)\n\nNow, let’s say we want to compute the difference in temperatures across these time frames, and deposit the calculated temperature differences in a new vector. We do so below, assigning the vector of temperature differences to a new object named north_america_temperature_difference:\n\n# Computes the difference between \"north_america_temperatures_celsius_B\" and \"north_america_temperatures_celsius\" and assigns the difference to a new object named \"north_america_temperature_difference\"\nnorth_america_temperature_difference&lt;-north_america_temperatures_celsius_B-north_america_temperatures_celsius\n\nThe code above takes the first element in north_america_temperatures_celsius, subtracts it from the first element in north_america_temperatures_celsius_B, and deposits the difference as the first element in the new north_america_temperature_difference vector; it then takes the second element in north_america_temperatures_celsius, subtracts it from the second element in north_america_temperatures_celsius_B, and deposits the difference as the second element in the new north_america_temperature_difference vector; and so on for the other elements. In short, the corresponding elements of the two vectors are related through the mathematical operation of subtraction; this concept, wherein operations with multiple vectors are applied to the corresponding elements of those vectors, is often referred to as “element-wise operations”.\nGiven this framework of element-wise operations, it’s important to note what happens when carrying out operations with vectors of unequal length. Let’s create some toy vectors of unequal length and add them together:\n\n# creates two new vectors, \"a\" and \"b\" of unequal length\na&lt;-c(3,5,7)\nb&lt;-c(6,12,3,5)\n\na + b\n\nWarning in a + b: longer object length is not a multiple of shorter object\nlength\n\n\n[1]  9 17 10  8\n\n\nThe first three element-wise operations are straightforward: 3+6=9, 5+12=17, and 7+3=10. However, a does not have a fourth element, but b does; how is this handled? In short, the shorter vector is “recycled” (i.e. repeated) to match the length of the longer one. In this case, once we hit the end of a the recycling process goes back to the beginning, takes the element “3”, and uses it as the fourth element in the vector, which can be added to the fourth element of b to yield “8” as the fourth element in the resultant a+b vector. Let’s now slightly tweak this scenario by adding another element, “6”, to vector b :\n\na&lt;-c(3,5,7)\nb&lt;-c(6,12,3,5,6)\n\nWhat do you think happens when we carry out a+b? In particular, what do you think are the fourth and fifth elements of a+b? The principle of vector recycling suggests that the fourth element will be 8 (3+5), while the fifth element will be 11 (5+6):\n\na+b\n\nWarning in a + b: longer object length is not a multiple of shorter object\nlength\n\n\n[1]  9 17 10  8 11\n\n\nBeing aware of this property of vectors in R can be helpful in troubleshooting errors or unexpected behavior once you’re working with real-world data in R.\nIt is also possible to carry out vectorized operations on character vectors that are somewhat analogous to the mathematical operations carried out on numeric vectors. To illustrate one useful example that draws on the paste0() function, let’s first create two character vectors:\n\n# creates vector of university names\nuniversity_names&lt;-c(\"University of Colorado, \", \"Colorado State University, \")\n\n# creates vector of locations\nlocations&lt;-c(\"Boulder\", \"Fort Collins\")\n\nNow, we’ll use the paste() function to carry out an element-wise concatenation of the strings in these two vectors; we’ll assign the resulting vector of concatenated strings to a new object named university_name_location:\n\n# uses paste0 function to paste the strings in \"university_names\" and \"locations\" together in element-wise fashion and assign the resulting character vector to \"university_name_location\"\nuniversity_name_location&lt;-paste0(university_names, locations)\n\nLet’s go ahead and print the contents of university_name_location:\n\n# prints contents of \"university_name_location\"\nuniversity_name_location\n\n[1] \"University of Colorado, Boulder\"        \n[2] \"Colorado State University, Fort Collins\"\n\n\nVectorized operations with the paste0() can be very useful in creating names for objects and file names when working in applied settings.\n\n\n\n2.5.2 Data Frames\nThe data frame structure is the workhorse of data analysis in R. A data frame resembles a table, of the sort you might generate in a spreadsheet application.\nOften, the most important (and arduous) step in a data analysis workflow is to assemble disparate strands of data into a tractable data frame. What does it mean for a data frame to be “tractable”? One way to define this concept more precisely is to appeal to the concept of “tidy” data, which is often referenced in the data science world. Broadly speaking, a “tidy” data frame is a table in which:\n\nEach variable has its own column\nEach observation has its own row\nEach value has its own cell\n\nWe will work extensively with data frames later in the workshop, but let’s generate a toy data frame from scratch, and assign it to a new object. We will generate a data frame containing made up country-level data on basic economic, geographic, and demographic variables, and assign it to a new object named country_df. The data frame is created through the use of the data.frame() function, which has already been programmed into R. Column names and the corresponding column values are passed to the data.frame() function in the manner below, and the function effectively binds these different columns together into a table:\n\n# Creates a toy country-level data frame \ncountry_df&lt;-data.frame(Country=c(\"Country A\", \"Country B\", \"Country C\"),\n                       GDP=c(8000, 30000, 23500),\n                       Population=c(2000, 5400, 10000),\n                       Continent=c(\"South America\", \"Europe\", \"North America\"))\n\nTo observe the structure of the table, we can print it to the R console by simply printing the name of the object to which it has been assigned:\n\n# prints \"country_df\" data frame to console\ncountry_df\n\n    Country   GDP Population     Continent\n1 Country A  8000       2000 South America\n2 Country B 30000       5400        Europe\n3 Country C 23500      10000 North America\n\n\nOne nice feature of R Studio is that instead of simply printing our data frames into the console, we can view a nicely formatted version of our data frame by passing the name of the data frame object through the View() function. For example, the code below will bring up the country_df data frame as a new tab in R Studio:\n\n# pulls up \"country_df\" data frame in R Studio data viewer\nView(country_df)\n\n\n\n\n\n\n\nNote the “tidy” features of this simple data frame:\n\nEach of the variables (i.e. GDP, Population, Continent) has its own column\nEach of the (country-level) observations has its own row\nEach of the values (i.e. country-level information about a given variable) has its own distinct cell\n\nLet’s now turn to a brief exploration of how to extract rows and columns from a data frame, using principles of indexing similar to what we learned in the context of working with vectors. Since data frames are the workhorse of social scientific research in R, we’ll spend considerably more time on data frames in future lessons; for now, we just want to get acquainted with some basic base R syntax that allows us to get started.\nUnlike vectors, data frames are two dimensional; that is, they have both rows and columns. Both rows and columns are assigned index numbers; the convention is to refer to the index number of rows first, followed by the index number for columns. We can reference index numbers within square brackets to extract rows, columns, or observations from a data frame.\nLet’s say, for example, that we want to extract the entire first row from country_df. We can do so with the following:\n\n# extracts entire first row from \"country_df\"\ncountry_df[1, ]\n\n    Country  GDP Population     Continent\n1 Country A 8000       2000 South America\n\n\nThe number “1” indicates that we want to extract the first row; we leave the second argument after the comma blank, to indicate that we want all of the columns associated with that row. If we want the entire second row, we can do the following:\n\n# extracts entire second row from \"country_df\"\ncountry_df[2, ]\n\n    Country   GDP Population Continent\n2 Country B 30000       5400    Europe\n\n\nIf, instead, we want to extract a particular column, we indicate the index number of the desired column as the second argument in square brackets. Assuming we want all the rows associated with that column, we leave the row index blank. For example, we can extract the entire third column with the following:\n\n# extracts entire third column from \"country_df\"\ncountry_df[, 3]\n\n[1]  2000  5400 10000\n\n\nThus far, we haven’t been assigning these subsetted elements of the country_df data frame object to their own objects, but we can easily do so if we want to have them handy for future use. For example:\n\n# extracts entire third column from \"country_df\" and assigns it to an object named country_df_column\ncountry_df_column&lt;-country_df[, 3]\n\n# prints contents of \"country_df_column\"\ncountry_df_column\n\n[1]  2000  5400 10000\n\n\n\n# extracts entire third row from \"country_df\" and assigns it to an object named country_df_row\ncountry_df_row&lt;-country_df[3, ]\n\n# prints contents of \"country_df_row\"\ncountry_df_row\n\n    Country   GDP Population     Continent\n3 Country C 23500      10000 North America\n\n\nWe can also extract more than one row or column. For example, let’s say we want to extract the entirety of the second and third rows. We can do so with the following:\n\n# extracts second and third rows from \"country_df\"\ncountry_df[2:3, ]\n\n    Country   GDP Population     Continent\n2 Country B 30000       5400        Europe\n3 Country C 23500      10000 North America\n\n\nIf, instead, we want to grab the second and third columns, we can run the following:\n\n# extracts second and third columns from \"country_df\"\ncountry_df[, 2:3]\n\n    GDP Population\n1  8000       2000\n2 30000       5400\n3 23500      10000\n\n\nAs you would expect, we can simultaneously select particular rows and columns. For example, let’s say we want to grab the second through third rows, and the first through third columns:\n\n# extracts second through third rows, and first through third columns from \"country_df\"\ncountry_df[2:3, 1:3]\n\n    Country   GDP Population\n2 Country B 30000       5400\n3 Country C 23500      10000\n\n\nAlternatively, let’s say we want to grab the first through second columns from the third row:\n\n# extracts the third row, and first and second columns, from \"country_df\"\ncountry_df[3, 1:2]\n\n    Country   GDP\n3 Country C 23500\n\n\nIf we want to extract non-consecutive rows or columns, we must pass the desired index numbers as a vector. For example, let’s say we want rows 1 and 3, but not row 2:\n\n# extracts first and third rows from \"country_df\", while excluding second row\ncountry_df[c(1,3), ]\n\n    Country   GDP Population     Continent\n1 Country A  8000       2000 South America\n3 Country C 23500      10000 North America\n\n\nLet’s say we want the first, second, and fourth columns:\n\n# extracts first, second, and fourth columns from \"country_df\"\ncountry_df[, c(1,2,4)]\n\n    Country   GDP     Continent\n1 Country A  8000 South America\n2 Country B 30000        Europe\n3 Country C 23500 North America\n\n\nOr, the first and third rows for the first, second and fourth columns:\n\n# extracts the first and third rows, and second and fourth columns, from \"country_df\" and assigns it to a new object named \"dataset_selection\"\ndataset_selection&lt;-country_df[c(1,3), c(1,2,4)]\n\n# prints contents of \"dataset_selection\"\ndataset_selection\n\n    Country   GDP     Continent\n1 Country A  8000 South America\n3 Country C 23500 North America\n\n\nBefore proceeding, it’s worth noting a convenient way to extract columns from a data frame, which we will often encounter when working with R. In particular, we can extract a column from a data frame by typing the name of the data frame object, followed by the dollar sign ($), followed by the name of the column we want to extract. For example, let’s say we want to extract the “Continent” column from country_df:\n\n# extracts \"Continent\" column from \"country_df\"\ncountry_df$Continent\n\n[1] \"South America\" \"Europe\"        \"North America\"\n\n\nLet’s take another example; we’ll extract the “GDP” column, and assign it to a new object named country_df_gdp:\n\n# extracts \"GDP\" column from \"country_df\" and assigns it to a new object named \"country_df_gdp\"\ncountry_df_gdp&lt;-country_df$GDP\n\nThe columns that comprise data frames are vectors, so when we extract a column, the resulting object is a vector. We will confirm this below, when we discuss the concept of data classes, which are closely related to data structures.\n\n\n2.5.3 Lists\nIn R, a list is a data structure that allows us to conveniently store a variety of different objects, of various types. For example, we can use a list to vectors, data frames, visualizations and graphs–basically any R object you can think of! It is also possible to store a list within a list.\nLists allow us to keep track of the various objects we create, and are therefore a useful data management tool. In addition, lists are very helpful to use when we want to perform iterative operations across multiple objects.\nWe can create lists in R using the list() function; the arguments to this function are the objects that we want to include in the list. In the code below, we’ll create a list (assigned to an object named example_list) using the list() function. It contains some of the objects we create earlier in the lesson: the numeric asia_temperatures_fahrenheit vector, the university_name_locationcharacter vector, the country_df data frame, and the selection from country_df, dataset_selection, which is also a data frame.\n\n# creates list whose elements are the \"arbitrary_values\" numeric vector, the \"months_four\" character vector, and the \"country_df\" data frame, and assigns it to a new object named \"example_list\"\nexample_list&lt;-list(asia_temperatures_fahrenheit, university_name_location, country_df, dataset_selection)\n\nNow that we’ve created our list object, let’s print out its contents:\n\n# prints contents of \"example_list\"\nexample_list\n\n[[1]]\n   Mumbai     Hanoi Singapore   Beijing   Jakarta    Manila \n     93.2      68.0     109.4      55.4      93.2      83.3 \n\n[[2]]\n[1] \"University of Colorado, Boulder\"        \n[2] \"Colorado State University, Fort Collins\"\n\n[[3]]\n    Country   GDP Population     Continent\n1 Country A  8000       2000 South America\n2 Country B 30000       5400        Europe\n3 Country C 23500      10000 North America\n\n[[4]]\n    Country   GDP     Continent\n1 Country A  8000 South America\n3 Country C 23500 North America\n\n\nAs you can see, our list contains each of the various specified objects within a single, unified structure. We can access specific elements within a list using the specific index number of the desired element, in much the same way we did for vectors. When extracting a single list element from a list, the convention is to enclose the index number of the desired list element in double square brackets. For example, if we want to extract the country-level data frame from example_list, we can use the following:\n\n# extracts third element from \"example_list\"\nexample_list[[3]]\n\n    Country   GDP Population     Continent\n1 Country A  8000       2000 South America\n2 Country B 30000       5400        Europe\n3 Country C 23500      10000 North America\n\n\nIf we want to subset a list, and extract more than one list element as a separate list, we can do so by creating a vector of the index values of the desired elements, and enclosing it in single brackets after the name of the list object. For example, if we wanted to generate a new list that contained only the first and third elements of example_list (the numeric vector of arbitrary values and the data frame), we would use the following syntax:\n\n# extracts first and third elements from \"example_list\"\nexample_list[c(1,3)]\n\n[[1]]\n   Mumbai     Hanoi Singapore   Beijing   Jakarta    Manila \n     93.2      68.0     109.4      55.4      93.2      83.3 \n\n[[2]]\n    Country   GDP Population     Continent\n1 Country A  8000       2000 South America\n2 Country B 30000       5400        Europe\n3 Country C 23500      10000 North America\n\n\nWhile list elements are not automatically named, we can name our list element using the names()function. The first step is to define a character vector of desired names. We can specify any names we’d like but for the sake of illustration, let’s say we want to name the first list element “element1”, the second list element “element2”, and the third list element “element3”. Let’s create a vector of our desired names, and assign it to an object named name_vector:\n\n# creates a character vector of desired names for list elements, and assigns it to a new object named \"name_vector\"\nname_vector_list&lt;-c(\"element1\", \"element2\", \"element3\", \"element4\")\n\nNow, we’ll assign these names in name_vector to the list elements in example_list with the following:\n\n# assigns names from \"name_vector\" to list elements in \"example_list\"\nnames(example_list)&lt;-name_vector_list\n\nLet’s now print the contents of example_list:\n\n# prints contents of \"example_list\"\nexample_list\n\n$element1\n   Mumbai     Hanoi Singapore   Beijing   Jakarta    Manila \n     93.2      68.0     109.4      55.4      93.2      83.3 \n\n$element2\n[1] \"University of Colorado, Boulder\"        \n[2] \"Colorado State University, Fort Collins\"\n\n$element3\n    Country   GDP Population     Continent\n1 Country A  8000       2000 South America\n2 Country B 30000       5400        Europe\n3 Country C 23500      10000 North America\n\n$element4\n    Country   GDP     Continent\n1 Country A  8000 South America\n3 Country C 23500 North America\n\n\nNote that the list elements now have names attached to them; the first character string in name_vectoris assigned as the name of the first element in example_list, the second character string in name_vector is assigned as the name of the second element in example_list, and so on.\nPractically speaking, we can now extract list elements using the assigned names. For example, if we want to extract the data frame from example_list, we could do so by its assigned name (“element3”), as follows:\n\n# Extracts the data frame from \"example_list\" by its assigned name\nexample_list[[\"element3\"]]\n\n    Country   GDP Population     Continent\n1 Country A  8000       2000 South America\n2 Country B 30000       5400        Europe\n3 Country C 23500      10000 North America\n\n\nNote that even after assigning names to list elements, you can still extract elements by their index value, if you would prefer to do so:\n\n# Extracts the \"element3\" data frame from \"example_list\" by its index number\nexample_list[[3]]\n\n    Country   GDP Population     Continent\n1 Country A  8000       2000 South America\n2 Country B 30000       5400        Europe\n3 Country C 23500      10000 North America\n\n\nWe can also create lists with inline naming (analogous to the inline naming of vector elements) instead of assigning names with the names() function after the fact. Below, we’ll name the list elements after their objects, with “le” (for “list element” appended to the name):\n\n# create a list with inline naming\nexample_list_alt&lt;-list(asia_temperatures_fahrenheit_le=asia_temperatures_fahrenheit, \n                       university_name_location_le=university_name_location, \n                       country_df_le=country_df, \n                       dataset_selection_le=dataset_selection)\n\nLet’s print the contents of example_list_alt:\n\n# prints contents of \"example_list_alt\"\nexample_list_alt\n\n$asia_temperatures_fahrenheit_le\n   Mumbai     Hanoi Singapore   Beijing   Jakarta    Manila \n     93.2      68.0     109.4      55.4      93.2      83.3 \n\n$university_name_location_le\n[1] \"University of Colorado, Boulder\"        \n[2] \"Colorado State University, Fort Collins\"\n\n$country_df_le\n    Country   GDP Population     Continent\n1 Country A  8000       2000 South America\n2 Country B 30000       5400        Europe\n3 Country C 23500      10000 North America\n\n$dataset_selection_le\n    Country   GDP     Continent\n1 Country A  8000 South America\n3 Country C 23500 North America\n\n\nAnd confirm that we can extract elements with their assigned names:\n\n# extracts \"university_name_location\" vector from \"example_list_alt\" using its assigned name \nexample_list_alt[[\"university_name_location_le\"]]\n\n[1] \"University of Colorado, Boulder\"        \n[2] \"Colorado State University, Fort Collins\"\n\n\nIt’s also possible to make a list within a list (i.e. a “nested list”) which can sometimes come in handy for more complicated data workflows. However, we won’t use nested lists in our workshop series, so we will not cover that topic here.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R Foundations</span>"
    ]
  },
  {
    "objectID": "session1.html#data-classes",
    "href": "session1.html#data-classes",
    "title": "2  R Foundations",
    "section": "2.6 Data Classes",
    "text": "2.6 Data Classes\nWe’re done with our tour of three fundamental data structures in R, which we will repeatedly use in our work as applied social scientists: vectors, data frames, and lists. Data structures are essentially containers for storing and organizing data in well-defined and organized ways, and R functions interact with object differently based on their underlying structure. An object’s “class” provides additional information about how it behaves. The class of an object generally corresponds to the object’s data structure (for example, the “data.frame” class is often associated with the data frame data structure), but the class of an object can also extend functionality, and customize how an object interacts with R. For example, “tibbles” are a type of enhanced data frame that are used in the tidyverse, and tibbles have the class “tbl_df”\nWe can retrieve the class of an object (i.e. extract information about whether an object behaves as a data frame, vector, list, or some other structure) by passing the name of the object as an argument to the class() function. For example, let’s say we want to confirm the class of example_list:\n\n# prints class of \"example_list\"\nclass(example_list)\n\n[1] \"list\"\n\n\nAs expected, example_list belongs to the class “list”.\nLet’s consider another:\n\n# prints class of \"asia_temperatures_fahrenheit\"\nclass(asia_temperatures_fahrenheit)\n\n[1] \"numeric\"\n\n\nAs expected, given how we created it, asia_temperatures_fahrenheit is of the class “numeric”, i.e. a numeric vector.\nLet’s retrieve the class of country_df:\n\n# prints class of \"country_df\"\nclass(country_df)\n\n[1] \"data.frame\"\n\n\nRecall that we extracted the “GDP” column from country_df and assigned it to an object named country_df_gdp. Recall that the columns of data frames are vectors, which means that we would expect country_df_gdp to be of the class “numeric”:\n\n# prints class of \"country_df_gdp\"\nclass(country_df_gdp)\n\n[1] \"numeric\"\n\n\nWhile data frame columns are vectors, rows are treated as data frames, which we can confirm by checking the class of country_df_row (i.e. the third row of country_df):\n\n# prints class of \"country_df_row\"\nclass(country_df_row)\n\n[1] \"data.frame\"\n\n\nSometimes, we will need to transform objects into a different class than the one they are currently assigned. For example, let’s say that a function we’d like to use can take a data frame input, but doesn’t accept vector inputs. In that case, if our data is stored as a numeric vector, we must convert the object to a data frame before passing it to the desired function. Let’s say the numeric vector data we want to convert to a data frame is asia_temperatures_fahrenheit. We can do so by passing it to the as.data.frame() function which converts objects of different classes to the “data.frame” class. We’ll assign the data frame version of asia_temperatures_fahrenheit to a new object named asia_temperatures_df and print its contents:\n\n# converts \"asia_temperatures_fahrenheit\" to data frame class and assigns the data frame to a new object named \"asia_temperatures_df\"\nasia_temperatures_df&lt;-as.data.frame(asia_temperatures_fahrenheit)\n\n# prints contents of \"asia_temperatures_df\"\nasia_temperatures_df\n\n          asia_temperatures_fahrenheit\nMumbai                            93.2\nHanoi                             68.0\nSingapore                        109.4\nBeijing                           55.4\nJakarta                           93.2\nManila                            83.3\n\n\nWe can confirm the new class of asia_temperatures_df with the following:\n\n# prints class of \"asia_temperatures_df\"\nclass(asia_temperatures_df)\n\n[1] \"data.frame\"\n\n\nWe could carry out the inverse operation (i.e. transforming an object of the “data.frame” class to an object of class “numeric”) by passing the data frame object to the as.numeric() function. There are several functions that allow for class transformations such as this. Classes may feel confusing now, but they will become more intuitive as you work in R. They are important to be aware of, especially in the context of trouble shooting and debugging, since functions often don’t work as expected when they expect arguments of one class but receive another.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R Foundations</span>"
    ]
  },
  {
    "objectID": "session1.html#end-of-lesson-exercises",
    "href": "session1.html#end-of-lesson-exercises",
    "title": "2  R Foundations",
    "section": "2.7 End-of-Lesson Exercises",
    "text": "2.7 End-of-Lesson Exercises\nExercise 1\nConsider the following vector of Fahrenheit temperature values:\n\n# creates vector of Fahrenheit temperature values in Colorado\nfahrenheit_colorado &lt;- c(33, 15, 22, 44)\n\nThe first temperature is associated with Boulder; the second with Fort Collins; the third with Denver; and the fourth with Colorado Springs. Assign cities as labels to the temperature values with which they’re associated, and update fahrenheit_colorado with these changes.\n\n\nSuggested Solution to Exercise 1\n\n\n# assigns names to \"fahrenheit_colorado\" using the \"names\" function and a vector of names\nnames(fahrenheit_colorado) &lt;- c(\"Boulder\", \"Fort Collins\", \"Denver\", \"Colorado Springs\")\n\n# prints labeled \"fahrenheit_colorado\" vector\nfahrenheit_colorado\n\n         Boulder     Fort Collins           Denver Colorado Springs \n              33               15               22               44 \n\n\n\nExercise 2\nApply a transformation to fahrenheit_colorado that converts the temperature values to Celsius, and assign this new vector of Celsius temperatures to a new object named celsius_colorado.\n\n\nSuggested Solution to Exercise 2\n\n\n# applies Fahrenheit to Celsius conversion formula to \"fahrenheit_colorado\" and assigns resulting vector of Celsius values to a new object named \"celsius_colorado\"\ncelsius_colorado&lt;-(fahrenheit_colorado-32)*5/9\n\n# prints contents of \"celsius_colorado\"\ncelsius_colorado\n\n         Boulder     Fort Collins           Denver Colorado Springs \n       0.5555556       -9.4444444       -5.5555556        6.6666667 \n\n\n\nExercise 3\nTransform the class of the updated celsius_colorado object into “data.frame”, and assign the new data frame to an object named celsius_colorado_df.\n\n\nSuggested Solution to Exercise 3\n\n\n# uses \"as.data.frame\" function to transform \"celsius_colorado\" into a data.frame object, and assigns the data frame to a new object named \"celsius_colorado_df\"\ncelsius_colorado_df&lt;-as.data.frame(celsius_colorado)\n\n# prints contents of \"celsius_colorado_df\"\ncelsius_colorado_df\n\n                 celsius_colorado\nBoulder                 0.5555556\nFort Collins           -9.4444444\nDenver                 -5.5555556\nColorado Springs        6.6666667\n\n\n\nExercise 4\nConsider our toy country-level data frame, which is reproduced below:\n\n\n    Country   GDP Population     Continent\n1 Country A  8000       2000 South America\n2 Country B 30000       5400        Europe\n3 Country C 23500      10000 North America\n\n\nA). What is the class of the “Continent” Column?\n\n\nSuggested Solution to Exercise 4A\n\n\n# extracts class of \"Continent\" column\nclass(country_df$Continent)\n\n[1] \"character\"\n\n\n\nB). Extract the “Population” column into a new object. What is it’s class? Convert it to the “data.frame” class.\n\n\nSuggested Solution to Exercise 4B\n\n\n# extracts \"Population\" column into a new object named \"country_df_population\"\ncountry_df_population&lt;-country_df$Population\n\n# prints class of \"country_df_population\"\nclass(country_df_population)\n\n[1] \"numeric\"\n\n# converts \"country_df_population\" to a data.frame\ncountry_df_population&lt;-as.data.frame(country_df_population)\n\n\nC. Extract the first three columns of country_df and assign this subsetted data frame to a new object. View it in the R Studio data viewer.\n\n\nSuggested Solution to Exercise 4C\n\n\n# extracts first three columns of \"country_df_columns\" and assigns it to a new object named \"country_df_columns\"\ncountry_df_columns&lt;-country_df[, 1:3]\n\n# prints \"country_df_columns\", pass object to View() function to see it in the data viewer\ncountry_df_columns\n\n    Country   GDP Population\n1 Country A  8000       2000\n2 Country B 30000       5400\n3 Country C 23500      10000\n\n\n\nD. Extract the value of Country B’s population using indexing.\n\n\nSuggested Solution to Exercise 4D\n\n\n# extracts Country B's population (2nd row, 3rd column)\ncountry_df[2,3]\n\n[1] 5400\n\n\n\nExercise 5\nDeposit fahrenheit_colorado, celsius_colorado , and country_df into a new list object. After you have done so, extract country_df from the list using index numbers and bracket notation. Then, assign the list elements names of your choosing, and extract the celsius_colorado list object using its name and bracket notation.\n\n\nSuggested Solution to Exercise 5\n\n\n# makes a list with the relevant elements and assigns it to a new object named \"exercise_list\"\nexercise_list&lt;-list(fahrenheit_colorado, celsius_colorado, country_df)\n\n# extracts \"country_df\" from list using its index\ncountry_df[[3]]\n\n[1]  2000  5400 10000\n\n# assigns names to \"exercise_list\"\nnames(exercise_list)&lt;-c(\"CO_F\", \"CO_C\", \"ToyDF\")\n\n# extracts data frame using its list label\nexercise_list[[\"ToyDF\"]]\n\n    Country   GDP Population     Continent\n1 Country A  8000       2000 South America\n2 Country B 30000       5400        Europe\n3 Country C 23500      10000 North America",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R Foundations</span>"
    ]
  },
  {
    "objectID": "session2.html",
    "href": "session2.html",
    "title": "3  Functional Programming",
    "section": "",
    "text": "3.1 Built-In Functions\nIn this lesson, we’ll continue to develop an understanding of foundational skills and concepts that will allow you to use R effectively for applied social scientific research. Our goal is to develop an elementary proficiency in functional programming, which will allow you to fully exploit R’s capabilities when you use it for your research data tasks. A function is essentially a small program that takes an input (or series of inputs), run the input(s) through an algorithm, and produces output(s). Many functions come pre-programmed into R. R packages are essentially open-source user-written libraries of interrelated functions united by some theme, which we can draw on to extend the range of functions available to us. And finally, we can write our own custom-functions.\nGiven the enormous variety and sophistication of the R package ecosystem, you will not have to become an expert programmer to work with data in R; rather, you can draw on the functions others have written to implement virtually any data-related task you could imagine. However, developing a basic understanding of how to write your own functions is nevertheless important, for a variety of reasons:\nWith those considerations in mind, we’ll learn more in this lesson about built-in functions in R and R packages, but our main purpose is to learn how to write some simple functions of our own. We’ll also learn more about how to use functions from the purrr package (part of the tidyverse suite) to iteratively apply our functions to multiple objects, which can help to automate various data processing workflows. In other words, iteration is the process of applying a function to each element in a vector, list, or data frame; it is a key part of functional programming that can save you enormous amounts of time and energy.\nAs we have noted, functions are programmatic constructs that take in a set of inputs, and return an output or set of outputs after applying an algorithm, or “recipe” to the set of inputs. The input(s) of a function are often called argument(s). Many functions come programmed into R. For example, consider the sum() function, which takes a numeric vector as an input, and returns the sum of those elements as an output. To see how this works, we’ll first create a toy numeric vector, sample_vector:\n# creates a new numeric vector and assigns it to a new object named \"sample_vector\"\nsample_vector&lt;-c(5, 11, 5.6, 8)\n\n# prints contents of \"sample_vector\"\nsample_vector\n\n[1]  5.0 11.0  5.6  8.0\nNow, we’ll pass sample_vector as an argument to the sum() function. The sum() function takes this argument, applies the algorithm programmed into to it to calculate the sum of vector elements, and returns the sum of the vector elements as the output:\n# calculates sum of vector elements using built-in \"sum\" function\nsum(sample_vector)\n\n[1] 29.6\nAnother example of a built-in function is prod(), which returns the product of vector elements. Below, we pass sample_vector as an argument to this function, and it returns the product of the vector elements:\n# calculates product of vector elements using built-in \"prod\" function\nprod(sample_vector)\n\n[1] 2464\nNow, let’s use the built in mean() function to calculate the mean of the vector elements in sample_vector. We pass sample_vector as an argument to the mean() function, which performs the calculation based on its internal programming, and returns the mean of the vector elements as the output:\n# calculates the mean of vector elements using built-in \"mean\" function\nmean(sample_vector)\n\n[1] 7.4\nLet’s try applying the built-in median() function to sample_vector :\n# calculates the median of vector elements\nmedian(sample_vector)\n\n[1] 6.8\nThus far, we’ve been exploring elementary functions that perform mathematical calculations on numeric vectors. Let’s consider a function that’s relevant for character vectors. The nchar() function takes a string as an argument, and returns the number of characters in that string as the output. Below, we’ll pass the argument “Hello, World!” to nchar(), which returns the number of characters in that argument:\n# calculates the number of characters in a string using built-in \"nchar\" function\nnchar(\"Hello, World!\")\n\n[1] 13\nNow, let’s consider the colnames() function, which is a useful built-in function that takes a data frame as an argument, and returns the names of all of its columns. Below, the argument to the colnames() function is mtcars, which is a dataset that’s built into R (R comes installed with several built-in datasets that are very helpful for practicing new skills and experimenting with code). If you’d like, you can get a sense of the mtcars dataset by passing it to the View() function, or by viewing its documentation with ?mtcars.\n# extracts column names for \"mtcars\" dataset (which is built into R) using the built-in\n# \"ncol\" function\ncolnames(mtcars)\n\n [1] \"mpg\"  \"cyl\"  \"disp\" \"hp\"   \"drat\" \"wt\"   \"qsec\" \"vs\"   \"am\"   \"gear\"\n[11] \"carb\"\nWe can also extract a data frame’s row names using the built-in rownames() function. Below, we’ll pass mtcars as an argument to rownames():\n## extracts row names for \"mtcars\" dataset\nrownames(mtcars)\n\n [1] \"Mazda RX4\"           \"Mazda RX4 Wag\"       \"Datsun 710\"         \n [4] \"Hornet 4 Drive\"      \"Hornet Sportabout\"   \"Valiant\"            \n [7] \"Duster 360\"          \"Merc 240D\"           \"Merc 230\"           \n[10] \"Merc 280\"            \"Merc 280C\"           \"Merc 450SE\"         \n[13] \"Merc 450SL\"          \"Merc 450SLC\"         \"Cadillac Fleetwood\" \n[16] \"Lincoln Continental\" \"Chrysler Imperial\"   \"Fiat 128\"           \n[19] \"Honda Civic\"         \"Toyota Corolla\"      \"Toyota Corona\"      \n[22] \"Dodge Challenger\"    \"AMC Javelin\"         \"Camaro Z28\"         \n[25] \"Pontiac Firebird\"    \"Fiat X1-9\"           \"Porsche 914-2\"      \n[28] \"Lotus Europa\"        \"Ford Pantera L\"      \"Ferrari Dino\"       \n[31] \"Maserati Bora\"       \"Volvo 142E\"\nR has a large number of useful built-in functions, but we are not limited to these. By drawing on R packages, we can exponentially increase the number of functions at our disposal.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Functional Programming</span>"
    ]
  },
  {
    "objectID": "session2.html#packages",
    "href": "session2.html#packages",
    "title": "3  Functional Programming",
    "section": "3.2 Packages",
    "text": "3.2 Packages\nR packages are essentially pre-written collections of functions organized around a given theme. One of the big advantages of using R is that it has a very large user community among social scientists, statisticians, and digital humanists, who frequently publish R packages. One might think of packages as workbooks of sorts, which contain a well-integrated set of R functions, scripts, data, and documentation; these “workbooks” are designed to facilitate certain tasks or implement useful procedures. These packages are then shared with the broader R user community, and at this point, anyone who needs to accomplish the tasks to which the package addresses itself can use the package in the context of their own projects. The ability to use published packages considerably simplifies the work of applied data research using R; it means that we rarely have to write code entirely from scratch, and can build on the code that others have published in the form of packages. This allows applied researchers to focus on substantive problems, without having to get too bogged down in complicated programming tasks.\nIn this session, we will use various functions from the tidyverse, which is actually a suite of several different packages that implement a variety of data science tasks. When you install and load the tidyverse, we’re simultaneously installing the entire range of these packages. Today the main tidyverse package we’ll use is known as the purrr package, which is a package that contains a variety of functions that facilitate the iterative application of functions to multiple input arguments.\nTo install a package in R, we can use the install.packages() function. In the code block below, the name of the package we want to install (here, the tidyverse suite) is enclosed within quotation marks and placed within parentheses after printing install.packages Running the code below will effectively download the tidyverse suite of packages to our computer:\n\ninstall.packages(\"tidyverse\")\n\nAt this point, the tidyverse suite of packages should be installed on your computers, but the packages are not yet ready for use. Before we can use our packages, we must load them into our environment. We can think of the process of loading installed packages into a current R environment as analogous to opening up an application on your phone or computer after it has been installed (even after an application has been installed, you can’t use it until you open it!). To load (i.e. “open”) an R package, we pass the name of the package we want to load as an argument to the library() function. For example, if we want to load our tidyverse packages into the current environment, we can type:\n\nlibrary(tidyverse)\n\nAt this point, the full suite of the tidyverse suite’s functionality is available for us to use. In the next few sessions, we’ll install and load additional packages, but this is all we need for now.\nOne important thing to note regarding the installation and loading of packages is that we only have to install packages once; after a package is installed, there is usually no need to subsequently reinstall it. However, we must load the packages we need (using the library function) every time we open a new R session. In other words, if we were to close RStudio at this point and open it up later, we would not need to install the tidyverse again, but would need to load the tidyverse within the library() function again.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Functional Programming</span>"
    ]
  },
  {
    "objectID": "session2.html#writing-custom-functions",
    "href": "session2.html#writing-custom-functions",
    "title": "3  Functional Programming",
    "section": "3.3 Writing Custom Functions",
    "text": "3.3 Writing Custom Functions\nAs we mentioned earlier, a function is a programming construct that takes in a set of inputs (also known as arguments), manipulates those inputs/arguments in a specific way (within what’s known as the body of the function), and returns an output that is the product of how those inputs are manipulated in the body of the function. It is much like a recipe, where the recipe’s ingredients are analogous to a function’s inputs, the instructions about how to combine and process those ingredients are analogous to the body of the function, and the end product of the recipe (for example, a cake) is analogous to the function’s output.\nIn the previous section on built-in functions, we specified the functions’ arguments, and noted its outputs; the actual “recipes” were hidden from view. The best way to learn how these under-the-hood “recipes” work is to develop our own. To that end, we’ll now learn how to write some simple functions, and develop some intuition for how they are put together. Writing your own functions can be challenging, so we’ll develop our intuition by starting with a very simple example. In particular, we begin by writing a one-argument function; we then turn to writing a two-argument function; and then consider a multiple (more than two) input function. We’ll also explore writing functions with conditional statements embedded into them, so that they execute differently based on whether or not certain conditions are met.\n\n3.3.1 Writing One-Input Functions\nLet’s say we have a large collection of temperature data, measured in Fahrenheit, and we want to convert these data to Celsius. Recall that the formula to convert from Fahrenheit to Celsius is the following, where “C” represents temperature in Celsius, and “F” represents temperature in Fahrenheit:\n\n# fahrenheit to Celsius formula, where C is Celsius output and F is Fahrenheit input\n(F-32)*(5/9)=C\n\nAs we discussed before, at its most basic level, R is a calculator; if for example, one of our Fahrenheit measurements is 55 degrees; we can convert this to Celsius by plugging 55 into the conversion formula:\n\n# Converts 55 degrees fahrenheit to Celsius\n(55-32)*(5/9)\n\n[1] 12.77778\n\n\nThis is easy enough, but if we have a large amount of temperature data that requires processing, we wouldn’t want to carry out this calculation for each measurement in our data collection. The first step in allowing us to carry out this conversion operation at scale is to write a function. Let’s see how we can wrap the Fahrenheit-Celsius formula above into a function:\n\n# creates fahrenheit to celsius conversion function and assigns it to a new object named \"fahrenheit_to_celsius_converter\"\nfahrenheit_to_celsius_converter&lt;-function(fahrenheit_input){\n  celsius_output&lt;-(fahrenheit_input-32)*5/9\n  return(celsius_output)\n}\n\nLet’s unpack the code above, which we used to create our function:\n\nWe declare that we are creating a new function with the word function; within the parenthesis after function, we specify the function’s argument(s). Here, the function’s argument is an input named fahrenheit_input. The name of the argument(s) is arbitrary, and can be anything you like; ideally, its name should be informed by relevant context. Here, the argument/input to the function is a temperature value expressed in degrees Fahrenheit, so the name “fahrenheit_input” describes the nature of this input.\nAfter enclosing the function’s arguments within parentheses, we print a right-facing curly brace {, and then define the body of the function (i.e. the recipe), which specifies how we want to transform this input. In particular, we takefahrenheit_input, subtract 32, and then multiply by 5/9, which transforms the input to the celsius temperature scale. We’ll tell R to assign this transformed value to a new object within the function, named celsius_output. Objects defined within a function are treated differently than objects defined outside of it; we’ll return to this topic at the end of the session, but this is worth flagging and keeping in mind right now.\nIn the function’s final line, return(celsius_output), we specify the value we want the function to return. Here, we are saying that we want the function to return the value that was assigned to celsius_output. We then close the function by typing a left-facing curly brace below the return statement }.\nJust as we can assign data or visualizations to objects that allow us to subsequently retrieve the outputs of our code, so too with functions. Here, we’ll assign the function we have just written to an object named fahrenheit_to_celsius_converter.\n\nAfter running that code, we can use the newly created fahrenheit_to_celsius() function to perform our Fahrenheit to Celsius transformations. Let’s say we have a Fahrenheit value of 68, and want to transform it to Celsius:\n\n# tests function using an input of 68 degrees fahrenheit\nfahrenheit_to_celsius_converter(fahrenheit_input=68)\n\n[1] 20\n\n\nAbove, we passed the argument fahrenheit_input=68 to the fahrenheit_to_celsius_converter() function that we created; the function then took this value (68), plugged it into “fahrenheit_input” within the function and assigned the resulting value to “celsius_output”; it then returned the value of “celsius_output” (20) back to us. Note that while it’s good practice to label one’s arguments, as we did above (fahrehnheit_input=68), it isn’t strictly necessary. For example, we could just enter a numeric argument for the temperature input, and the function will work:\n\n# uses \"fahrenheit_to_celsius_converter\" function using an input of 20 degrees fahrenheit\nfahrenheit_to_celsius_converter(22)\n\n[1] -5.555556\n\n\nIn short, we can specify any value for the “fahrenheit_input” argument; this value will be substituted for “fahrenheit_input” in the expression celsius_output&lt;-(fahrenheit_input-32)*(5/9), after which the value of celsius_output will be returned to us.\n\n\n3.3.2 Writing Two-Input Functions\nLet’s extend what we learned above by writing a function that takes two arguments, rather than one. The principles are the same. To see this, let’s define a function that takes export and import values as arguments, and returns a value for net exports (defined as the difference between total exports and total imports). Below, we assign this function to an object named net_exports_calculation():\n\n# writes function that takes export and import values as inputs, and returns a value for net exports; function is assigned to a new object named \"net_exports_calculation\"\nnet_exports_calculation&lt;-function(exports, imports){\n  net_export_value&lt;-exports-imports\n  return(net_export_value)\n}\n\nIn essence, the function has two arguments, “exports” and “imports” that are supplied by the user; the body of the function takes these arguments, and subtracts the supplied value of imports from exports, and assigns this result to the object net_export_value, which it then returns as the output. Let’s go ahead and test the function:\n\n# tests the \"net_exports_calculation\" function in a case where exports are 133, and imports are 55\nnet_exports_calculation(exports=133, imports=55)\n\n[1] 78\n\n\nThe function works as expected. Note that if we switch the order in which we supply the arguments, the function continues to work as expected, so long as we label the arguments:\n\n# tests the \"net_exports_calculation\" function in a case where exports are 133, and imports are 55; reverses order in which inputs are supplied\nnet_exports_calculation(imports=55, exports=133)\n\n[1] 78\n\n\nHowever, if the arguments are not labelled, the order in which they are supplied does matter. That is, if the arguments are not labelled, the function assumes that they are passed in the order they’re defined in the function; in this case, that means that the assumption is that the first argument is the import argument and the second is the export argument. So, the following presumes that exports are 55, and imports are 133:\n\n# tests the \"net_exports_calculation\" function in a case where exports are 55, and imports are 133; does not explicitly label inputs, order matters\nnet_exports_calculation(55, 133)\n\n[1] -78\n\n\nAnd the following presumes the opposite, that exports are 133, and imports are 55.\n\n# uses the \"net_exports_calculation\" function in a case where exports are 133, and imports are 55; does not explicitly label inputs, order matters\nnet_exports_calculation(133, 55)\n\n[1] 78\n\n\n\n\n3.3.3 Writing Multiple-Input Functions\nIn this section, we’ll create a function that takes more than two inputs. In particular, we’ll create a function that takes numeric values for consumption spending (consumption_spending), government spending (government_spending), investment spending (investment_spending), and net exports (net_exports) as arguments, and returns a value for GDP (which is the sum of these values). We’ll assign this GDP calculator function to a new object named gdp_calculation:\n\n# creates a new function that takes consumption spending, government spending, investment spending, and net exports as inputs, and returns a value for GDP by summing these elements; function is assigned to a new object named \"gdp_calculation\"\ngdp_calculation&lt;-\n  function(consumption_spending, government_spending, investment_spending, net_exports){\n  gdp&lt;-consumption_spending+government_spending+investment_spending+net_exports\n  return(gdp)\n}\n\nIn short, the function takes numeric data on consumption spending, government spending, investment spending, and net exports as user-supplied arguments; it then takes these values, adds them up, and assigns them to the object gdp, which it returns as output.\nLet’s now test the function; as before, we’ll assume that units are in millions of dollars. We’ll test our function for a country with consumption spending of $125 (consumption_spending=125), government spending of $66 (government_spending=66), investment spending of $36 (investment_spending=36), and net exports of -$33 (net_exports=-33):\n\n# tests gdp calculation for consumption spending of 125, government spending of 66, investment spending of 36, and net exports of -33\ngdp_calculation(consumption_spending = 125, government_spending=66, investment_spending=36, net_exports=-33)\n\n[1] 194\n\n\nAs expected, the function returns the sum of these values, which translates into 194 (interpreted here as a GDP of $194 million).\n\n\n3.3.4 if-then Statements in Functions\nNow that we’re hopefully getting the hang of writing functions with any number of arguments, we can introduce a concept that will allow you to write more complex and sophisticated functions, namely conditional statements. By embedding conditional statements within functions, we enable them to make decisions based on whether a condition is true or false, and execute code accordingly. Conditional statements take the following form:\n\nif (condition1) {\n  # Code to execute if condition1 is TRUE\n} else if (condition2) {\n  # Code to execute if condition1 is FALSE and condition2 is TRUE\n} else {\n  # Code to execute if all the above conditions are FALSE\n}\n\nThe if block is always evaluated first. If the if condition is FALSE, the program moves to the else if block (there can be multiple such blocks). If none of the if or else if conditions are met, and all specified conditions are false, the else block (which is optional) executes.\nLet’s take an example; below, we’ll create a function that takes two arguments, “value”, and “unit”. The “value” argument is a numeric temperature value, while “unit” is a string that specifies whether “value” is in Celsius or Fahrenheit. If the input temperature value is in Fahrenheit, the function coverts it to Celsius and returns this value; if the input value is not in Fahrenheit (i.e. is in Celsius), the function converts the input to Fahrenheit, and returns this value; and finally, if the specified input temperature is in neither Celsius nor Fahrenheit, the function returns a message saying “Please indicate whether your input is in Celsius or Fahrenheit”:\n\n# creates a function that takes a temperature value (\"value\"), and a temperature scale label (\"unit\") that is either \"Fahrenheit\" or \"Celsius\" which designates the temperature scale of the input temperature value; if the input argument is in \"Fahrenheit\", the function converts the temperature to Celsius and returns this value; if the input is in \"Celsius\" the function converts the temperature to Fahrenheit and returns this value; if the the temperature scale label is neither \"Fahrenheit\" nor \"Celsius\" an error message is returned to the user; the function is assigned to a new object named \"convert_temperature\"\nconvert_temperature &lt;- function(value, unit) {\n  if (unit == \"Fahrenheit\") {\n    # Convert Fahrenheit to Celsius\n    celsius &lt;- (value - 32) * 5 / 9\n    return(celsius)\n  } else if (unit == \"Celsius\") {\n    # Convert Celsius to Fahrenheit\n    fahrenheit &lt;- (value * 9 / 5) + 32\n    return(fahrenheit)\n  } else {\n    # Handle invalid input for the unit\n    return(\"Please indicate whether your input is in Celsius or Fahrenheit\")\n  }\n}\n\nLet’s go ahead and test the function. Let’s say we want to convert 100 degrees Fahrenheit to Celsius:\n\n# Converts 100 degrees Fahrenheit to Celsius\nconvert_temperature(100, \"Fahrenheit\")\n\n[1] 37.77778\n\n\nOr, say we have Celsius values, and want to convert 25 degrees Celsius to Fahrenheit\n\n# Converts 25 degrees Celsius to Fahrenheit\nconvert_temperature(25, \"Celsius\")\n\n[1] 77\n\n\nLet’s try inputting a temperature in Kelvin:\n\n# Attempts to convert 100 degrees Kelvin to another unit; met with a message specifying the function's constraints\nconvert_temperature(100, \"Kelvin\")\n\n[1] \"Please indicate whether your input is in Celsius or Fahrenheit\"\n\n\nAs expected, the function returns a message saying this is beyond its scope.\nAs you can see, using if-then statements in a function allows functions to be flexible and dynamic, which can save time; instead of writing separate functions to convert Celsius to Fahrenheit and vice-versa, we can write a function that implements the conversion in either direction depending on the temperature value the user supplies.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Functional Programming</span>"
    ]
  },
  {
    "objectID": "session2.html#iteration",
    "href": "session2.html#iteration",
    "title": "3  Functional Programming",
    "section": "3.4 Iteration",
    "text": "3.4 Iteration\nNow that we have a sense of how to write basic functions, let’s now turn to the concept of iteration, which is fundamentally about applying a function across the elements of a vector, list, or data frame in a programmatic way. Functions and iteration are thus closely related; functions are small programs that perform some action, while iteration applies those programs repeatedly across several objects. For example, we already have a function to convert Fahrenheit temperature values to Celsius temperature values; using this newly created function helps us to avoid manually converting each of our temperature values from the Fahrenheit scale to the Celsius scale. Instead of repeating the calculation over and over manually, we could simply plug our Fahrenheit temperature values into the function, and let the function carry out the calculation for us. However, it is still time-consuming to plug our Fahrenheit values into the function one-by-one. Instead, we could deposit our Fahrenheit temperature values into a vector, and iteratively (i.e. sequentially) apply our function to all of these vector elements, and deposit the transformed results into a new vector (or a list, or as the rows of a data frame).\nIn programming languages, functions are typically applied to multiple inputs in an iterative fashion using a construct known as a for-loop, which some of you may already be familiar with. R users also frequently use specialized functions (instead of for-loops) to iterate over elements; this is often faster, or at the very least, makes R scripts more readable. One family of these iterative functions is the “Apply” family of functions. A more recent set of functions that facilitate iteration is part of the tidyverse, and is found within the purrr package. These functions are known as map() functions, and we will use them in this lesson to iteratively apply our functions to multiple inputs arguments in a repeated fashion.\nThere are many different kinds of map() functions within the purrr package, and we’ll introduce specific functions from this family of functions as we go. However, two of the fundamental map functions to be aware of at the outset are map(), which iterates over the elements of a vector or list, and deposits the results in a list, and map_dbl(), which iterates over the elements of a vector or list, and deposits the results in a numeric vector. If you’d like a preview of map() functions before we dive in, please consult the function’s documentation: ?map().\n\n3.4.1 Iteration with a Single-Input Function\nLet’s say we have four different Fahrenheit temperature values that we want to convert to Celsius: 45.6, 95.9, 67.8, 43. We could pass each input as an argument to fahrenheit_to_celsius_converter() individually, and get our Fahrenheit values that way, but it would quickly become tedious. Instead, we’ll implement a strategy that involves iteratively applying our function to those Fahrenheit temperature values. As a first step, we’ll create a vector of Fahrenheit temperature input arguments:\n\n# creates a vector of fahrenheit inputs\nfahrenheit_input_vector&lt;-c(45.6, 95.9, 67.8, 43)\n\nNow, we’ll use the map() function to iteratively apply fahrenheit_to_celsius_converter() to each element in that vector, and deposit the results in a list. We’ll passfahrenheit_input_vector (i.e. the elements we want to iterate over) as the first argument to the map() function, and fahrenheit_to_celsius_converter() (i.e. the function we want to apply iteratively to the elements in thefahrenheit_input_vector) as the second argument. The result of this operation will be a new “results list”, containing the transformed temperature values for each input in the original vector of Fahrenheit values (fahrenheit_input_vector). We’ll assign this result/output list to a new object namedcelsius_outputs_list:\n\n# iteratively applies the \"fahrenheit_to_celsius_converter\" function to the vector of input arguments, \"fahrenheit_input_vector\", and assigns the resulting list of outputs to \"celsius_outputs_vector\"\ncelsius_outputs_list&lt;-map(.x=fahrenheit_input_vector, .f=fahrenheit_to_celsius_converter)\n\nIn short, the code above takes fahrenheit_input_vector and runs each of these numbers through the fahrenheit_to_celsius_converter() function, and then sequentially deposits the transformed result to the newly created celsius_outputs_list object, which contains the transformed Celsius values:\n\n# prints contents of \"celsius_outputs_list\"\ncelsius_outputs_list\n\n[[1]]\n[1] 7.555556\n\n[[2]]\n[1] 35.5\n\n[[3]]\n[1] 19.88889\n\n[[4]]\n[1] 6.111111\n\n\nMore explicitly, the code that reads celsius_outputs_list&lt;-map(fahrenheit_input_vector, fahrenheit_converter)did the following:\n\nPass 45.6 (the first element in the input vector, fahrenheit_input_vector) to the fahrenheit_to_celsius_converter() function, and place the output (7.555556) as the first element in a new list of transformed values, named celsius_outputs_list.\nPass 95.9 (the second element in the input vector, fahrenheit_input_vector) to the fahrenheit_to_celsius_converter() function, and deposit the output (35.500000) as the second element in celsius_outputs_list.\nPass 67.8 (the third element in the input vector, fahrenheit_input_vector) to the fahrenheit_to_celsius_converter() function, and deposit the output (19.888889) as the third element in celsius_outputs_list.\nPass 43 (the fourth element in the input vector, fahrenheit_input_vector) to the fahrenheit_to_celsius_converter() function, and deposit the output (6.111111) as the fourth element in celsius_outputs_list.\n\nRecall that if we want to extract an element from a list, we can do so by specifying its index within double brackets. For instance, if we wanted to extract the second element in celsius_outputs_list, we could type the following:\n\n# extracts second element from \"celsius_outputs_list\"\ncelsius_outputs_list[[2]]\n\n[1] 35.5\n\n\nAs we have noted, there are a variety of map() functions, and the precise one you should use turns on the number of arguments used by the function (here, this value is of course one), and the desired class of the output (i.e. list, numeric vector etc.). Here, we used the core map() function because we wanted a list as an output, and we have a one-argument function that we are applying. Below, we’ll talk more about how to handle functions with multiple arguments within the purrr ecosystem. Before that, though, let’s see how to use a slightly different type of map() function to return a different kind of output.\nIn particular, let’s say we want to iteratively apply the values in fahrenheit_input_vector as arguments to the fahrenheit_to_celsius_converter() but that we want the outputs to be deposited in a numeric vector, rather than a list (as above). To do so, we can pass the same arguments we passed to the map() function, but use the map_dbl() function instead, which will return a vector:\n\n# iteratively applies the \"fahrenheit_to_celsius_converter\" function to the vector of input arguments, \"fahrenheit_input_vector\", and assigns the resulting vector of outputs to \"celsius_outputs_vector\"\ncelsius_outputs_vector&lt;-map_dbl(.x=fahrenheit_input_vector, .f=fahrenheit_to_celsius_converter)\n\nIn short, the code above takes the first element of fahrenheit_input_vector, passes it as an input argument to fahrenheit_to_celsius_converter(), and deposits the output Celsius value as the first element in celsius_outputs_vector; it then takes the second element of fahrenheit_input_vector, passes it as an input argument to fahrenheit_to_celsius_converter(), and deposits the output Celsius value as the second element in celsius_outputs_vector ; and so on. Let’s print the contents of celsius_outputs_vector:\n\n# prints contents of \"celsius_outputs_vector\"\ncelsius_outputs_vector\n\n[1]  7.555556 35.500000 19.888889  6.111111\n\n\nAs expected, we see that it is a vector containing the output Celsius values generated by applying the function to the various Fahrenheit input arguments.\nWhat if we want a data frame that contains the input Fahrenheit values as one column, and the output Celsius columns as another, instead of a list or vector of outputs? We can do so by using the map_dbl() function in conjunction with the arguments above within the data.frame() function that can define a data frame. In particular:\n\n# creates a data frame in which one column contains Fahrenheit input values, and the other contains Celsius output values\nfahrenheit_celsius_df_output&lt;-data.frame(Fahrenheit=fahrenheit_input_vector,\n                                         Celsius=map_dbl(.x=fahrenheit_input_vector, .f=fahrenheit_to_celsius_converter))\n\nLet’s confirm that the data frame has been created as expected:\n\n# prints contents of \"fahrenheit_celsius_df_output\"\nfahrenheit_celsius_df_output\n\n  Fahrenheit   Celsius\n1       45.6  7.555556\n2       95.9 35.500000\n3       67.8 19.888889\n4       43.0  6.111111\n\n\nAs you can see, we now have a handy data frame that has a column of Fahrenheit inputs, and a column of Celsius outputs.\n\n\n3.4.2 Iteration with a Double-Input Function\nIn the previous subsection, we explored map() function in the context of working with single argument functions. In this section, we’ll explore how related functions from the purrr package can be used to iteratively pass arguments to a function with two input arguments. To illustrate, we will consider the net_exports_calculation() function we created above.\nLet’s say we have export and import data from three countries, and want to calculate net exports for each country. First, we’ll deposit our input arguments into two different vectors. The numeric vector export_vector contains information for export values, while import_vector contains information on import values:\n\n# creates export and import vectors\nexport_vector&lt;-c(78, 499, 785)\nimport_vector&lt;-c(134, 345, 645)\n\nNow, we’ll use the map2() function to iteratively pass the input arguments from these two vectors to the net_exports_calculation() function, and deposit the outputs (i.e. net export values) into a list, which we’ll assign to an object named net_export_list. The “.x” label signifies that export_vector is the first argument for the net_exports_calculation() function to iterate over, while the “.y” label signifies that import_vector is the second argument for net_exports_calculation() to iterate over. The “.f” label signifies the name of the function to which we’re applying these arguments.\n\n# iteratively applies the \"net_exports_calculation\" function to the export values contained in \"export_vector\" and the import values contained in \"import_vector\" and deposits the resulting outputs in a list that's assigned to the new object entitled \"net_export_list\"\nnet_export_list&lt;-map2(.x=export_vector, .y=import_vector, .f=net_exports_calculation)\n\nIn short, the code above takes the first value in export_vector and the first value in import_vector and passes these values to net_exports_calculation to calculate net exports for the first country, which is then deposited as the first element in net_export_list; then, it takes the second value in export_vector and the second value in import_vector and passes these values to net_exports_calculation to calculate net exports for the second country, which is then deposited as the second element in net_export_list; and likewise for the third country. We can print the contents of net_export_list to ensure that the code worked as expected:\n\n# prints contents of \"net_export_list\"\nnet_export_list\n\n[[1]]\n[1] -56\n\n[[2]]\n[1] 154\n\n[[3]]\n[1] 140\n\n\nIf, instead of depositing the results into a list, we’d like to deposit our outputs into a numeric vector, we can do so using themap2_dbl() function, the analog of map_dbl() which is used when the function takes two input arguments rather than one. We’ll assign our results vector to a new object named net_export_vector:\n\n# iteratively applies the \"net_exports_calculation\" function to the export values contained in \"export_vector\" and the import values contained in \"import_vector\" and deposits the resulting outputs in a vector that's assigned to the new object entitled \"net_export_vector\"\nnet_export_vector&lt;-map2_dbl(.x=export_vector, .y=import_vector, .f=net_exports_calculation)\n\nLet’s print the contents of net_export_vector:\n\n# prints contents of \"net_export_vector\"\nnet_export_vector\n\n[1] -56 154 140\n\n\nIf, instead, we’d like a data frame that contains exports in the first column, imports in the second column, and net exports in the third, we could use the data.frame() function, and run the code that generated net_export_vector within it. We’ll assign this data frame to a new object named net_exports_dataframe:\n\n# creates data frame with exports in first column, imports in second column, and net exports in third; assigns the data frame to a new object named \"net_exports_dataframe\"\nnet_exports_dataframe&lt;-data.frame(exports=export_vector,\n                                 imports=import_vector,\n      net_exports=map2_dbl(.x=export_vector, .y=import_vector, .f=net_exports_calculation))\n\nOf course, we could have also created the data frame above with the following:\n\n# alternative way of creating \"net_exports_dataframe\"\ndata.frame(exports=export_vector,\n           imports=import_vector,\n           net_exports=net_export_vector)\n\n  exports imports net_exports\n1      78     134         -56\n2     499     345         154\n3     785     645         140\n\n\n\n\n3.4.3 Iteration with a Multiple-Input Function\nWhile the map2() family functions allows us to conveniently handle iteration tasks involving two-argument functions, we will often need to write and work with functions with more than two arguments. How can we carry out iteration tasks when we need to iteratively pass multiple input arguments to a function?\nThe pmap() family of functions within purrr allows us to handle iteration tasks using functions with any number of inputs greater than two, by using a list as a container for all of the input arguments we would like to iteratively pass to a functions To see how this works, let’s consider the gdp_calculator() function that we created above. Let’s say we have consumption spending, government spending, investment spending, and net export data for four different countries, and we want to iteratively pass the data for these countries as arguments to gdp_calculator() and derive the GDP for each country.\nThe first step is to create a new list of input arguments, where each list element is a vector that contains the country-level values for each argument of the gdp_calculation() function. We’ll assign this list to a new object named gdp_input_list:\n\n# creates a list as a container for the input arguments we'll iteratively run through the \"gdp_calculation\" function\ngdp_input_list&lt;-list(consumption_spending=c(44, 89, 64, 33),\n                     government_spending=c(54, 76, 222, 110),\n                     investment_spending=c(123, 200, 55, 45),\n                     net_exports=c(-55, 89, 143,-12))\n\nTo make sure we understand what gdp_input_list represents, consider the first element in each of the four numeric vectors in the list; these first elements correspond to the first country, which we can see has consumption spending of $44, government spending of $54, investment spending of $123, and net exports of -$55. The second element of each of the vectors in the list corresponds to information for the second country, which has consumption spending of $89, government spending of $76, investment spending of $200, and net exports of $89. And so on for Countries 3 and 4.\nNow that we have defined our list of input values (gdp_input_list) based on the arguments to the gdp_calculation() function, we can pass gdp_input_list (the list of input values) and gdp_calculation() (the function to which we’re iteratively passing the arguments in gdp_input_list) as arguments to purrr’s pmap() function. The pmap() function iteratively passes the arguments in the input list to the gdp_calculation() function in a vectorized fashion. That is, the pmap() function uses the first element in each vector of the input list to generate the first output value, then uses the second element in each vector of the input list to generate the second output value, and so on. We’ll assign the resulting list of output values to a new object named gdp_output_list. The “.l” label is used to designate the list of input arguments, while the “.f” argument designates the function to which we are iteratively passing arguments from the input list:\n\n# iteratively passes arguments from \"gdp_input_list\" to the \"gdp_calculation\" function and deposits the results in a new list object named \"gdp_output_list\"\ngdp_output_list&lt;-pmap(.l=gdp_input_list, .f=gdp_calculation)\n\nLet’s now print the contents of gdp_output_list:\n\n# prints contents of \"gdp_output_list\"\ngdp_output_list\n\n[[1]]\n[1] 166\n\n[[2]]\n[1] 454\n\n[[3]]\n[1] 484\n\n[[4]]\n[1] 176\n\n\nAs expected, the first list element contains the GDP of the first country, 166 (44+54+123+55); the second list element contains the GDP of the second country, 454 (89+76+200+89); and so on, for the third and fourth countries.\nIf, instead, we want the results deposited in a vector, we can use the pmap_dbl() function instead:\n\n# iteratively passes arguments from \"gdp_input_list\" to the \"gdp_calculation\" function and deposits the results in a new list object named \"gdp_output_vector\"\ngdp_output_vector&lt;-pmap_dbl(.l=gdp_input_list, .f=gdp_calculation)\n\nLet’s print the contents of gdp_output_vector and confirm that it contains the expected outputs of the GDP function:\n\n# prints contents of \"gdp_output_vector\"\ngdp_output_vector\n\n[1] 166 454 484 176\n\n\nAs an exercise below, we’ll ask you to assemble a data frame in which consumption spending, government spending, investment spending, and net exports for these countries are in columns, along with another column that contains the GDP value.\n\n\n3.4.4 Iteration with more complex functions\nNow, let’s see how we can iteratively apply a more complex function with multiple inputs and conditional logic that results in different outputs depending on whether certain conditions are met. We’ll slightly modify the convert_temperature() function we created above. In particular, this modified function will take three inputs; the first specifies the name of a country, the second specifies a temperature in either Celsius or Fahrenheit, and the third provides information on whether the temperature value is provided in Celsius or Fahrenheit.\nIf the temperature is provided in Fahrenheit, the function converts this value to Celsius, while also recording the temperature in Fahrenheit based on the input value. If the temperature is provided in Celsius, it converts Celsius to Fahrenheit, while also recording the temperature in Celsius based on the input value. Then, it uses this information to create a one-row data frame, where the columns are the Country, temperature in Celsius, and temperature in Fahrenheit. The function below is extensively commented; see if you can make sense of its logic.\n\n# creates new function to take a country name, temperature value in either Celsius or Fahrenheit, and a designation for the temperature unit as inputs, and return a data frame with the country name, temperature value in Fahrenheit, and Temperature value in Celsius as columns; the function is assigned to a new object named \"convert_temperature_df\"\nconvert_temperature_df &lt;- function(country, temperature, unit) {\n  # Check if the unit is valid\n  if (unit == \"Fahrenheit\") {\n    # Convert Fahrenheit to Celsius\n    celsius &lt;- (temperature - 32) * 5 / 9\n    fahrenheit &lt;- temperature\n  } else if (unit == \"Celsius\") {\n    # Convert Celsius to Fahrenheit\n    fahrenheit &lt;- (temperature * 9 / 5) + 32\n    celsius &lt;- temperature\n  } else {\n    # Throw an error if the unit is invalid\n    stop(\"Error: Please indicate whether your input is in 'Celsius' or 'Fahrenheit'\")\n  }\n  \n  # Create and return a data frame\n  result &lt;- data.frame(\n    Country = country,\n    Temperature_Celsius = round(celsius, 2),   # Round to 2 decimal places\n    Temperature_Fahrenheit = round(fahrenheit, 2)\n  )\n  \n  return(result)\n}\n\nNow, let’s go ahead and test this function, where the country is “USA”, and the temperature in Fahrenheit is 100:\n\n# tests \"convert_temperature_df\" function for USA as the country input, and a temperature of 100 degrees in Fahrenheit\nconvert_temperature_df(\"USA\", 100, \"Fahrenheit\")\n\n  Country Temperature_Celsius Temperature_Fahrenheit\n1     USA               37.78                    100\n\n\nAs we can see, the function behaved as expected; it creates a data frame where the country is “USA”, and there are columns for the temperature in Celsius and Fahrenheit. In this case, the Fahrenheit temperature was filled in by the user-supplied argument, while the Celsius temperature was filled in by transforming the Fahrenheit temperature value to the Celsius scale within the function.\nLet’s test the function again, with different input arguments:\n\n# tests \"convert_temperature_df\" function for India as the country input, and a temperature of 100 degrees in Fahrenheit\nconvert_temperature_df(\"India\", 39, \"Celsius\")\n\n  Country Temperature_Celsius Temperature_Fahrenheit\n1   India                  39                  102.2\n\n\nAgain, the function behaves as expected. It creates a data frame where the country is “India”, and columns for the temperature in Celsius and Fahrenheit. In this case, the Celsius temperature was filled in by the user-supplied argument, while the Fahrenheit temperature was filled in by transforming the Celsius temperature value to the Fahrenheit scale within the function.\nNow, let’s imagine we have data for several countries, and we want to iteratively pass this data as arguments to convert_temperature_df to generate a data frame with information on the temperatures for these countries. To do so, we can use the pmap() function. First, we’ll create a list with vectors that contain the input arguments we want to pass to the function; we’ll assign this list to a new object named input_list_temperatures:\n\n# creates a list of inputs to iterate over\ninput_list_temperatures&lt;-list(country=c(\"USA\", \"Canada\", \"Mexico\", \"France\"),\n                              temperature=c(66, 11, 25, 33),\n                              unit=c(\"Fahrenheit\", \"Celsius\", \"Fahrenheit\", \"Celsius\"))\n\nNext, we’ll pass this list and the convert_temperature_df() function as arguments to pmap(), and assign the resulting list of outputs to a new object named convert_temperature_list.\n\n# iteratively applies the \"convert_temperature_df\" function using the input variables in \"input_list_temperatures\"; the outputs are deposited in a list assigned to the object named \"convert_temperature_list\"\nconvert_temperature_list&lt;-pmap(.l=input_list_temperatures, .f=convert_temperature_df)\n\nThe code above first takes the first elements in the vectors in input_list_temperatures (“USA, 66,”Fahrenheit”), runs them through the convert_temperature_df() function, and deposits the resulting data frame as the first element in convert_temperature_list. It then takes the second elements in the vectors in input_list_temperatures (“Canada”, 11, “Celsius”), passes them as arguments to the convert_temperature_df() function, and deposits the resulting data frame as the second element in convert_temperature_list. And so on.\nLet’s now print the contents of convert_temperature_list , which should contain four single-row data frames:\n\n# prints contents of \"convert_temperature_list\"\nconvert_temperature_list\n\n[[1]]\n  Country Temperature_Celsius Temperature_Fahrenheit\n1     USA               18.89                     66\n\n[[2]]\n  Country Temperature_Celsius Temperature_Fahrenheit\n1  Canada                  11                   51.8\n\n[[3]]\n  Country Temperature_Celsius Temperature_Fahrenheit\n1  Mexico               -3.89                     25\n\n[[4]]\n  Country Temperature_Celsius Temperature_Fahrenheit\n1  France                  33                   91.4\n\n\nAs we can see, the data frames are stored separately as list elements (which is what we expected). If we’d like to bind these data frame rows together into a single, consolidated data frame, we can easily do so by passing convert_temperature_list as an argument to the bind_rows() function from the dplyr package. We’ll assign this data frame to a new object named convert_temperature_df_final:\n\n# appends together the single-row data frames in \"convert_temperature_list\" into a single data frame by passing \"convert_temperature_list\" as an argument to \"bind_rows\"; the newly created data frame is assigned to a new object named \"convert_temperature_df_final\"\nconvert_temperature_df_final&lt;-bind_rows(convert_temperature_list)\n\n\n# prints contents of \"convert_temperature_df_final\"\nconvert_temperature_df_final\n\n  Country Temperature_Celsius Temperature_Fahrenheit\n1     USA               18.89                   66.0\n2  Canada               11.00                   51.8\n3  Mexico               -3.89                   25.0\n4  France               33.00                   91.4\n\n\nFinally, it’s worth noting that it’s possible to incorporate iteration processes with map() family functions within our custom-written functions. In other words, we can include map() functions within the body of our functions, rather than simply using them on pre-defined functions. Moreover, its possible to incorporate functions we’ve already written into new custom functions; incorporating “functions within functions” can often help us accomplish some very useful tasks.\nLet’s consider an example, by writing a new function that takes takes a vector of Fahrenheit temperature values and transforms these values to the Celsius scale. It will return these transformed values either as a list, vector, or data frame (containing the initial Fahrenheit temperatures as one column. and the transformed Celsius temperatures in another), depending on the user’s preference\nBelow, the function’s first argument is the vector of Fahrenheit temperatures, while the second is the user’s preference over whether the transformed values are returned as a list (“List), vector (”Vector”), or data frame (“Data.Frame”).\n\nIf the user desires the output as a list, the function passes the vector of Fahrenheit inputs as an argument to the map() function, along with the fahrenheit_to_celsius_converter() that we defined earlier. This will iteratively pass the temperature values in the input vector as arguments to fahrenheit_to_celsius_converter, and the output Celsius temperatures are returned as a list.\nIf, instead, the user desires the output as a numeric vector, the function passes the the vector of Fahrenheit inputs as an argument to the map_dbl() function, along with the fahrenheit_to_celsius_converter(). This will iteratively pass the temperature values in the input vector as arguments to fahrenheit_to_celsius_converter, and the output Celsius temperatures are returned as a vector (given the behavior of the map_dbl() function).\nIf the user desires a data frame, the function will create a data frame using the data.frame() function, and define a column for Fahrenheit values using the vector of inputs, and a column of Celsius temperature values using the vector of transformed Celsius values created by map_dbl(.x=vector_of_fahrenheit_inputs, .f =fahrenheit_to_celsius_converter). We’ll assign this function to a new object named fahrenheit_to_celsius_general():\nFinally, If the user specifies a an output that is not “List”, “Data.Frame”, or “Vector”, the function throws an error.\n\n\n# Writes a function that takes a vector of fahrenheit temperature values, and returns either a list, data frame, or vector of outputs depending on the user's desired output; assigns the function to a new object named \"fahrenheit_to_celsius_general\"\nfahrenheit_to_celsius_general&lt;-function(vector_of_fahrenheit_inputs, desired_output){\n   if (desired_output == \"List\") {\n     outputlist&lt;-map(.x=vector_of_fahrenheit_inputs, .f=fahrenheit_to_celsius_converter)\n     return(outputlist)\n   } else if (desired_output==\"Vector\"){\n     outputvector&lt;-map_dbl(.x=vector_of_fahrenheit_inputs, .f =fahrenheit_to_celsius_converter)\n     return(outputvector)\n   } else if (desired_output==\"Data.Frame\"){\n     outputdf&lt;-data.frame(Fahrenheit=vector_of_fahrenheit_inputs,\n                          Celsius=map_dbl(.x=vector_of_fahrenheit_inputs, .f =fahrenheit_to_celsius_converter))\n     return(outputdf)\n   } else {\n      stop(\"Error: Please indicate whether your desired output is a 'Vector', 'Data.Frame', or 'List'\")\n   }\n}\n\nNow, let’s test this function out. First, we’ll define a vector of Fahrenheit values we’d like to convert, and assign it to a new object named test_vector_ftoc:\n\n# tests \"fahrenheit_to_celsius_general\" function; first, defines a vector of fahrenheit values\ntest_vector_ftoc&lt;-c(18, 66, 88, -12, 7)\n\nNow let’s test the function by passing test_vector_ftoc as an argument to it, along with specifying “Data.Frame” as our desired output.\n\n# uses \"fahrenheit_to_celsius_general\" function to convert the temperature values in \"test_vector_ftoc\" to Celsius and return a data frame with input Fahrenheit values in one column, and corresponding celsius temperatures in another column\nfahrenheit_to_celsius_general(vector_of_fahrenheit_inputs=test_vector_ftoc, desired_output=\"Data.Frame\")\n\n  Fahrenheit    Celsius\n1         18  -7.777778\n2         66  18.888889\n3         88  31.111111\n4        -12 -24.444444\n5          7 -13.888889\n\n\nThe function behaves as expected. Now, let’s try specifying that we want the transformed Celsius temperatures as a list:\n\n# uses \"fahrenheit_to_celsius_general\" function to convert the temperature values in \"test_vector_ftoc\" to Celsius and return the outputs as a list\nfahrenheit_to_celsius_general(vector_of_fahrenheit_inputs=test_vector_ftoc, desired_output=\"List\")\n\n[[1]]\n[1] -7.777778\n\n[[2]]\n[1] 18.88889\n\n[[3]]\n[1] 31.11111\n\n[[4]]\n[1] -24.44444\n\n[[5]]\n[1] -13.88889\n\n\nFinally, we’ll check the function’s behavior when we request the output as a vector:\n\n# uses \"fahrenheit_to_celsius_general\" function to convert the temperature values in \"test_vector_ftoc\" to Celsius and return the outputs as a vector\nfahrenheit_to_celsius_general(vector_of_fahrenheit_inputs=test_vector_ftoc, desired_output=\"Vector\")\n\n[1]  -7.777778  18.888889  31.111111 -24.444444 -13.888889\n\n\nIt’s worth noting that when we request an output that is not supported, we receive the expected error message. For example, let’s specify our desired output as a tibble (i.e. a special type of data frame):\n\n# uses \"fahrenheit_to_celsius_general\" function to convert the temperature values in \"test_vector_ftoc\" to Celsius and return the outputs as a tibble\nfahrenheit_to_celsius_general(vector_of_fahrenheit_inputs=test_vector_ftoc, desired_output=\"Tibble\")\n\nError in fahrenheit_to_celsius_general(vector_of_fahrenheit_inputs = test_vector_ftoc, : Error: Please indicate whether your desired output is a 'Vector', 'Data.Frame', or 'List'",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Functional Programming</span>"
    ]
  },
  {
    "objectID": "session2.html#global-and-local-environments",
    "href": "session2.html#global-and-local-environments",
    "title": "3  Functional Programming",
    "section": "3.5 Global and Local Environments",
    "text": "3.5 Global and Local Environments\nNow that we know a little bit more about how functions are put together, it is worth briefly discussing global and local environments in R. The global environment is the environment where the objects we define are created and stored during an R Session. A local environment is a temporary environment created within functions. When objects are defined within a function, those objects only exist within that function, and won’t be accessible globally (unless they’re explicitly assigned to the global environment).\nTo get a better sense of this, let’s first define an object, x in our global environment:\n\n# define a variable in the global environment\nx&lt;-24\n\nNow, we’ll create a toy function that defines another value for x within its environment.\n\n# creates a toy function that takes a numeric input argument (\"input1\"); it defines an object, x, within the function, then defines a function, z, that's the sum of x and input1. It returns Z as an output\ntoy_function&lt;-function(input1){\n  x&lt;-5\n  z&lt;-x+input1\n  return(z)\n}\n\nGo ahead and test the function to ensure it works as expected.\n\n# passes the argument \"input1=7\" to the toy function\ntoy_function(input1=7)\n\n[1] 12\n\n\nIn this context, the key thing to note is that even though we defined x&lt;-5 within the function, when we print the value of x, it returns 24, which was the value assigned in the global environment. The local object x, assigned a value of 5, only exists when the function runs; then it disappears.\n\n# prints value of x; note it returns the value from the global environment\nx\n\n[1] 24\n\n\nNote, also that when we try to print out the value of z, we are met with an error, since it’s only defined within the local environment of the function; z is not an object in the global environment and does not exist in the context of this environment. Rather, it is created in the function’s local environment and disappears after the function finishes running.\n\n# prints value of z; note that there's an error, since z is only defined within the local environment of the function\nz\n\nError: object 'z' not found\n\n\nAnother way of noting this is to call the ls() function, and see that “z” is not printed to the console along with other objects in the global environment, since it’s only defined within the toy_function().\n\n# prints objects in memory; note that z is not included, since it's only defined within the function\nls()\n\n [1] \"celsius_outputs_list\"            \"celsius_outputs_vector\"         \n [3] \"convert_temperature\"             \"convert_temperature_df\"         \n [5] \"convert_temperature_df_final\"    \"convert_temperature_list\"       \n [7] \"export_vector\"                   \"fahrenheit_celsius_df_output\"   \n [9] \"fahrenheit_input_vector\"         \"fahrenheit_to_celsius_converter\"\n[11] \"fahrenheit_to_celsius_general\"   \"gdp_calculation\"                \n[13] \"gdp_input_list\"                  \"gdp_output_list\"                \n[15] \"gdp_output_vector\"               \"import_vector\"                  \n[17] \"input_list_temperatures\"         \"net_export_list\"                \n[19] \"net_export_vector\"               \"net_exports_calculation\"        \n[21] \"net_exports_dataframe\"           \"sample_vector\"                  \n[23] \"test_vector_ftoc\"                \"toy_function\"                   \n[25] \"x\"                              \n\n\nAn important implication of the fact that the local environment within a function exists apart from the global environment is that when writing functions, you don’t have to worry about accidentally overwriting global objects.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Functional Programming</span>"
    ]
  },
  {
    "objectID": "session2.html#end-of-lesson-exercises",
    "href": "session2.html#end-of-lesson-exercises",
    "title": "3  Functional Programming",
    "section": "3.6 End-of-Lesson Exercises",
    "text": "3.6 End-of-Lesson Exercises\nExercise 1\nWrite a function that takes a monetary value (in US dollars) as an input, and returns the equivalent value in Euros. Assign the function to an object, and test it out with some sample arguments.\n\n\nSuggested Solution to Exercise 1\n\n\n# creates a US Dollar (usd) to Euro (eur) conversion function based on current Dollar to Euro exchange rate\nusd_to_eur&lt;-function(dollar_input){\n  dollar_to_euro_conversion&lt;-dollar_input*0.9637\n  return(dollar_to_euro_conversion)\n}\n\n# Uses function to convert $18.23 to Euros\nusd_to_eur(18.23)\n\n[1] 17.56825\n\n# Uses function to convert $127.00 to Euros\nusd_to_eur(127)\n\n[1] 122.3899\n\n\n\nExercise 2\nWrite a function that takes a monetary value (in US Dollars) as an input, as well as an argument in which the user can tell the function to convert that value to an equivalent amount in Euros, Indian Rupees, or Mexican Pesos. The function returns the US dollar equivalent in the desired currency. Assign this function to a new object.\n\n\nSuggested Solution to Exercise 2\n\n\n# creates new function, \"exchange_rate_calculator\", that converts USD amount to Euros (EUR), Indian Rupees (INR), or Pesos (MXN); if the desired currency argument is not either \"EUR\", \"INR\", or \"MXN\" (i.e. the currency tickers), the function throws an error\nexchange_rate_calculator&lt;-function(USD_currency_value, desired_currency){\n  if (desired_currency==\"EUR\"){\n    euros&lt;-USD_currency_value*0.96\n    return(euros)\n  } else if (desired_currency==\"INR\"){\n    inr&lt;-USD_currency_value*87.58\n    return(inr)\n  } else if (desired_currency==\"MXN\"){\n    mxn&lt;-USD_currency_value*20.48\n    return(mxn)\n  } else{\n    stop(\"Please indicate whether you'd like to convert this value to EUR, INR, or MXN\")\n  }\n}\n\n# tests \"exchange_rate_calculator\" by converting $25 to INR\nexchange_rate_calculator(25, \"INR\")\n\n[1] 2189.5\n\n# uses \"exchange_rate_calculator\" to convert $25 to EUR\nexchange_rate_calculator(25, \"EUR\")\n\n[1] 24\n\n# uses \"exchange_rate_calculator\" to convert $25 to MXN\nexchange_rate_calculator(25, \"MXN\")\n\n[1] 512\n\n\n\nExercise 3\nTake the function you wrote for Question 1 above, and use a function from the purrr package to programmatically generate a data frame where one column contains US dollars in the following amounts: 10.25, 1245.55, 83, 76, 11559, and the other column contains the equivalent sum of money in Euros.\n\n\nSuggested Solution to Exercise 3\n\n\n# create vector of USD currency values to convert\nusd_vector&lt;-c(10.25, 1245.55, 83, 76, 11559)\n\n# create vector that contains converted Euro values\neuro_vector&lt;-map_dbl(.x=usd_vector, .f=usd_to_eur)\n\n# creates dataset with USD values in one column, and corresponding converted Euro values in another\ncurrency_df&lt;-data.frame(USD_Value=usd_vector,\n                        EUR_Value=euro_vector)\n\n# prints \"currency_df\"\ncurrency_df\n\n  USD_Value    EUR_Value\n1     10.25     9.877925\n2   1245.55  1200.336535\n3     83.00    79.987100\n4     76.00    73.241200\n5  11559.00 11139.408300",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Functional Programming</span>"
    ]
  },
  {
    "objectID": "session3.html",
    "href": "session3.html",
    "title": "4  Transferring, Processing, and Wrangling Data",
    "section": "",
    "text": "4.1 Introduction\nIn the past two sessions, we presented some ideas, concepts, and tools that provide a basic foundation for working with data in R. Now that we have this basic foundation, we’ll turn in this session to a more applied exploration of some actual datasets. Our goal here is to introduce you to some useful functions that will allow you to explore and begin making sense of actual datasets in R. This lesson will provide a tour of various functions that can be particularly helpful as you get started processing and wrangling data in R, so that you can get your raw datasets ready for analysis and visualization. Among the topics we’ll cover today are:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transferring, Processing, and Wrangling Data</span>"
    ]
  },
  {
    "objectID": "session3.html#introduction",
    "href": "session3.html#introduction",
    "title": "4  Transferring, Processing, and Wrangling Data",
    "section": "",
    "text": "Reading data into R\nHandling missing data in R\nPreparing and transforming datasets for analysis using a variety of tidyverse functions for data wrangling and processing",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transferring, Processing, and Wrangling Data</span>"
    ]
  },
  {
    "objectID": "session3.html#preliminaries",
    "href": "session3.html#preliminaries",
    "title": "4  Transferring, Processing, and Wrangling Data",
    "section": "4.2 Preliminaries",
    "text": "4.2 Preliminaries\n\n4.2.1 Install and Load Packages\nIn this lesson, we’ll work with a variety of packages from the tidyverse suite, as well as the fastDummies package, which is a handy package for quickly transforming categorical variables into binary indicator variables (i.e. dummy variables). Please go ahead and make sure that both the tidyverse and fastDummies are installed and loaded. Recall that in general, you only need to install packages once, so assuming you completed the previous lesson, you wouldn’t need to install the tidyverse again (assuming you’re working on the same computer and haven’t made significant changes to your operating system or updated R since then). If you haven’t installed one or both packages, recall that you can install packages by passing the name of the package as an argument to the install.packages() function (i.e. install.packages(\"fastDummies\").\nNote that when you need to install more than one package, you can do so by passing a vector of package names to the install.packages() function. For example, in this case, you could use the following:\n\ninstall.packages(c(\"tidyverse\", \"fastDummmies\", \"haven\"))\n\nRemember that even if you’ve already installed the packages that you need in a previous session, you must load packages into memory each time you begin a new R session by passing the package names as arguments to the library() function. In this case:\n\n# load packages into memory\nlibrary(tidyverse)\nlibrary(fastDummies)\nlibrary(haven)\n\n\n\n4.2.2 Lesson Datasets\nIn this lesson, we’ll be working with a handful of datasets, which you should have download from the Workshop’s repository page. One of the datasets is a cross-national dataset published by the Quality of Government (QoG) Institute at the University of Gothenburg. The dataset contains information on a variety of political, social, and economic variables from the early 2020s; additional documentation is available on the QoG’s website. In addition, we’ll be working with several World Bank datasets downloaded from the World Development Indicators. You can download these datasets from the Workshop Repository.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transferring, Processing, and Wrangling Data</span>"
    ]
  },
  {
    "objectID": "session3.html#importing-datasets-into-r",
    "href": "session3.html#importing-datasets-into-r",
    "title": "4  Transferring, Processing, and Wrangling Data",
    "section": "4.3 Importing Datasets into R",
    "text": "4.3 Importing Datasets into R\nWe will begin this section by learning a few ways to read an individual dataset into memory in R, using the QoG dataset as an example. Then, we’ll explore how to read in multiple external datasets into R in an efficient manner through some basic functional programing techniques.\n\n4.3.1 Importing Individual Datasets\nBelow, we’ll learn how to import individual datasets into R from various sources. We’ll also explore how to handle data stored in different file formats.\n\n4.3.1.1 Reading in Local Files\nThough it’s not strictly necessary, it’s useful to begin by setting your working directory to the location on your computer where the data is stored. The easiest way to do this is to go to the R Studio menu: click Session, then click Set Working Directory, then click Choose Directory. We can also set the working directory programmatically using the setwd() function.\nWe can now pass the name of file and its extension in quotation marks to the read_csv() function (since the data we want to load is a CSV file). We’ll assign it to an object named qog (for “Quality of Government”):\n\n# reads in the workshop dataset (Persson and Tabellini cross-national dataset) by passing the file path as an argument to the \"read_csv\" and assigns it to a new object named \"qog\"\nqog&lt;-read_csv(\"data/quality_of_government/qog_bas_cs_jan25.csv\")\n\nRows: 194 Columns: 331\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): cname_qog, cname, ccodealp\ndbl (328): ccode_qog, ccodecow, ccode, ajr_settmort, atop_ally, atop_number,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nBy printing the name of the object, we can extract a preview of the dataset, along with some useful metadata:\n\n# prints contents of \"qog\" object to console\nqog\n\n# A tibble: 194 × 331\n   cname_qog      cname ccode_qog ccodecow ccodealp ccode ajr_settmort atop_ally\n   &lt;chr&gt;          &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n 1 Afghanistan    Afgh…         4      700 AFG          4         4.54         1\n 2 Albania        Alba…         8      339 ALB          8        NA            1\n 3 Algeria        Alge…        12      615 DZA         12         4.36         1\n 4 Andorra        Ando…        20      232 AND         20        NA            1\n 5 Angola         Ango…        24      540 AGO         24         5.63         1\n 6 Antigua and B… Anti…        28       58 ATG         28        NA            1\n 7 Azerbaijan     Azer…        31      373 AZE         31        NA            1\n 8 Argentina      Arge…        32      160 ARG         32         4.23         1\n 9 Australia      Aust…        36      900 AUS         36         2.15         1\n10 Austria        Aust…        40      305 AUT         40        NA            1\n# ℹ 184 more rows\n# ℹ 323 more variables: atop_number &lt;dbl&gt;, bci_bci &lt;dbl&gt;, bicc_gmi &lt;dbl&gt;,\n#   bmr_dem &lt;dbl&gt;, bmr_demdur &lt;dbl&gt;, bti_aar &lt;dbl&gt;, bti_acp &lt;dbl&gt;,\n#   bti_aod &lt;dbl&gt;, bti_cdi &lt;dbl&gt;, bti_ci &lt;dbl&gt;, bti_cps &lt;dbl&gt;, bti_cr &lt;dbl&gt;,\n#   bti_ds &lt;dbl&gt;, bti_eo &lt;dbl&gt;, bti_eos &lt;dbl&gt;, bti_ep &lt;dbl&gt;, bti_ffe &lt;dbl&gt;,\n#   bti_foe &lt;dbl&gt;, bti_ij &lt;dbl&gt;, bti_mes &lt;dbl&gt;, bti_muf &lt;dbl&gt;, bti_pdi &lt;dbl&gt;,\n#   bti_pp &lt;dbl&gt;, bti_prp &lt;dbl&gt;, bti_ps &lt;dbl&gt;, bti_rol &lt;dbl&gt;, bti_sdi &lt;dbl&gt;, …\n\n\nRecall, also, that we can view data frames in the R Studio data viewer by passing the name of the object to the View() function:\n\n# views \"qog\" in data viewer\nView(qog)\n\n\n\n\n\n\n\nNote that to keep things tractable within this document, the table printed above does not print all of the columns in the dataset, but the full data frame should appear in the Viewer when the corresponding object name is passed to the View() function.\n\n\n4.3.1.2 Reading in Data from an Online Source\nThe Quality of Government hosts its data online, and instead of reading the data into R from a downloaded local file, we could have read the data into R directly from the online source by using the appropriate URL. For example, the code below reads in the same QoG dataset directly from its website, and assigns the data to a new object named qog_direct:\n\n# Reads in cross-national CSV dataset directly from QoG website and assigns it to a new object named \"qog_direct\"\nqog_direct&lt;-read_csv(\"https://www.qogdata.pol.gu.se/data/qog_bas_cs_jan25.csv\")\n\nRows: 194 Columns: 331\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): cname_qog, cname, ccodealp\ndbl (328): ccode_qog, ccodecow, ccode, ajr_settmort, atop_ally, atop_number,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe can print qog_direct to the console to confirm that the data was successfully read in, and that its contents are identical to qog:\n\n# prints contents of qog_direct\nqog_direct\n\n# A tibble: 194 × 331\n   cname_qog      cname ccode_qog ccodecow ccodealp ccode ajr_settmort atop_ally\n   &lt;chr&gt;          &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n 1 Afghanistan    Afgh…         4      700 AFG          4         4.54         1\n 2 Albania        Alba…         8      339 ALB          8        NA            1\n 3 Algeria        Alge…        12      615 DZA         12         4.36         1\n 4 Andorra        Ando…        20      232 AND         20        NA            1\n 5 Angola         Ango…        24      540 AGO         24         5.63         1\n 6 Antigua and B… Anti…        28       58 ATG         28        NA            1\n 7 Azerbaijan     Azer…        31      373 AZE         31        NA            1\n 8 Argentina      Arge…        32      160 ARG         32         4.23         1\n 9 Australia      Aust…        36      900 AUS         36         2.15         1\n10 Austria        Aust…        40      305 AUT         40        NA            1\n# ℹ 184 more rows\n# ℹ 323 more variables: atop_number &lt;dbl&gt;, bci_bci &lt;dbl&gt;, bicc_gmi &lt;dbl&gt;,\n#   bmr_dem &lt;dbl&gt;, bmr_demdur &lt;dbl&gt;, bti_aar &lt;dbl&gt;, bti_acp &lt;dbl&gt;,\n#   bti_aod &lt;dbl&gt;, bti_cdi &lt;dbl&gt;, bti_ci &lt;dbl&gt;, bti_cps &lt;dbl&gt;, bti_cr &lt;dbl&gt;,\n#   bti_ds &lt;dbl&gt;, bti_eo &lt;dbl&gt;, bti_eos &lt;dbl&gt;, bti_ep &lt;dbl&gt;, bti_ffe &lt;dbl&gt;,\n#   bti_foe &lt;dbl&gt;, bti_ij &lt;dbl&gt;, bti_mes &lt;dbl&gt;, bti_muf &lt;dbl&gt;, bti_pdi &lt;dbl&gt;,\n#   bti_pp &lt;dbl&gt;, bti_prp &lt;dbl&gt;, bti_ps &lt;dbl&gt;, bti_rol &lt;dbl&gt;, bti_sdi &lt;dbl&gt;, …\n\n\n\n\n4.3.1.3 Reading in Data from Cloud Storage\nSometimes, the dataset you are working with won’t be available on a public website, and it may be more convenient to read the data in from a cloud storage account (i.e. Dropbox, OneDrive, Google Drive etc) than to download the data to your machine and read in a local file.\nThe specific steps required to read in a dataset from cloud storage depend on your provider, as well as the nature of the account (for example, additional steps or functions may be required to read in password protected or non-public files), and you may need to do a bit of research to determine the specific steps required in your case.\nIn general, though, the process tends to be fairly simple. For example, we’ve placed a copy of the QoG dataset on a publicly shared Dropbox page. In order to read this data from Dropbox directly into R, we simply change the “0” at the end of the Dropbox url into a “1”, and pass this modified URL to the read_csv() function. Below, we’ll read in the dataset from Dropbox, and assign it to a new object named qog_cloud:\n\n# reads dataset into R from Dropbox and assigns it to a new object named \"qog_cloud\"\nqog_cloud&lt;-read_csv(\"https://www.dropbox.com/scl/fi/xxd5otw869auq56fs4c9k/qog_bas_cs_jan25.csv?rlkey=8thev7gb5u1ffbtmhs2tutxxp&e=1&st=folhfq67&dl=1\")\n\nRows: 194 Columns: 331\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): cname_qog, cname, ccodealp\ndbl (328): ccode_qog, ccodecow, ccode, ajr_settmort, atop_ally, atop_number,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe can print out the contents of qog_cloud to the console to ensure that the data has been read in correctly:\n\n# prints contents of \"qog_cloud\" to the console\nqog_cloud\n\n# A tibble: 194 × 331\n   cname_qog      cname ccode_qog ccodecow ccodealp ccode ajr_settmort atop_ally\n   &lt;chr&gt;          &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n 1 Afghanistan    Afgh…         4      700 AFG          4         4.54         1\n 2 Albania        Alba…         8      339 ALB          8        NA            1\n 3 Algeria        Alge…        12      615 DZA         12         4.36         1\n 4 Andorra        Ando…        20      232 AND         20        NA            1\n 5 Angola         Ango…        24      540 AGO         24         5.63         1\n 6 Antigua and B… Anti…        28       58 ATG         28        NA            1\n 7 Azerbaijan     Azer…        31      373 AZE         31        NA            1\n 8 Argentina      Arge…        32      160 ARG         32         4.23         1\n 9 Australia      Aust…        36      900 AUS         36         2.15         1\n10 Austria        Aust…        40      305 AUT         40        NA            1\n# ℹ 184 more rows\n# ℹ 323 more variables: atop_number &lt;dbl&gt;, bci_bci &lt;dbl&gt;, bicc_gmi &lt;dbl&gt;,\n#   bmr_dem &lt;dbl&gt;, bmr_demdur &lt;dbl&gt;, bti_aar &lt;dbl&gt;, bti_acp &lt;dbl&gt;,\n#   bti_aod &lt;dbl&gt;, bti_cdi &lt;dbl&gt;, bti_ci &lt;dbl&gt;, bti_cps &lt;dbl&gt;, bti_cr &lt;dbl&gt;,\n#   bti_ds &lt;dbl&gt;, bti_eo &lt;dbl&gt;, bti_eos &lt;dbl&gt;, bti_ep &lt;dbl&gt;, bti_ffe &lt;dbl&gt;,\n#   bti_foe &lt;dbl&gt;, bti_ij &lt;dbl&gt;, bti_mes &lt;dbl&gt;, bti_muf &lt;dbl&gt;, bti_pdi &lt;dbl&gt;,\n#   bti_pp &lt;dbl&gt;, bti_prp &lt;dbl&gt;, bti_ps &lt;dbl&gt;, bti_rol &lt;dbl&gt;, bti_sdi &lt;dbl&gt;, …\n\n\n\n\n4.3.1.4 Reading in data saved in different file formats\nThe QoG dataset that we read in from different sources in the subsections above was saved as a CSV file; though this is a widely-used and flexible file format, it’s likely that you’ll also have to read in datasets in file formats other than CSV (for example, .xlsx, or Stata, SPSS, or SAS files). There are useful tidyverse packages that can help with importing datasets stored in a variety of such file formats. For example, the readxl package offers handy functions for reading in Excel files (i.e. .xls and .xlsx files), while the haven package provides functions to read in Stata, SPSS, or SAS files.\nTo get a sense of how to read in a non-CSV file, let’s quickly explore how to use the haven package’s read_dta() function to read a Stata file into R as a data frame. As part of the data package you downloaded for this workshop, there is a Stata version of the QoG dataset (“qog_bas_cs_jan25.dta”). Below, we’ll read this version of the dataset into R from our local directory by passing the file path and file name as an argument to the read_dta() function and assigning it to a new object named qog_stata:\n\n# reads in stata version of QoG crossnational dataset from local drive using haven's \"read_dta\" function and assigns the data to a new object named \"qog_stata\"\nqog_stata &lt;- read_dta(\"data/quality_of_government/qog_bas_cs_jan25.dta\")\n\nNow, let’s print the contents of qog_stata to the console, and confirm that the Stata dataset was successfully read in as an R data frame/tibble:\n\n# prints contents of \"qog_stata\"\nqog_stata\n\n# A tibble: 194 × 331\n   cname_qog      cname ccode_qog ccodecow ccodealp ccode ajr_settmort atop_ally\n   &lt;chr&gt;          &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n 1 Afghanistan    Afgh…         4      700 AFG          4         4.54         1\n 2 Albania        Alba…         8      339 ALB          8        NA            1\n 3 Algeria        Alge…        12      615 DZA         12         4.36         1\n 4 Andorra        Ando…        20      232 AND         20        NA            1\n 5 Angola         Ango…        24      540 AGO         24         5.63         1\n 6 Antigua and B… Anti…        28       58 ATG         28        NA            1\n 7 Azerbaijan     Azer…        31      373 AZE         31        NA            1\n 8 Argentina      Arge…        32      160 ARG         32         4.23         1\n 9 Australia      Aust…        36      900 AUS         36         2.15         1\n10 Austria        Aust…        40      305 AUT         40        NA            1\n# ℹ 184 more rows\n# ℹ 323 more variables: atop_number &lt;dbl&gt;, bci_bci &lt;dbl&gt;, bicc_gmi &lt;dbl&gt;,\n#   bmr_dem &lt;dbl&gt;, bmr_demdur &lt;dbl&gt;, bti_aar &lt;dbl&gt;, bti_acp &lt;dbl&gt;,\n#   bti_aod &lt;dbl&gt;, bti_cdi &lt;dbl&gt;, bti_ci &lt;dbl&gt;, bti_cps &lt;dbl&gt;, bti_cr &lt;dbl&gt;,\n#   bti_ds &lt;dbl&gt;, bti_eo &lt;dbl&gt;, bti_eos &lt;dbl&gt;, bti_ep &lt;dbl&gt;, bti_ffe &lt;dbl&gt;,\n#   bti_foe &lt;dbl&gt;, bti_ij &lt;dbl&gt;, bti_mes &lt;dbl&gt;, bti_muf &lt;dbl&gt;, bti_pdi &lt;dbl&gt;,\n#   bti_pp &lt;dbl&gt;, bti_prp &lt;dbl&gt;, bti_ps &lt;dbl&gt;, bti_rol &lt;dbl&gt;, bti_sdi &lt;dbl&gt;, …\n\n\n\n\n\n4.3.2 Importing Multiple Datasets\nSometimes, you may be working with more than one dataset, in which case it could make sense to iteratively load multiple datasets into memory. In such cases, it is typically useful to read the datasets directly into a list.\nWithin the “world_bank” subdirectory in the “data” directory, there are four CSV files downloaded from the World Bank’s development indicators site:\n\nwdi_debt2019.csv (country level World Bank data on debt as a share of GDP in 2019)\nwdi_fdi2019.csv (country level World Bank data on foreign direct investment as a share of GDP in 2019)\nwdi_trade2019.csv (country level World Bank data on trade as a share of GDP in 2019)\nwdi_urban2019.csv (country level World Bank data on the urban population as a share of the overall population in 2019).\n\nThe first step we must take to iteratively read these files into a list is to make a character vector of the file names we want to read in. The code below uses the list.files() function to extract the file names of the files in the “data/world_bank” directory to a character vector, which we’ll assign to an object named “worldbank_filenames”:\n\n# prints the names of the files we want to read in and assigns the vector of strings to a new object named \"worldbank_filenames\" \nworldbank_filenames&lt;-list.files(\"data/world_bank\")\n\nLet’s confirm that the file names have been written correctly:\n\n# prints \"worldbank_filenames\"\nworldbank_filenames\n\n[1] \"wdi_debt2019.csv\"  \"wdi_fdi2019.csv\"   \"wdi_trade2019.csv\"\n[4] \"wdi_urban2019.csv\"\n\n\nNow, we’ll use the map() function to iteratively pass the file names in the worldbank_filenames vector to the read_csv() function, and deposit the imported files into a list named world_bank_list:\n\n# iteratively passes file names in \"worldbank_filenames\" to the \"read_csv\" function, and deposits imported world bank files into a list that is assigned to an object named \"world_bank_list\"; assumes the working directory is the one with the world bank files\nsetwd(\"data/world_bank\")\nworld_bank_list &lt;- map(worldbank_filenames, read_csv)\n\nRows: 271 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): Country Name, Country Code, Series Name, Series Code, 2019 [YR2019]\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 271 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): Country Name, Country Code, Series Name, Series Code, 2019 [YR2019]\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 271 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): Country Name, Country Code, Series Name, Series Code, 2019 [YR2019]\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 271 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): Country Name, Country Code, Series Name, Series Code, 2019 [YR2019]\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNow, let’s go ahead print the contents of world_bank_list:\n\n# prints contents of \"world_bank_list\"\nworld_bank_list\n\n[[1]]\n# A tibble: 271 × 5\n   `Country Name`     `Country Code` `Series Name` `Series Code` `2019 [YR2019]`\n   &lt;chr&gt;              &lt;chr&gt;          &lt;chr&gt;         &lt;chr&gt;         &lt;chr&gt;          \n 1 Afghanistan        AFG            Central gove… GC.DOD.TOTL.… ..             \n 2 Albania            ALB            Central gove… GC.DOD.TOTL.… 75.69848824949…\n 3 Algeria            DZA            Central gove… GC.DOD.TOTL.… ..             \n 4 American Samoa     ASM            Central gove… GC.DOD.TOTL.… ..             \n 5 Andorra            AND            Central gove… GC.DOD.TOTL.… ..             \n 6 Angola             AGO            Central gove… GC.DOD.TOTL.… ..             \n 7 Antigua and Barbu… ATG            Central gove… GC.DOD.TOTL.… ..             \n 8 Argentina          ARG            Central gove… GC.DOD.TOTL.… ..             \n 9 Armenia            ARM            Central gove… GC.DOD.TOTL.… 50.02842068637…\n10 Aruba              ABW            Central gove… GC.DOD.TOTL.… ..             \n# ℹ 261 more rows\n\n[[2]]\n# A tibble: 271 × 5\n   `Country Name`     `Country Code` `Series Name` `Series Code` `2019 [YR2019]`\n   &lt;chr&gt;              &lt;chr&gt;          &lt;chr&gt;         &lt;chr&gt;         &lt;chr&gt;          \n 1 Afghanistan        AFG            Foreign dire… BX.KLT.DINV.… 0.124495985791…\n 2 Albania            ALB            Foreign dire… BX.KLT.DINV.… 7.797920483865…\n 3 Algeria            DZA            Foreign dire… BX.KLT.DINV.… 0.804144058246…\n 4 American Samoa     ASM            Foreign dire… BX.KLT.DINV.… ..             \n 5 Andorra            AND            Foreign dire… BX.KLT.DINV.… ..             \n 6 Angola             AGO            Foreign dire… BX.KLT.DINV.… -5.78081314444…\n 7 Antigua and Barbu… ATG            Foreign dire… BX.KLT.DINV.… 7.433324076307…\n 8 Argentina          ARG            Foreign dire… BX.KLT.DINV.… 1.485006875706…\n 9 Armenia            ARM            Foreign dire… BX.KLT.DINV.… 0.736361516844…\n10 Aruba              ABW            Foreign dire… BX.KLT.DINV.… -2.21528256776…\n# ℹ 261 more rows\n\n[[3]]\n# A tibble: 271 × 5\n   `Country Name`     `Country Code` `Series Name` `Series Code` `2019 [YR2019]`\n   &lt;chr&gt;              &lt;chr&gt;          &lt;chr&gt;         &lt;chr&gt;         &lt;chr&gt;          \n 1 Afghanistan        AFG            Trade (% of … NE.TRD.GNFS.… ..             \n 2 Albania            ALB            Trade (% of … NE.TRD.GNFS.… 76.27919464957…\n 3 Algeria            DZA            Trade (% of … NE.TRD.GNFS.… 51.80973844157…\n 4 American Samoa     ASM            Trade (% of … NE.TRD.GNFS.… 156.5687789799…\n 5 Andorra            AND            Trade (% of … NE.TRD.GNFS.… ..             \n 6 Angola             AGO            Trade (% of … NE.TRD.GNFS.… 57.82953811830…\n 7 Antigua and Barbu… ATG            Trade (% of … NE.TRD.GNFS.… 137.6251757558…\n 8 Argentina          ARG            Trade (% of … NE.TRD.GNFS.… 32.63061504584…\n 9 Armenia            ARM            Trade (% of … NE.TRD.GNFS.… 96.11415412887…\n10 Aruba              ABW            Trade (% of … NE.TRD.GNFS.… 145.3435727352…\n# ℹ 261 more rows\n\n[[4]]\n# A tibble: 271 × 5\n   `Country Name`     `Country Code` `Series Name` `Series Code` `2019 [YR2019]`\n   &lt;chr&gt;              &lt;chr&gt;          &lt;chr&gt;         &lt;chr&gt;         &lt;chr&gt;          \n 1 Afghanistan        AFG            Urban popula… SP.URB.TOTL.… 25.754         \n 2 Albania            ALB            Urban popula… SP.URB.TOTL.… 61.229         \n 3 Algeria            DZA            Urban popula… SP.URB.TOTL.… 73.189         \n 4 American Samoa     ASM            Urban popula… SP.URB.TOTL.… 87.147         \n 5 Andorra            AND            Urban popula… SP.URB.TOTL.… 87.984         \n 6 Angola             AGO            Urban popula… SP.URB.TOTL.… 66.177         \n 7 Antigua and Barbu… ATG            Urban popula… SP.URB.TOTL.… 24.506         \n 8 Argentina          ARG            Urban popula… SP.URB.TOTL.… 91.991         \n 9 Armenia            ARM            Urban popula… SP.URB.TOTL.… 63.219         \n10 Aruba              ABW            Urban popula… SP.URB.TOTL.… 43.546         \n# ℹ 261 more rows\n\n\nIt could be useful to label the list elements of world_bank_list. For labels, it would make sense to use the file names in worldbank_filenames, without the “.csv” extension. Below, we use the str_remove() function to remove the “.csv” extension from the file names in worldbank_filenames and assign the result to a new object named worldbank_filenames_base:\n\n# removes CSV extension from \"worldbank_filenames\"\nworldbank_filenames_base &lt;- str_remove(worldbank_filenames, \".csv\")\n\nNow, let’s use the names() argument to assign the labels in worldbank_filenames_base to the elements in world_bank_list:\n\n# assigns names to datasets in \"world_bank_list\"\nnames(world_bank_list) &lt;- worldbank_filenames_base\n\nNow that the file names are assigned, we can extract list elements by their labels. Below, for example, we extract the FDI dataset from world_bank_list using its label:\n\n# extracts fdi dataset from \"world_bank_list\" by assigned label\nworld_bank_list[[\"wdi_fdi2019\"]]\n\n# A tibble: 271 × 5\n   `Country Name`     `Country Code` `Series Name` `Series Code` `2019 [YR2019]`\n   &lt;chr&gt;              &lt;chr&gt;          &lt;chr&gt;         &lt;chr&gt;         &lt;chr&gt;          \n 1 Afghanistan        AFG            Foreign dire… BX.KLT.DINV.… 0.124495985791…\n 2 Albania            ALB            Foreign dire… BX.KLT.DINV.… 7.797920483865…\n 3 Algeria            DZA            Foreign dire… BX.KLT.DINV.… 0.804144058246…\n 4 American Samoa     ASM            Foreign dire… BX.KLT.DINV.… ..             \n 5 Andorra            AND            Foreign dire… BX.KLT.DINV.… ..             \n 6 Angola             AGO            Foreign dire… BX.KLT.DINV.… -5.78081314444…\n 7 Antigua and Barbu… ATG            Foreign dire… BX.KLT.DINV.… 7.433324076307…\n 8 Argentina          ARG            Foreign dire… BX.KLT.DINV.… 1.485006875706…\n 9 Armenia            ARM            Foreign dire… BX.KLT.DINV.… 0.736361516844…\n10 Aruba              ABW            Foreign dire… BX.KLT.DINV.… -2.21528256776…\n# ℹ 261 more rows",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transferring, Processing, and Wrangling Data</span>"
    ]
  },
  {
    "objectID": "session3.html#processing-and-wrangling-a-single-dataset",
    "href": "session3.html#processing-and-wrangling-a-single-dataset",
    "title": "4  Transferring, Processing, and Wrangling Data",
    "section": "4.4 Processing and Wrangling a Single Dataset",
    "text": "4.4 Processing and Wrangling a Single Dataset\nOnce we’ve read in our dataset(s) of interest, we typically need to carry out a variety of processing and wrangling tasks to prepare to data for analysis and visualization. In this section, we’ll consider a variety of useful functions (most of them from tidyverse packages such as dplyr) that can help with a variety of these data preparation tasks.\nWe’ll start by making a copy of the qog object, by assigning it to a new object named qog_copy; we’ll work with qog_copy instead of the original qog object, to ensure that we can always revert to the original data when needed. Keeping a “clean” version of the dataset of interest, and carrying out data processing and analysis tasks on a copy of this dataset, is good data management practice.\n\n# makes a copy of \"qog\", called \"qog_copy\" that we can use for processing; keeps the original data frame, \"qog\" untouched\nqog_copy&lt;-qog\n\n\n4.4.1 Introducing the %&gt;% (“pipe”) operator\nOne of the most useful features of the tidyverse is the %&gt;% operator (pronounced “pipe”) which helps chain together different functions to form a clear and explicit data processing and analysis pipeline. To illustrate how a pipe works, let’s first consider a simple data processing operation that does not use a pipe. In particular, we will use the select() function from the dplyr package to select a few columns from qog_copy; this dataset has over 300 variables, so it would make sense to create a more tractable dataset that extracts the specific columns/variables we’re interested in. Let’s say, for example, that we want to select the “cname_qog”, “cname”, “ccodealp”, “undp_hdi”, and “wdi_expedu” variables from qog_copy. We can do so by passing the name of the data object containing the columns we want to select, along with the names of the desired columns, as arguments to the select() function. Below, we’ll select these columns from qog_copy and assign the modified data frame to a new object named qog_copy_select_initial:\n\n# selects columns/variables from \"qog_copy\" and assigns the \n# modified data frame to a new object named \"qog_copy_select\"\nqog_copy_select_initial &lt;- select(qog_copy, cname_qog, cname, ccodealp, undp_hdi, wdi_expedu)\n\nLet’s view qog_copy_select_initial in the data viewer:\n\n# Views \"qog_copy_select_initial\" in the data viewer\nView(qog_copy_select_initial)\n\n\n\n\n\n\n\nNow that we’ve seen how to use the select() function using traditional syntax, let’s see how we can carry out the same operation with a pipe operator. In particular, the piping syntax looks something like this:\n\n# selects columns/variables from \"qog_copy\" using the \n# pipe syntax and assigns the modified data frame \n# to a new object named \"qog_copy_select\"\nqog_copy_select_pipe &lt;- \n  qog_copy %&gt;% \n    select(cname_qog, cname, ccodealp, undp_hdi, wdi_expedu)\n\nNote that the pipe operator %&gt;% comes immediately after qog_copy and immediately before we call the select() function. In essence, the pipe operator takes the contents to its left, and then uses these contents as an input to the code on its right. Above, the pipe takes the contents of qog_copy on its left, and then feeds this data into the select() function on the right, and returns a modified data frame which is assigned to qog_copy_select_pipe. We can pass qog_copy_select_pipe into the data viewer to confirm that the operation worked as expected:\n\n# views \"qog_copy_select_pipe\" in data viewer\nView(qog_copy_select_pipe)\n\n\n\n\n\n\n\nWe can already see that the pipe makes our code slightly more readable even when performing a simple operation, but the pipe’s usefulness for the task of writing concise and readable code becomes even more visible when performing more complex operations that involve several different data processing functions.\nFor example, let’s say that in addition to selecting the columns above, we also want to subset the dataset to include only countries for which the “undp_hdi” variable is higher than 0.8. We can subset datasets based on such conditions using the filter() function. Below, we’ll take qog_copy_select_initial and subset this dataset to meet the undp_hdi&gt;0.8 condition, and assign the final version of our processed dataset to a new object named qog_final_processed:\n\n# subsets \"qog_copy_select_initial\" using the \"filter()\" function to include only observations with undp_hdi&gt;0.8, and deposits the modified dataset into a new object named \"qog_final_processed\"\nqog_final_processed &lt;- filter(qog_copy_select_initial, undp_hdi&gt;0.8)\n\nNow, let’s view qog_final_processed in the data viewer and confirm that it only includes the selected variables and is appropriately subsetted according to the specified condition:\n\nView(qog_final_processed)\n\n\n\n\n\n\n\nNotice that using conventional notation (i.e. notation without a pipe), we arrived at our final processed dataset in two steps; first, we had to select columns using the select() function, and then we had to take the resulting object and call the filter() function to subset the data based on the “undp_hdi” variable. This process can by a little clunky, and the pipe operator helps to streamline it, making for more efficient and readable code. In short, when we use pipe (rather than conventional) notation, we can get from qog_copy to the final processed dataset with just the following:\n\n# uses pipe notation to select columns and filter according to a condition\nqog_copy %&gt;% \n  select(cname_qog, cname, ccodealp, undp_hdi, wdi_expedu) %&gt;% \n  filter(undp_hdi&gt;0.8)\n\n# A tibble: 65 × 5\n   cname_qog           cname               ccodealp undp_hdi wdi_expedu\n   &lt;chr&gt;               &lt;chr&gt;               &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n 1 Andorra             Andorra             AND         0.855       2.58\n 2 Antigua and Barbuda Antigua and Barbuda ATG         0.819       2.57\n 3 Argentina           Argentina           ARG         0.844       4.64\n 4 Australia           Australia           AUS         0.949       5.33\n 5 Austria             Austria             AUT         0.92        5.49\n 6 Bahrain             Bahrain             BHR         0.884       2.22\n 7 Barbados            Barbados            BRB         0.803       4.86\n 8 Belgium             Belgium             BEL         0.938       6.36\n 9 Brunei              Brunei Darussalam   BRN         0.824      NA   \n10 Belarus             Belarus             BLR         0.801       4.61\n# ℹ 55 more rows\n\n\nThis code takes the qog_copy dataset, and then feeds it into the select() function; the output of the select() function is then fed into the filter() function, which then returns a final dataset equivalent to qog_final_processed. Given the readability and conciseness of pipe notation, we will use it extensively in our exploration of data processing and wrangling.\nBelow, we’ll explore the select() and filter() functions (along with other data processing functions) at greater length; our main purpose in this sub-section was to motivate the utility of the %&gt;% operator in helping to create complex data processing pipelines with intuitive and readable code.\n\n\n4.4.2 Selecting and Deleting Variables\nIn this section, we’ll explore the select() function at greater length, and use it to select some key variables of interest from qog_copy; this will allow us to subsequently work with a more tractable dataset.\nIn particular, let’s select the following variables from qog_copy (additional information about the variables is available in the Quality of Government Basic Dataset Codebook:\n\n“cname_qog”: Country name as standardized by QoG\n“cname”: Country name based on the ISO standard\n“ccodealp”: 3-digit ISO country code\n“undp_hdi”: Human development index\n“wdi_expedu”: Government expenditure on education as a percentage of GDP\n“wdi_acel”: Percentage of population with access to electricity\n“wdi_area”: Land area in sq km\n“wdi_taxrev”: Tax revenue as a percentage of GDP\n“wdi_expmil”: Military expenditure as a percentage of GDP\n“wdi_fdiin”: Foreign direct investment (FDI) inflows as a share of GDP\n“wdi_trade”: Foreign trade as a percentage of GDP\n“cbie_index”: Central bank independence index\n“ht_region”: World region of the country\n“wbgi_rle”: Rule of law index\n“bmr_dem”: Dichotomous democracy measure\n“atop_ally”: Member of a military alliance\n“gol_est”: Electoral system (majoritarian/proportional/mixed)\n“mad_gdppc”: Real GDP per capita in 2018 (2011 dollars)\n“mad_gdppc1900”: Real GDP per capita in 1900 (2011 dollars)\n“bci_bci”: Bayesian Corruption Indicator\n“lis_gini”: Gini coefficient\n“top_top1_income_share”: Income share of the population’s top 1%\n“wdi_wip”: Percentage of lower house or single house parliamentary seats held by women\n\nBelow, we select these variables by passing qog_copy to the select() function via a %&gt;%, and then specify the columns we want to select as arguments to the select() function; we assign the resulting selection to a new object named qog_copy_selection:\n\n# selects specific variables from \"qog_copy\" and assigns the selection to a new object named \"qog_copy_selection\"\nqog_copy_selection &lt;- qog_copy %&gt;% \n                        select(cname_qog, \n                               cname, \n                               ccodealp, \n                               undp_hdi, \n                               wdi_expedu,\n                               wdi_acel,\n                               wdi_area,\n                               wdi_taxrev,\n                               wdi_expmil,\n                               wdi_fdiin,\n                               wdi_trade,\n                               cbie_index,\n                               ht_region,\n                               wbgi_rle,\n                               bmr_dem,\n                               atop_ally,\n                               gol_est,\n                               mad_gdppc,\n                               mad_gdppc1900,\n                               bci_bci,\n                               lis_gini,\n                               top_top1_income_share,\n                               wdi_wip)\n\nWhen we view qog_copy_selection in the R Studio data viewer, it looks something like this:\n\n# Views \"qog_copy_selection\" in the data viewer\nView(qog_copy_selection)\n\n\n\n\n\n\n\nSometimes, it could make more sense to directly delete columns, instead of deciding on which ones to keep or select. For example, the code below deletes the “cname” variable from qog_copy_selection by passing it to the select() column with a “-” in front of it:\n\n# removes \"cname\" column from \"qog_copy_selection\"\nqog_copy_selection %&gt;% select(-cname)\n\n# A tibble: 194 × 22\n   cname_qog           ccodealp undp_hdi wdi_expedu wdi_acel wdi_area wdi_taxrev\n   &lt;chr&gt;               &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1 Afghanistan         AFG         0.473      NA        97.7   652230      NA   \n 2 Albania             ALB         0.785       3.02    100      27400      18.2 \n 3 Algeria             DZA         0.74        5.51     99.8  2381741      NA   \n 4 Andorra             AND         0.855       2.58    100        470      NA   \n 5 Angola              AGO         0.59        2.30     48.2  1246700      10.1 \n 6 Antigua and Barbuda ATG         0.819       2.57    100        440      NA   \n 7 Azerbaijan          AZE         0.738       3.70    100      82650      13.4 \n 8 Argentina           ARG         0.844       4.64    100    2736690       8.79\n 9 Australia           AUS         0.949       5.33    100    7692020      23.0 \n10 Austria             AUT         0.92        5.49    100      82520      25.9 \n# ℹ 184 more rows\n# ℹ 15 more variables: wdi_expmil &lt;dbl&gt;, wdi_fdiin &lt;dbl&gt;, wdi_trade &lt;dbl&gt;,\n#   cbie_index &lt;dbl&gt;, ht_region &lt;dbl&gt;, wbgi_rle &lt;dbl&gt;, bmr_dem &lt;dbl&gt;,\n#   atop_ally &lt;dbl&gt;, gol_est &lt;dbl&gt;, mad_gdppc &lt;dbl&gt;, mad_gdppc1900 &lt;dbl&gt;,\n#   bci_bci &lt;dbl&gt;, lis_gini &lt;dbl&gt;, top_top1_income_share &lt;dbl&gt;, wdi_wip &lt;dbl&gt;\n\n\nNote that the “cname” column is not permanently deleted since we didn’t assign the code back to qog_copy_selection (i.e. with qog_copy_selection &lt;- qog_copy_selection %&gt;% select(-cname).) We can confirm this by reprinting qog_copy_selection and noting that “cname” is still in the data frame:\n\n# prints contents of \"qog_copy_selection\"\nqog_copy_selection\n\n# A tibble: 194 × 23\n   cname_qog     cname ccodealp undp_hdi wdi_expedu wdi_acel wdi_area wdi_taxrev\n   &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1 Afghanistan   Afgh… AFG         0.473      NA        97.7   652230      NA   \n 2 Albania       Alba… ALB         0.785       3.02    100      27400      18.2 \n 3 Algeria       Alge… DZA         0.74        5.51     99.8  2381741      NA   \n 4 Andorra       Ando… AND         0.855       2.58    100        470      NA   \n 5 Angola        Ango… AGO         0.59        2.30     48.2  1246700      10.1 \n 6 Antigua and … Anti… ATG         0.819       2.57    100        440      NA   \n 7 Azerbaijan    Azer… AZE         0.738       3.70    100      82650      13.4 \n 8 Argentina     Arge… ARG         0.844       4.64    100    2736690       8.79\n 9 Australia     Aust… AUS         0.949       5.33    100    7692020      23.0 \n10 Austria       Aust… AUT         0.92        5.49    100      82520      25.9 \n# ℹ 184 more rows\n# ℹ 15 more variables: wdi_expmil &lt;dbl&gt;, wdi_fdiin &lt;dbl&gt;, wdi_trade &lt;dbl&gt;,\n#   cbie_index &lt;dbl&gt;, ht_region &lt;dbl&gt;, wbgi_rle &lt;dbl&gt;, bmr_dem &lt;dbl&gt;,\n#   atop_ally &lt;dbl&gt;, gol_est &lt;dbl&gt;, mad_gdppc &lt;dbl&gt;, mad_gdppc1900 &lt;dbl&gt;,\n#   bci_bci &lt;dbl&gt;, lis_gini &lt;dbl&gt;, top_top1_income_share &lt;dbl&gt;, wdi_wip &lt;dbl&gt;\n\n\nIf we want to delete multiple columns, we can pass a vector containing the names of the columns to be deleted to the select() function, preceded by a minus sign. For example, if we want to delete “cname”, “undp_hdi”, and “wdi_acel” from qog_copy_selection we can do so with the following:\n\n# deletes \"cname\", \"undp_hdi\", and \"wdi_acel\" from \"qog_copy_selection\"\nqog_copy_selection %&gt;% select(-c(cname, undp_hdi, wdi_acel))\n\n# A tibble: 194 × 20\n   cname_qog        ccodealp wdi_expedu wdi_area wdi_taxrev wdi_expmil wdi_fdiin\n   &lt;chr&gt;            &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n 1 Afghanistan      AFG           NA      652230      NA         1.83      0.144\n 2 Albania          ALB            3.02    27400      18.2       1.22      6.80 \n 3 Algeria          DZA            5.51  2381741      NA         5.59      0.467\n 4 Andorra          AND            2.58      470      NA        NA        NA    \n 5 Angola           AGO            2.30  1246700      10.1       1.29     -6.55 \n 6 Antigua and Bar… ATG            2.57      440      NA        NA        18.1  \n 7 Azerbaijan       AZE            3.70    82650      13.4       5.27     -3.11 \n 8 Argentina        ARG            4.64  2736690       8.79      0.631     1.36 \n 9 Australia        AUS            5.33  7692020      23.0       1.99      1.78 \n10 Austria          AUT            5.49    82520      25.9       0.874     3.71 \n# ℹ 184 more rows\n# ℹ 13 more variables: wdi_trade &lt;dbl&gt;, cbie_index &lt;dbl&gt;, ht_region &lt;dbl&gt;,\n#   wbgi_rle &lt;dbl&gt;, bmr_dem &lt;dbl&gt;, atop_ally &lt;dbl&gt;, gol_est &lt;dbl&gt;,\n#   mad_gdppc &lt;dbl&gt;, mad_gdppc1900 &lt;dbl&gt;, bci_bci &lt;dbl&gt;, lis_gini &lt;dbl&gt;,\n#   top_top1_income_share &lt;dbl&gt;, wdi_wip &lt;dbl&gt;\n\n\n\n\n4.4.3 Rearranging Columns\nWe can change the order of the columns in a dataset using the relocate() function. For example, the code below uses the relocate() function to shift the “ccdoealp” column to the front of the qog_copy_selection data frame:\n\n# moves \"ccdoealp\" to front of \"qog_copy_selection\" dataset\nqog_copy_selection %&gt;% relocate(ccodealp)\n\n# A tibble: 194 × 23\n   ccodealp cname_qog     cname undp_hdi wdi_expedu wdi_acel wdi_area wdi_taxrev\n   &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1 AFG      Afghanistan   Afgh…    0.473      NA        97.7   652230      NA   \n 2 ALB      Albania       Alba…    0.785       3.02    100      27400      18.2 \n 3 DZA      Algeria       Alge…    0.74        5.51     99.8  2381741      NA   \n 4 AND      Andorra       Ando…    0.855       2.58    100        470      NA   \n 5 AGO      Angola        Ango…    0.59        2.30     48.2  1246700      10.1 \n 6 ATG      Antigua and … Anti…    0.819       2.57    100        440      NA   \n 7 AZE      Azerbaijan    Azer…    0.738       3.70    100      82650      13.4 \n 8 ARG      Argentina     Arge…    0.844       4.64    100    2736690       8.79\n 9 AUS      Australia     Aust…    0.949       5.33    100    7692020      23.0 \n10 AUT      Austria       Aust…    0.92        5.49    100      82520      25.9 \n# ℹ 184 more rows\n# ℹ 15 more variables: wdi_expmil &lt;dbl&gt;, wdi_fdiin &lt;dbl&gt;, wdi_trade &lt;dbl&gt;,\n#   cbie_index &lt;dbl&gt;, ht_region &lt;dbl&gt;, wbgi_rle &lt;dbl&gt;, bmr_dem &lt;dbl&gt;,\n#   atop_ally &lt;dbl&gt;, gol_est &lt;dbl&gt;, mad_gdppc &lt;dbl&gt;, mad_gdppc1900 &lt;dbl&gt;,\n#   bci_bci &lt;dbl&gt;, lis_gini &lt;dbl&gt;, top_top1_income_share &lt;dbl&gt;, wdi_wip &lt;dbl&gt;\n\n\nWe can specify more than one argument to the relocate function. For example, in the code below, passing the “ccodealp”, “wdi_acel”, “wdi_expmil”, and “wdi_wip” variables/columns to the relocate() function will make “ccodealp” the first column, “wdi_acel” the second column, “wdi_expmil” the third column, and “wdi_wip” the fourth column. Below, we specify this order, and assign the result back to qog_copy_selection:\n\n# sets the order for the first four columns of \"qog_copy_selection\" and assigns the result back to \"qog_copy_selection\"\nqog_copy_selection &lt;- qog_copy_selection %&gt;% \n                        relocate(ccodealp, wdi_acel, wdi_expmil, wdi_wip)\n\nNow, let’s print the contents of “qog_copy_selection” to the console and confirm the change has been made:\n\n# prints contents of updated \"qog_copy_selection\" object\nqog_copy_selection\n\n# A tibble: 194 × 23\n   ccodealp wdi_acel wdi_expmil wdi_wip cname_qog      cname undp_hdi wdi_expedu\n   &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1 AFG          97.7      1.83    27.0  Afghanistan    Afgh…    0.473      NA   \n 2 ALB         100        1.22    35.7  Albania        Alba…    0.785       3.02\n 3 DZA          99.8      5.59     8.11 Algeria        Alge…    0.74        5.51\n 4 AND         100       NA       46.4  Andorra        Ando…    0.855       2.58\n 5 AGO          48.2      1.29    29.5  Angola         Ango…    0.59        2.30\n 6 ATG         100       NA       11.1  Antigua and B… Anti…    0.819       2.57\n 7 AZE         100        5.27    18.2  Azerbaijan     Azer…    0.738       3.70\n 8 ARG         100        0.631   44.7  Argentina      Arge…    0.844       4.64\n 9 AUS         100        1.99    31.1  Australia      Aust…    0.949       5.33\n10 AUT         100        0.874   40.4  Austria        Aust…    0.92        5.49\n# ℹ 184 more rows\n# ℹ 15 more variables: wdi_area &lt;dbl&gt;, wdi_taxrev &lt;dbl&gt;, wdi_fdiin &lt;dbl&gt;,\n#   wdi_trade &lt;dbl&gt;, cbie_index &lt;dbl&gt;, ht_region &lt;dbl&gt;, wbgi_rle &lt;dbl&gt;,\n#   bmr_dem &lt;dbl&gt;, atop_ally &lt;dbl&gt;, gol_est &lt;dbl&gt;, mad_gdppc &lt;dbl&gt;,\n#   mad_gdppc1900 &lt;dbl&gt;, bci_bci &lt;dbl&gt;, lis_gini &lt;dbl&gt;,\n#   top_top1_income_share &lt;dbl&gt;\n\n\n\n\n4.4.4 Renaming Variables\nIn order to rename variables, we can use the rename() function; the argument to this function takes the form new_name=old_name. The code below renames the existing “ccodealp” variable in the qog_copy_selection data frame to “iso3” using the %&gt;% operator to pass\n\n# renames \"ccodealp\" variable in \"qog_copy_selection\" to \"iso3\"\nqog_copy_selection %&gt;% \n  rename(iso3=ccodealp)\n\n# A tibble: 194 × 23\n   iso3  wdi_acel wdi_expmil wdi_wip cname_qog         cname undp_hdi wdi_expedu\n   &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1 AFG       97.7      1.83    27.0  Afghanistan       Afgh…    0.473      NA   \n 2 ALB      100        1.22    35.7  Albania           Alba…    0.785       3.02\n 3 DZA       99.8      5.59     8.11 Algeria           Alge…    0.74        5.51\n 4 AND      100       NA       46.4  Andorra           Ando…    0.855       2.58\n 5 AGO       48.2      1.29    29.5  Angola            Ango…    0.59        2.30\n 6 ATG      100       NA       11.1  Antigua and Barb… Anti…    0.819       2.57\n 7 AZE      100        5.27    18.2  Azerbaijan        Azer…    0.738       3.70\n 8 ARG      100        0.631   44.7  Argentina         Arge…    0.844       4.64\n 9 AUS      100        1.99    31.1  Australia         Aust…    0.949       5.33\n10 AUT      100        0.874   40.4  Austria           Aust…    0.92        5.49\n# ℹ 184 more rows\n# ℹ 15 more variables: wdi_area &lt;dbl&gt;, wdi_taxrev &lt;dbl&gt;, wdi_fdiin &lt;dbl&gt;,\n#   wdi_trade &lt;dbl&gt;, cbie_index &lt;dbl&gt;, ht_region &lt;dbl&gt;, wbgi_rle &lt;dbl&gt;,\n#   bmr_dem &lt;dbl&gt;, atop_ally &lt;dbl&gt;, gol_est &lt;dbl&gt;, mad_gdppc &lt;dbl&gt;,\n#   mad_gdppc1900 &lt;dbl&gt;, bci_bci &lt;dbl&gt;, lis_gini &lt;dbl&gt;,\n#   top_top1_income_share &lt;dbl&gt;\n\n\nNote the “ccodealp” variable was changed to “iso3”. If we want to change the name of more than one variable, the rename() function can take multiple arguments, separated by a comma. For example, the code below changes “undp_hdi” to “hdi” and “wdi_area” to “wdi_area_sqkm”:\n\n# renames \"undp_hdi\" variable to \"hdi\", and \"wdi_area\" to \"wdi_area_sqkm\" in \"qog_copy_selection\" data frame\nqog_copy_selection %&gt;% \n  rename(hdi=undp_hdi,\n         wdi_area_sqkm=wdi_area)\n\n# A tibble: 194 × 23\n   ccodealp wdi_acel wdi_expmil wdi_wip cname_qog         cname   hdi wdi_expedu\n   &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1 AFG          97.7      1.83    27.0  Afghanistan       Afgh… 0.473      NA   \n 2 ALB         100        1.22    35.7  Albania           Alba… 0.785       3.02\n 3 DZA          99.8      5.59     8.11 Algeria           Alge… 0.74        5.51\n 4 AND         100       NA       46.4  Andorra           Ando… 0.855       2.58\n 5 AGO          48.2      1.29    29.5  Angola            Ango… 0.59        2.30\n 6 ATG         100       NA       11.1  Antigua and Barb… Anti… 0.819       2.57\n 7 AZE         100        5.27    18.2  Azerbaijan        Azer… 0.738       3.70\n 8 ARG         100        0.631   44.7  Argentina         Arge… 0.844       4.64\n 9 AUS         100        1.99    31.1  Australia         Aust… 0.949       5.33\n10 AUT         100        0.874   40.4  Austria           Aust… 0.92        5.49\n# ℹ 184 more rows\n# ℹ 15 more variables: wdi_area_sqkm &lt;dbl&gt;, wdi_taxrev &lt;dbl&gt;, wdi_fdiin &lt;dbl&gt;,\n#   wdi_trade &lt;dbl&gt;, cbie_index &lt;dbl&gt;, ht_region &lt;dbl&gt;, wbgi_rle &lt;dbl&gt;,\n#   bmr_dem &lt;dbl&gt;, atop_ally &lt;dbl&gt;, gol_est &lt;dbl&gt;, mad_gdppc &lt;dbl&gt;,\n#   mad_gdppc1900 &lt;dbl&gt;, bci_bci &lt;dbl&gt;, lis_gini &lt;dbl&gt;,\n#   top_top1_income_share &lt;dbl&gt;\n\n\n\n\n4.4.5 Sorting data\nIt is often useful to sort a data frame in ascending or descending order with respect to a given variable. The code below sorts the qog_copy_selection data frame in ascending order with respect to the “wdi_trade” variable using the arrange() function, and then uses the relocate() function to move “wdi_trade” towards the front of the dataset, right after the country name and country code variables:\n\n# sorts \"qog_copy_selection\" data frame in ascending (low to high) order with respect to the \"wdi_trade\" variable, and then brings the \"wdi_trade\" variable\nqog_copy_selection %&gt;% \n  arrange(wdi_trade) %&gt;% \n  relocate(cname_qog, cname, ccodealp, wdi_trade)\n\n# A tibble: 194 × 23\n   cname_qog       cname ccodealp wdi_trade wdi_acel wdi_expmil wdi_wip undp_hdi\n   &lt;chr&gt;           &lt;chr&gt; &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n 1 Ethiopia (1993… Ethi… ETH           24.3     54.2      0.492    42.6    0.489\n 2 United States   Unit… USA           25.3    100        3.46     27.6    0.921\n 3 Pakistan (1971… Paki… PAK           27.0     94.9      2.87     20.2    0.537\n 4 Bangladesh      Bang… BGD           27.7     99        1.20     20.9    0.662\n 5 Burundi         Buru… BDI           28.8     10.2      2.04     38.2    0.419\n 6 Egypt           Egypt EGY           29.9    100        1.12     27.7    0.726\n 7 Tanzania        Tanz… TZA           29.9     42.7      1.08     36.9    0.529\n 8 Kenya           Kenya KEN           30.7     76.5      1.07     21.6    0.596\n 9 Argentina       Arge… ARG           32.9    100        0.631    44.7    0.844\n10 Turkmenistan    Turk… TKM           33.1    100       NA        25      0.74 \n# ℹ 184 more rows\n# ℹ 15 more variables: wdi_expedu &lt;dbl&gt;, wdi_area &lt;dbl&gt;, wdi_taxrev &lt;dbl&gt;,\n#   wdi_fdiin &lt;dbl&gt;, cbie_index &lt;dbl&gt;, ht_region &lt;dbl&gt;, wbgi_rle &lt;dbl&gt;,\n#   bmr_dem &lt;dbl&gt;, atop_ally &lt;dbl&gt;, gol_est &lt;dbl&gt;, mad_gdppc &lt;dbl&gt;,\n#   mad_gdppc1900 &lt;dbl&gt;, bci_bci &lt;dbl&gt;, lis_gini &lt;dbl&gt;,\n#   top_top1_income_share &lt;dbl&gt;\n\n\nIf, instead, we want to sort the dataset in descending order with respect to the “wdi_trade” variable, we can pass the name of the variable to the desc() function within the arrange() function, as below:\n\n# sorts \"qog_copy_selection\" data frame in descending (high to low) order with respect to the \"wdi_trade\" variable, and then brings the \"wdi_trade\" variable to the front of the dataset\nqog_copy_selection %&gt;% \n  arrange(desc(wdi_trade)) %&gt;% \n  relocate(cname_qog, cname, ccodealp, wdi_trade)\n\n# A tibble: 194 × 23\n   cname_qog      cname  ccodealp wdi_trade wdi_acel wdi_expmil wdi_wip undp_hdi\n   &lt;chr&gt;          &lt;chr&gt;  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n 1 Luxembourg     Luxem… LUX           393.    100        0.472    35      0.927\n 2 San Marino     San M… SMR           342.    100       NA        33.3    0.853\n 3 Singapore      Singa… SGP           330.    100        2.78     29.8    0.942\n 4 Malta          Malta  MLT           315.    100        0.496    13.4    0.912\n 5 Djibouti       Djibo… DJI           264.     65.4     NA        26.2    0.512\n 6 Ireland        Irela… IRL           227.    100        0.251    22.5    0.946\n 7 Vietnam        Viet … VNM           187.    100        2.28     30.3    0.718\n 8 Slovakia       Slova… SVK           184.    100        1.77     22.7    0.852\n 9 Seychelles     Seych… SYC           184.    100        2.78     22.9    0.795\n10 Cyprus (1975-) Cyprus CYP           175.    100        1.91     14.3    0.901\n# ℹ 184 more rows\n# ℹ 15 more variables: wdi_expedu &lt;dbl&gt;, wdi_area &lt;dbl&gt;, wdi_taxrev &lt;dbl&gt;,\n#   wdi_fdiin &lt;dbl&gt;, cbie_index &lt;dbl&gt;, ht_region &lt;dbl&gt;, wbgi_rle &lt;dbl&gt;,\n#   bmr_dem &lt;dbl&gt;, atop_ally &lt;dbl&gt;, gol_est &lt;dbl&gt;, mad_gdppc &lt;dbl&gt;,\n#   mad_gdppc1900 &lt;dbl&gt;, bci_bci &lt;dbl&gt;, lis_gini &lt;dbl&gt;,\n#   top_top1_income_share &lt;dbl&gt;\n\n\nNote that it’s also possible to pass several arguments to the arrange function, and thereby sort a dataset with respect to multiple variables; for example, the code below sorts the qog_copy_selection dataset by region (“ht_region), and then further sorts it in descending order by”wdi_trade”. It assigns the result back to qog_copy_selection to effectively “save” these changes to the object:\n\n# arranges the \"qog_copy_selection\" data frame in ascending order with respect to \"ht_region\" and then in descending order with respect to \"wdi_trade\", and then relocates these variables to the front of the dataset; changes are assigned back to \"qog_copy_selection\" to store these changes\nqog_copy_selection&lt;-qog_copy_selection %&gt;% \n                      arrange(ht_region, desc(wdi_trade)) %&gt;% \n                      relocate(cname_qog, cname, ccodealp, ht_region, wdi_trade)\n\nLet’s view the updated version of the qog_copy_selection in the data viewer:\n\n# Views \"qog_copy_selection\" in the data viewer\nView(qog_copy_selection)\n\n\n\n\n\n\n\nAs we can see, sorting the data in this way allows us to quickly note the country in each regional grouping with the highest value on the “trade” variable. Sorting a dataset with respect to more than one variable can be especially useful in certain contexts, particularly in cases where you’re dealing with nested data. For example, in a time series dataset, it can be useful to first sort by year, then by months within the year. In a dataset with regional information, it could be helpful to first sort by regional, then by cities within those regional groupings.\n\n\n4.4.6 Creating New Variables Based on Existing Variables\nDepending on your research question and empirical strategy, it is often useful or necessary to create new variables in your dataset, based on existing variables. The mutate() function from the dplyr package is particularly useful for this purpose. To see how it works, consider the code below, which uses the mutate() function to create a new variable named “mip” (which stands for “men in parliament”) that is computed by subtracting the existing “wdi_wip” (percentage of parliamentary seats held by women) variable from 100. For convenience, we’ll also move “wdi_wip” and the newly created “mip” variables to the front of the dataset using relocate():\n\n# Creates new variable named \"mip\" (percentage of men in parliement) that is calculated by substracting the women's share of parliamentary seats (\"wdi_wip\") from 100 and relocates these variables to the front of the dataset\nqog_copy_selection %&gt;% \n  mutate(mip=100-wdi_wip) %&gt;% \n    relocate(cname_qog, cname, ccodealp, wdi_wip, mip)\n\n# A tibble: 194 × 24\n   cname_qog       cname     ccodealp wdi_wip   mip ht_region wdi_trade wdi_acel\n   &lt;chr&gt;           &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 Slovakia        Slovakia  SVK         22.7  77.3         1      184.    100  \n 2 Estonia         Estonia   EST         25.7  74.3         1      162.    100  \n 3 Slovenia        Slovenia  SVN         26.7  73.3         1      161.    100  \n 4 Hungary         Hungary   HUN         13.1  86.9         1      160.    100  \n 5 Lithuania       Lithuania LTU         27.7  72.3         1      156.    100  \n 6 North Macedonia North Ma… MKD         41.7  58.3         1      147.    100  \n 7 Czech Republic  Czechia   CZE         25    75           1      142.    100  \n 8 Belarus         Belarus   BLR         40    60           1      136.    100  \n 9 Latvia          Latvia    LVA         29    71           1      132.    100  \n10 Bulgaria        Bulgaria  BGR         23.8  76.2         1      121.     99.8\n# ℹ 184 more rows\n# ℹ 16 more variables: wdi_expmil &lt;dbl&gt;, undp_hdi &lt;dbl&gt;, wdi_expedu &lt;dbl&gt;,\n#   wdi_area &lt;dbl&gt;, wdi_taxrev &lt;dbl&gt;, wdi_fdiin &lt;dbl&gt;, cbie_index &lt;dbl&gt;,\n#   wbgi_rle &lt;dbl&gt;, bmr_dem &lt;dbl&gt;, atop_ally &lt;dbl&gt;, gol_est &lt;dbl&gt;,\n#   mad_gdppc &lt;dbl&gt;, mad_gdppc1900 &lt;dbl&gt;, bci_bci &lt;dbl&gt;, lis_gini &lt;dbl&gt;,\n#   top_top1_income_share &lt;dbl&gt;\n\n\nNote that the argument to the mutate function takes the form new_variable=old_variable. It’s possible to define more than one new variable at a time using mutate(); simply separate the arguments by a comma within the mutate() function. For example, the code below creates a new variable (“land_area_sqmiles”) that is created based on “wdi_area” (land area in sq km), as well as a new variable (“no_electricity_access”) that presents the percentage of the population without access to electricity (based on the “wdi_acel” variable that represents the percentage of the population with access to electricity):\n\n# creates \"land_area_sqmiles\" variable based on \"wdi_area\" and \"no_electricity_access\" variable based on \"wdi_acel\"\nqog_copy_selection %&gt;% \n  mutate(land_area_sqmiles=wdi_area/2.5899,\n         no_electricity_access=100-wdi_acel) %&gt;% \n    relocate(cname_qog, \n             cname, \n             ccodealp, \n             land_area_sqmiles, \n             wdi_area, \n             no_electricity_access, \n             wdi_acel)\n\n# A tibble: 194 × 25\n   cname_qog     cname ccodealp land_area_sqmiles wdi_area no_electricity_access\n   &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;                &lt;dbl&gt;    &lt;dbl&gt;                 &lt;dbl&gt;\n 1 Slovakia      Slov… SVK                 18564.   48080                  0    \n 2 Estonia       Esto… EST                 16506.   42750                  0    \n 3 Slovenia      Slov… SVN                  7775.   20136.                 0    \n 4 Hungary       Hung… HUN                 35237.   91260                  0    \n 5 Lithuania     Lith… LTU                 24175.   62610                  0    \n 6 North Macedo… Nort… MKD                  9738.   25220                  0    \n 7 Czech Republ… Czec… CZE                 29803.   77187.                 0    \n 8 Belarus       Bela… BLR                 78362.  202950                  0    \n 9 Latvia        Latv… LVA                 24028.   62230                  0    \n10 Bulgaria      Bulg… BGR                 41917.  108560                  0.200\n# ℹ 184 more rows\n# ℹ 19 more variables: wdi_acel &lt;dbl&gt;, ht_region &lt;dbl&gt;, wdi_trade &lt;dbl&gt;,\n#   wdi_expmil &lt;dbl&gt;, wdi_wip &lt;dbl&gt;, undp_hdi &lt;dbl&gt;, wdi_expedu &lt;dbl&gt;,\n#   wdi_taxrev &lt;dbl&gt;, wdi_fdiin &lt;dbl&gt;, cbie_index &lt;dbl&gt;, wbgi_rle &lt;dbl&gt;,\n#   bmr_dem &lt;dbl&gt;, atop_ally &lt;dbl&gt;, gol_est &lt;dbl&gt;, mad_gdppc &lt;dbl&gt;,\n#   mad_gdppc1900 &lt;dbl&gt;, bci_bci &lt;dbl&gt;, lis_gini &lt;dbl&gt;,\n#   top_top1_income_share &lt;dbl&gt;\n\n\nThe mutate() function is particularly handy when we want to transform continuous numeric variables into a dichotomous (i.e. a “dummy” variable that takes on a value of 1 if a condition is met and 0 otherwise) or categorical variable. For example, let’s say we want to create a new variable, named “trade_open” that takes on the value of 1 if the “wdi_trade” variable is greater than or equal to 60, and 0 otherwise. We can generate this new dummy variable using the mutate() function. In particular, within the mutate() function below, we specify that we want to create a new variable named “trade_open”; the ifelse() function specifies the desired condition (trade&gt;=60), followed by the value the new “trade_open” variable is to take if the condition is met (1), and the value the new “trade_open” variable is to take if the condition is not met (0). In other words, we can translate ifelse(wdi_trade&gt;=77, 1, 0) to “if wdi_trade&gt;=60, set the ‘trade_open’ variable to 1, otherwise set it to 0.” We’ll assign the data frame with the new “trade_open” variable back to “qog_copy_selection”:\n\n# Creates a new dummy variable based on the existing \"wdi_trade\" variable named \"trade_open\" (which takes on a value of \"1\" if \"trade\" is greater than or equal to 60, and 0 otherwise) and then moves the newly created variables to the front of the datasetall changes are assigned to \"qog_copy_selection\", thereby overwriting the existing version of \"qog_copy_selection\"\n\nqog_copy_selection&lt;-\n  qog_copy_selection %&gt;% \n    mutate(trade_open=ifelse(wdi_trade&gt;=60, 1, 0)) %&gt;% \n      relocate(cname_qog, cname, ccodealp, wdi_trade, trade_open)\n\nLet’s print the updated contents of qog_copy_selection to see that the changes have been made:\n\n# prints updated contents of \"qog_copy_selection\"\nqog_copy_selection\n\n# A tibble: 194 × 24\n   cname_qog   cname ccodealp wdi_trade trade_open ht_region wdi_acel wdi_expmil\n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;        &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1 Slovakia    Slov… SVK           184.          1         1    100         1.77\n 2 Estonia     Esto… EST           162.          1         1    100         2.01\n 3 Slovenia    Slov… SVN           161.          1         1    100         1.24\n 4 Hungary     Hung… HUN           160.          1         1    100         1.68\n 5 Lithuania   Lith… LTU           156.          1         1    100         1.97\n 6 North Mace… Nort… MKD           147.          1         1    100         1.47\n 7 Czech Repu… Czec… CZE           142.          1         1    100         1.40\n 8 Belarus     Bela… BLR           136.          1         1    100         1.12\n 9 Latvia      Latv… LVA           132.          1         1    100         2.07\n10 Bulgaria    Bulg… BGR           121.          1         1     99.8       1.52\n# ℹ 184 more rows\n# ℹ 16 more variables: wdi_wip &lt;dbl&gt;, undp_hdi &lt;dbl&gt;, wdi_expedu &lt;dbl&gt;,\n#   wdi_area &lt;dbl&gt;, wdi_taxrev &lt;dbl&gt;, wdi_fdiin &lt;dbl&gt;, cbie_index &lt;dbl&gt;,\n#   wbgi_rle &lt;dbl&gt;, bmr_dem &lt;dbl&gt;, atop_ally &lt;dbl&gt;, gol_est &lt;dbl&gt;,\n#   mad_gdppc &lt;dbl&gt;, mad_gdppc1900 &lt;dbl&gt;, bci_bci &lt;dbl&gt;, lis_gini &lt;dbl&gt;,\n#   top_top1_income_share &lt;dbl&gt;\n\n\nIt can also be useful to create categorical variables based on numeric thresholds from an existing variable. For instance, let’s say we want to take the existing “wdi_trade” variable, and define a new variable named “trade_level”, which is set to “Low_Trade” when the “trade” variable is greater than 15 and less than 50; “Intermediate_Trade” when the “trade” variable is greater than or equal to 50 and less than 100; and “High_Trade” when the “trade” variable is greater than or equal to 100. The code below creates this new “trade_level” variable using the mutate() function; within mutate() the case_when() function maps the conditions onto the desired variable values for “trade_level” using the following syntax:\n\n# Creates a new variable in the \"pt_copy\" dataset named \"trade_level\" (that is coded as \"Low_Trade\" when the \"wdi_trade\" variable is greater than 15 and less than 50, coded as \"Intermediate_Trade\" when \"wdi_trade\" is greater than or equal to 50 and less than 100, and coded as \"High_Trade\" when \"wdi_trade\" is greater than or equal to 100), and then reorders the dataset to move \"trade_level\" and \"wdi_trade\" to the front of the dataset; the changes are assigned back to \"qog_copy_selection\"\nqog_copy_selection&lt;-\n  qog_copy_selection %&gt;% \n  mutate(trade_level=case_when(wdi_trade&gt;15 & wdi_trade&lt;50~\"Low_Trade\",\n                              wdi_trade&gt;=50 & wdi_trade&lt;100~\"Intermediate_Trade\",\n                              wdi_trade&gt;=100~\"High_Trade\")) %&gt;% \n                    relocate(cname_qog, cname, ccodealp, wdi_trade, trade_level)\n\nLet’s print the contents of the updated qog_copy_selection data frame and confirm that the changes have been made:\n\n# prints updated contents of \"qog_copy_selection\"\nqog_copy_selection\n\n# A tibble: 194 × 25\n   cname_qog  cname ccodealp wdi_trade trade_level trade_open ht_region wdi_acel\n   &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 Slovakia   Slov… SVK           184. High_Trade           1         1    100  \n 2 Estonia    Esto… EST           162. High_Trade           1         1    100  \n 3 Slovenia   Slov… SVN           161. High_Trade           1         1    100  \n 4 Hungary    Hung… HUN           160. High_Trade           1         1    100  \n 5 Lithuania  Lith… LTU           156. High_Trade           1         1    100  \n 6 North Mac… Nort… MKD           147. High_Trade           1         1    100  \n 7 Czech Rep… Czec… CZE           142. High_Trade           1         1    100  \n 8 Belarus    Bela… BLR           136. High_Trade           1         1    100  \n 9 Latvia     Latv… LVA           132. High_Trade           1         1    100  \n10 Bulgaria   Bulg… BGR           121. High_Trade           1         1     99.8\n# ℹ 184 more rows\n# ℹ 17 more variables: wdi_expmil &lt;dbl&gt;, wdi_wip &lt;dbl&gt;, undp_hdi &lt;dbl&gt;,\n#   wdi_expedu &lt;dbl&gt;, wdi_area &lt;dbl&gt;, wdi_taxrev &lt;dbl&gt;, wdi_fdiin &lt;dbl&gt;,\n#   cbie_index &lt;dbl&gt;, wbgi_rle &lt;dbl&gt;, bmr_dem &lt;dbl&gt;, atop_ally &lt;dbl&gt;,\n#   gol_est &lt;dbl&gt;, mad_gdppc &lt;dbl&gt;, mad_gdppc1900 &lt;dbl&gt;, bci_bci &lt;dbl&gt;,\n#   lis_gini &lt;dbl&gt;, top_top1_income_share &lt;dbl&gt;\n\n\nAnother useful operation is to create dummy variables based on a categorical variable. For example, consider the “trade_level” variable we just created. Let’s say we want to use the “trade_level” column to create dummy variables for each of the categories in that column. We can do so with the fastDummies package, which can quickly generate dummy variables for the categories in a categorical variable using the dummy_cols() function. Below, we simply take the existing qog_copy_selection dataset, and pass the name of the categorical variable out of which we want to create the dummies (“trade_level”) to the dummy_cols() function:\n\n# Creates dummy variables from \"trade_level\" column, and relocates the new dummies to the front of the dataset; assigns changes back to \"qog_copy_selection\"\nqog_copy_selection&lt;-\n  qog_copy_selection %&gt;% \n  dummy_cols(\"trade_level\") %&gt;% \n    relocate(cname_qog, \n             cname,\n             ccodealp,\n             trade_level, \n             trade_level_High_Trade, \n             trade_level_Intermediate_Trade, \n             trade_level_Low_Trade, \n             trade_level_NA)\n\nYou’ll notice that there are now dummy variables corresponding to each of the categories in the categorical “trade_level” variable; for example, the “trade_level_High_Trade” dummy variable takes on the value of 1 for all observations where the “trade_level” variable is “High_Trade” and 0 otherwise; the “trade_level_Intermediate_Trade” dummy variable takes on the value of 1 for all observations where the “trade_level” variable is “Intermediate_Trade” and 0 otherwise; and so on. If we were to incorporate these dummy variables into a regression model, we would exclude one set of dummy variables (which would then serve as the reference category).\nLet’s view the updated version of qog_copy_selection in the data viewer to see our newly created variables. First, we’ll bring the variables of interest to the front of the data frame:\n\n# specifies variable order\nqog_copy_selection&lt;-\n  qog_copy_selection %&gt;% \n    relocate(cname_qog, cname, ccodealp, wdi_trade, trade_open, trade_level, trade_level_High_Trade, trade_level_Intermediate_Trade, trade_level_Low_Trade, trade_level_NA)\n\nLet’s now view the modified data frame and note the new variables:\n\n# Views \"qog_copy_selection\" in the data viewer\nView(qog_copy_selection)\n\n\n\n\n\n\n\n\n\n4.4.7 Subsetting (Filtering) Variables\nWe already introduced the filter() function in an earlier section, in the context of our discussion of the %&gt;% operator. We’ll now briefly return to this function, and provide additional examples of how it can be used to subset our data frames.\nLet’s say that we want to subset the qog_copy_selection data frame to extract only countries part of the South-East Asia region (coded as a “7” in the “ht_region” variable), and assign this South-East Asia data frame to its own object, named se_asia_data. We can do so with the following:\n\n# uses the filter() function to extract South East Asia observations from \"qog_copy_selection\" and assigns the result to a new object named \"se_asia_data\"\nse_asia_data&lt;-qog_copy_selection %&gt;% \n                filter(ht_region==7)\n\nLet’s print out the contents of se_asia_data to see if it worked as expected:\n\n# prints \"se_asia_data\" to console\nse_asia_data\n\n# A tibble: 11 × 29\n   cname_qog        cname              ccodealp wdi_trade trade_open trade_level\n   &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;        &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;      \n 1 Singapore        Singapore          SGP          330.           1 High_Trade \n 2 Vietnam          Viet Nam           VNM          187.           1 High_Trade \n 3 Brunei           Brunei Darussalam  BRN          147.           1 High_Trade \n 4 Malaysia (1966-) Malaysia           MYS          134.           1 High_Trade \n 5 Cambodia         Cambodia           KHM          129.           1 High_Trade \n 6 Thailand         Thailand           THA          117.           1 High_Trade \n 7 Timor-Leste      Timor-Leste        TLS           99.9          1 Intermedia…\n 8 Philippines      Philippines (the)  PHL           63.5          1 Intermedia…\n 9 Indonesia        Indonesia          IDN           40.2          0 Low_Trade  \n10 Myanmar          Myanmar            MMR           NA           NA &lt;NA&gt;       \n11 Laos             Lao People's Demo… LAO           NA           NA &lt;NA&gt;       \n# ℹ 23 more variables: trade_level_High_Trade &lt;int&gt;,\n#   trade_level_Intermediate_Trade &lt;int&gt;, trade_level_Low_Trade &lt;int&gt;,\n#   trade_level_NA &lt;int&gt;, ht_region &lt;dbl&gt;, wdi_acel &lt;dbl&gt;, wdi_expmil &lt;dbl&gt;,\n#   wdi_wip &lt;dbl&gt;, undp_hdi &lt;dbl&gt;, wdi_expedu &lt;dbl&gt;, wdi_area &lt;dbl&gt;,\n#   wdi_taxrev &lt;dbl&gt;, wdi_fdiin &lt;dbl&gt;, cbie_index &lt;dbl&gt;, wbgi_rle &lt;dbl&gt;,\n#   bmr_dem &lt;dbl&gt;, atop_ally &lt;dbl&gt;, gol_est &lt;dbl&gt;, mad_gdppc &lt;dbl&gt;,\n#   mad_gdppc1900 &lt;dbl&gt;, bci_bci &lt;dbl&gt;, lis_gini &lt;dbl&gt;, …\n\n\nWe can also chain together multiple conditions. For example, let’s use the filter() condition to extract observations for countries that are part of the “Sub-Saharan Africa” region, and have a Human Development Index (“und_hdi”) score greater than or equal to 0.65. We can do so by setting up an expression that uses the “&” logical operator:\n\n# subsets data to include Sub-Saharan African countries with a \"undp_hdi\" value greater than or equal to 0.65 and assigns the result to an object named \"sub_saharan_africa_hdi\"\nsub_saharan_africa_hdi&lt;-qog_copy_selection %&gt;% \n                          filter(ht_region==4 & undp_hdi&gt;=0.65)\n\nLet’s print out the contents of sub_saharan_africa_hdi:\n\n# prints \"sub_saharan_africa_hdi\"\nsub_saharan_africa_hdi\n\n# A tibble: 6 × 29\n  cname_qog    cname        ccodealp wdi_trade trade_open trade_level       \n  &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;        &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;             \n1 Seychelles   Seychelles   SYC          184.           1 High_Trade        \n2 Mauritius    Mauritius    MUS           98.0          1 Intermediate_Trade\n3 Botswana     Botswana     BWA           88.8          1 Intermediate_Trade\n4 Cape Verde   Cabo Verde   CPV           77.5          1 Intermediate_Trade\n5 Gabon        Gabon        GAB           74.5          1 Intermediate_Trade\n6 South Africa South Africa ZAF           56.1          0 Intermediate_Trade\n# ℹ 23 more variables: trade_level_High_Trade &lt;int&gt;,\n#   trade_level_Intermediate_Trade &lt;int&gt;, trade_level_Low_Trade &lt;int&gt;,\n#   trade_level_NA &lt;int&gt;, ht_region &lt;dbl&gt;, wdi_acel &lt;dbl&gt;, wdi_expmil &lt;dbl&gt;,\n#   wdi_wip &lt;dbl&gt;, undp_hdi &lt;dbl&gt;, wdi_expedu &lt;dbl&gt;, wdi_area &lt;dbl&gt;,\n#   wdi_taxrev &lt;dbl&gt;, wdi_fdiin &lt;dbl&gt;, cbie_index &lt;dbl&gt;, wbgi_rle &lt;dbl&gt;,\n#   bmr_dem &lt;dbl&gt;, atop_ally &lt;dbl&gt;, gol_est &lt;dbl&gt;, mad_gdppc &lt;dbl&gt;,\n#   mad_gdppc1900 &lt;dbl&gt;, bci_bci &lt;dbl&gt;, lis_gini &lt;dbl&gt;, …\n\n\nWe can also subset datasets using non-numeric data. For example, if we wanted to extract all of the observations from sub_saharan_africa_hdi for which the “trade_level” variable we created earlier is “Intermediate_Trade”, we can do the following:\n\n# Filters observations from \"sub_saharan_africa_hdi\" for which the \"trade_level\" variable is set to \"Intermediate_Trade\"\nsub_saharan_africa_hdi %&gt;% \n  filter(trade_level==\"Intermediate_Trade\")\n\n# A tibble: 5 × 29\n  cname_qog    cname        ccodealp wdi_trade trade_open trade_level       \n  &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;        &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;             \n1 Mauritius    Mauritius    MUS           98.0          1 Intermediate_Trade\n2 Botswana     Botswana     BWA           88.8          1 Intermediate_Trade\n3 Cape Verde   Cabo Verde   CPV           77.5          1 Intermediate_Trade\n4 Gabon        Gabon        GAB           74.5          1 Intermediate_Trade\n5 South Africa South Africa ZAF           56.1          0 Intermediate_Trade\n# ℹ 23 more variables: trade_level_High_Trade &lt;int&gt;,\n#   trade_level_Intermediate_Trade &lt;int&gt;, trade_level_Low_Trade &lt;int&gt;,\n#   trade_level_NA &lt;int&gt;, ht_region &lt;dbl&gt;, wdi_acel &lt;dbl&gt;, wdi_expmil &lt;dbl&gt;,\n#   wdi_wip &lt;dbl&gt;, undp_hdi &lt;dbl&gt;, wdi_expedu &lt;dbl&gt;, wdi_area &lt;dbl&gt;,\n#   wdi_taxrev &lt;dbl&gt;, wdi_fdiin &lt;dbl&gt;, cbie_index &lt;dbl&gt;, wbgi_rle &lt;dbl&gt;,\n#   bmr_dem &lt;dbl&gt;, atop_ally &lt;dbl&gt;, gol_est &lt;dbl&gt;, mad_gdppc &lt;dbl&gt;,\n#   mad_gdppc1900 &lt;dbl&gt;, bci_bci &lt;dbl&gt;, lis_gini &lt;dbl&gt;, …\n\n\nWe can also extract observations that do NOT meet a given condition. In particular, the condition “not equal to” is denoted by a “!=”. For example, an operation equivalent to the one immediately above would be to exclude observations for which “trade_level” is set to “High_Trade”:\n\n# filters observations from \"sub_saharan_africa_hdi\" for which the \"trade_level\" variable is NOT set to \"High_Trade\"\nsub_saharan_africa_hdi %&gt;% \n  filter(trade_level != \"High_Trade\")\n\n# A tibble: 5 × 29\n  cname_qog    cname        ccodealp wdi_trade trade_open trade_level       \n  &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;        &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;             \n1 Mauritius    Mauritius    MUS           98.0          1 Intermediate_Trade\n2 Botswana     Botswana     BWA           88.8          1 Intermediate_Trade\n3 Cape Verde   Cabo Verde   CPV           77.5          1 Intermediate_Trade\n4 Gabon        Gabon        GAB           74.5          1 Intermediate_Trade\n5 South Africa South Africa ZAF           56.1          0 Intermediate_Trade\n# ℹ 23 more variables: trade_level_High_Trade &lt;int&gt;,\n#   trade_level_Intermediate_Trade &lt;int&gt;, trade_level_Low_Trade &lt;int&gt;,\n#   trade_level_NA &lt;int&gt;, ht_region &lt;dbl&gt;, wdi_acel &lt;dbl&gt;, wdi_expmil &lt;dbl&gt;,\n#   wdi_wip &lt;dbl&gt;, undp_hdi &lt;dbl&gt;, wdi_expedu &lt;dbl&gt;, wdi_area &lt;dbl&gt;,\n#   wdi_taxrev &lt;dbl&gt;, wdi_fdiin &lt;dbl&gt;, cbie_index &lt;dbl&gt;, wbgi_rle &lt;dbl&gt;,\n#   bmr_dem &lt;dbl&gt;, atop_ally &lt;dbl&gt;, gol_est &lt;dbl&gt;, mad_gdppc &lt;dbl&gt;,\n#   mad_gdppc1900 &lt;dbl&gt;, bci_bci &lt;dbl&gt;, lis_gini &lt;dbl&gt;, …\n\n\nIt can also be useful to filter data using “or” conditions; we can make such statements within the filter() function using a “|”. For example, the code below creates a new “east_asia” dataset by using the filter() function to extract South-East Asia or East Asia observations from qog_copy_selection :\n\n# uses the \"filter()\" function to extract observations from South-East Asia (ht_region=7) and East Asia (ht_region=6) and assigns the result to a new object named \"east_asia\"\neast_asia&lt;-qog_copy_selection %&gt;% \n              filter(ht_region==6|ht_region==7) %&gt;% \n                relocate(cname_qog, cname, ccodealp, ht_region)\n\nNow, let’s print the contents of the newly created east_asia object:\n\n# prints contents of \"east_asia\"\neast_asia\n\n# A tibble: 17 × 29\n   cname_qog        cname    ccodealp ht_region wdi_trade trade_open trade_level\n   &lt;chr&gt;            &lt;chr&gt;    &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;      \n 1 Mongolia         Mongolia MNG              6     119.           1 High_Trade \n 2 Korea, South     Korea (… KOR              6      80.2          1 Intermedia…\n 3 China            China    CHN              6      37.3          0 Low_Trade  \n 4 Japan            Japan    JPN              6      36.8          0 Low_Trade  \n 5 Taiwan           Taiwan … TWN              6      NA           NA &lt;NA&gt;       \n 6 Korea, North     Korea (… PRK              6      NA           NA &lt;NA&gt;       \n 7 Singapore        Singapo… SGP              7     330.           1 High_Trade \n 8 Vietnam          Viet Nam VNM              7     187.           1 High_Trade \n 9 Brunei           Brunei … BRN              7     147.           1 High_Trade \n10 Malaysia (1966-) Malaysia MYS              7     134.           1 High_Trade \n11 Cambodia         Cambodia KHM              7     129.           1 High_Trade \n12 Thailand         Thailand THA              7     117.           1 High_Trade \n13 Timor-Leste      Timor-L… TLS              7      99.9          1 Intermedia…\n14 Philippines      Philipp… PHL              7      63.5          1 Intermedia…\n15 Indonesia        Indones… IDN              7      40.2          0 Low_Trade  \n16 Myanmar          Myanmar  MMR              7      NA           NA &lt;NA&gt;       \n17 Laos             Lao Peo… LAO              7      NA           NA &lt;NA&gt;       \n# ℹ 22 more variables: trade_level_High_Trade &lt;int&gt;,\n#   trade_level_Intermediate_Trade &lt;int&gt;, trade_level_Low_Trade &lt;int&gt;,\n#   trade_level_NA &lt;int&gt;, wdi_acel &lt;dbl&gt;, wdi_expmil &lt;dbl&gt;, wdi_wip &lt;dbl&gt;,\n#   undp_hdi &lt;dbl&gt;, wdi_expedu &lt;dbl&gt;, wdi_area &lt;dbl&gt;, wdi_taxrev &lt;dbl&gt;,\n#   wdi_fdiin &lt;dbl&gt;, cbie_index &lt;dbl&gt;, wbgi_rle &lt;dbl&gt;, bmr_dem &lt;dbl&gt;,\n#   atop_ally &lt;dbl&gt;, gol_est &lt;dbl&gt;, mad_gdppc &lt;dbl&gt;, mad_gdppc1900 &lt;dbl&gt;,\n#   bci_bci &lt;dbl&gt;, lis_gini &lt;dbl&gt;, top_top1_income_share &lt;dbl&gt;",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transferring, Processing, and Wrangling Data</span>"
    ]
  },
  {
    "objectID": "session3.html#processing-and-wrangling-multiple-datasets",
    "href": "session3.html#processing-and-wrangling-multiple-datasets",
    "title": "4  Transferring, Processing, and Wrangling Data",
    "section": "4.5 Processing and Wrangling Multiple Datasets",
    "text": "4.5 Processing and Wrangling Multiple Datasets\n\n4.5.1 Joining Data\nJoining, or merging, distinct datasets into a single dataset based on a common variable that exists in both individual datasets is an essential operation in most research projects. To see how we can implement joins in R using the join() family of functions, let’s first pull out two of the list elements in world_bank_list and assign them to objects in the global environment. First, we’ll extract the dataset on foreign direct investment, and assign it to an object named wdi_fdi:\n\n# extracts fdi dataset from \"world_bank_list\" by assigned name and assigns it to a new object named \"wdi_fdi\"\nwdi_fdi&lt;-world_bank_list[[\"wdi_fdi2019\"]]\n\nThen, we’ll extract the World Bank trade dataset and assign it to an object named wdi_trade:\n\n# extracts debt dataset from \"world_bank_list\" by assigned name and assigns it to a new object named \"wdi_trade\"\nwdi_trade&lt;-world_bank_list[[\"wdi_trade2019\"]]\n\nThen, we’ll clean up these datasets by dropping rows with NA values, and then renaming the awkwardly named “2019 [YR2019’” variables in each of the datasets to something more intuitive and descriptive:\n\n# drop na's and rename variable in in trade dataset and assign to \"wdi_trade_cleaned\"\nwdi_trade_cleaned&lt;-wdi_trade %&gt;%\n            drop_na() %&gt;% \n            rename(trade_2019=`2019 [YR2019]`)\n\n# drop na's and rename variable in in FDI dataset and assign to \"wdi_fdi_cleaned\"\nwdi_fdi_cleaned&lt;-wdi_fdi %&gt;% \n            drop_na() %&gt;% \n            rename(fdi_2019=`2019 [YR2019]`)\n\nNow, we can go ahead and use a join() function, to merge the datasets together. There are several different versions of the join() function, and you should read the documentation to learn more, and make sure you’re applying the correct function given the context of your research (?join). We will use the full_join() function, which keeps all of the observations from each of the component datasets in the joined (i.e. output) dataset (even those that do not have a corresponding observation in the other dataset). Below, we call the full_join() function, and pass as arguments the two datasets we’d like to join. The specification by=\"Country Code\" indicates that the join field (i.e. the common field that can be used to link the data frames) is the “Country Code” variable. The column containing the country codes is named “Country Code” in both columns, which makes this especially easy; if, however, the columns containing the join variable were named differently, we could equate them within the full_join() function by passing a vector to the “by” argument that specifies the join field from each component dataset. For example, if the country code variable was in a column named “iso3” in wdi_fdi and “Country Code” in wdi_trade, we could specify by=c(\"iso3\"=\"Country Code\") to let the function know that the join field in wdi_fdi is “iso3” and the join field in wdi_trade is “Country Code”. Below, we assign the product of the join to a new object named fdi_trade_join:\n\n# join together \"wdi_fdi_cleaned\" and \"wdi_fdi_cleaned\" using country code\nfdi_trade_join&lt;-full_join(wdi_fdi_cleaned, wdi_trade_cleaned, by=\"Country Code\")\n\nLet’s see what fdi_trade_join looks like by passing it to the R Studio Viewer:\n\nView(fdi_trade_join)\n\n\n\n\n\n\n\nNote that both variables are now in the dataset as separate columns.\n\n\n4.5.2 Appending Data\nIf joining datasets is fundamentally about situating disparate datasets side-by-side in a new unified dataset, appending datasets is about stacking disparate datasets with a similar structure on top of each other in a new unified dataset. In other words, joining datasets leads to a unified dataset with more columns than the original individual datasets, while appending datasets leads to a unified dataset with more rows than the original individual datasets. Depending on the type of data you’re working with, appending data can be just as important a method for bringing together disparate datasets.\nWe can easily append data frames a single unified data frame using the bind_rows() function from dplyr. Below, we append wdi_fdito wdi_trade by passing these objects as arguments to the bind_rows() function. We’ll assign the appended dataset to a new object named worldbank_trade_fdi_appended:\n\n# Appends \"worldbank_trade_2019\" to \"worldbank_fdi_2019\" and assigns new dataset to object named \"worldbank_trade_fdi\"\nworldbank_trade_fdi_appended&lt;-bind_rows(wdi_trade, wdi_fdi)\n\nTo confirm that the appending operation worked as expected, please view worldbank_trade_fdi_appended in the data viewer.\n\n\n4.5.3 Reshaping Data\nIn a “wide” dataset, each variable or measurement is stored in a separate column; on the other hand, in a “long” dataset, each measurement is stored in a single column, and there is an additional column that identifies the specific variable or category for each observation. For example, in our context, fdi_trade_join is a “wide” dataset, while worldbank_trade_fdi_appended is formatted as a long dataset.\nThe process of converting a wide dataset to a long one, or vice versa, is typically referred to as reshaping data. Often, one will need to bring different datasets together (either through a join or append operation), but in order to successfully implement the required procedure, it is first necessary to reshape at least one of the datasets so that they’re correctly formatted; the first step in integrating datasets, therefore, is frequently a reshaping operation that ensures that the datasets have a common structure. Below, we’ll quickly review some functions for carrying out these reshaping operations from the tidyr package, which is part of the tidyverse suite.\n\n4.5.3.1 Long to Wide\nTo see how a “long to wide” operation works using the tidyr lets imagine we want to transform worldbank_trade_fdi_appended, currently formatted as a long dataset, into a wide dataset. First we’ll clean up worldbank_trade_fdi_appended using some familiar tidyverse functions, and assign the result to a new object named worldbank_trade_fdi_cleaned cleaned:\n\n# cleans the dataset before reshaping\nworldbank_trade_fdi_cleaned&lt;-worldbank_trade_fdi_appended %&gt;% \n                              rename(economic_variables=\"2019 [YR2019]\",\n                                     series_code=\"Series Code\") %&gt;% \n                              select(-\"Series Name\") %&gt;% \n                              drop_na()\n\nBefore proceeding, we should note that the column containing the data, “economic_variables” is formatted as a character variable:\n\n# prints class of \"economic_variables\" column\nclass(worldbank_trade_fdi_cleaned$economic_variables)\n\n[1] \"character\"\n\n\nIn order for the reshaping process to work, we need to transform that column into the “numeric” class, which we do with the following:\n\n# converts \"economic_variables\" to numeric\nworldbank_trade_fdi_cleaned$economic_variables&lt;-as.numeric(worldbank_trade_fdi_cleaned$economic_variables)\n\nWarning: NAs introduced by coercion\n\n\nNow, we use tidyr’s pivote_wider function to “pivot” the data from long to wide. Below, we’ll take worldbank_trade_fdi_cleaned and then feed that data into the pivot_wider() function using the %&gt;% operator. Within the pivot_wider() function, the “names_from” argument specifies the current column that contains the names we would like to use as column names in the reshaped dataset, while the “values_from” argument specifies the name of the current column that contains the data that will be used to populate the columns in the reshaped dataset. We’ll assign this code to a new object named worldbank_trade_fdi_wide:\n\n# reshapes \"worldbank_trade_fdi_cleaned\" from long to wide and assigns the wide dataset to an object named \"worldbank_trade_fdi_wide\"\nworldbank_trade_fdi_wide&lt;-worldbank_trade_fdi_cleaned %&gt;% \n                              tidyr:: pivot_wider(names_from=series_code,\n                                          values_from=economic_variables)\n\nLet’s quickly take a look at the reshaped dataset:\n\n# prints contents of \"worldbank_trade_fdi_wide\"\nworldbank_trade_fdi_wide\n\n\n\n# A tibble: 6 × 4\n  `Country Name` `Country Code` NE.TRD.GNFS.ZS BX.KLT.DINV.WD.GD.ZS\n  &lt;chr&gt;          &lt;chr&gt;                   &lt;dbl&gt;                &lt;dbl&gt;\n1 Afghanistan    AFG                      NA                  0.124\n2 Albania        ALB                      76.3                7.80 \n3 Algeria        DZA                      51.8                0.804\n4 American Samoa ASM                     157.                NA    \n5 Andorra        AND                      NA                 NA    \n6 Angola         AGO                      57.8               -5.78 \n\n\nIt might be nice to rename the variables to something more intuitive:\n\n# renames columns in \"worldbank_trade_fdi_wide\"\nworldbank_trade_fdi_wide&lt;-worldbank_trade_fdi_wide %&gt;% \n                          rename(trade2019=NE.TRD.GNFS.ZS,\n                                 FDI2019=BX.KLT.DINV.WD.GD.ZS)\n\nGo ahead and inspect worldbank_trade_fdi_wide in the data viewer:\n\nView(worldbank_trade_fdi_wide)\n\n\n\n\n\n\n\n\n\n4.5.3.2 Wide to Long\nTo make the conversion in the opposite direction, i.e. reshaping a dataset from wide to long, we can use the pivot_longer() function. Below, we take the worldbank_trade_fdi_wide data frame, and feed it into the pivot_longer() function using the %&gt;% operator. Within the function, we use cols=c(FDI2019, trade2019) to specify the current columns that we’re going to collapse into a single column in the new dataset. The “names_to” argument specifies the name of column that will hold the original “FDI2019” and “trade2019” columns, while the “values_to” argument specifies the name of the column that will actually hold the data. Let’s go ahead and run the code, and assign the output to a new object named world_bank_trade_long:\n\n# reshapes \"worldbank_trade_fdi_wide\" back to long format and assigns the reshaped dataset to a new object named \"world_bank_trade_long\"\nworld_bank_trade_long&lt;-worldbank_trade_fdi_wide %&gt;% \n                        pivot_longer(cols=c(FDI2019, trade2019),\n                                     names_to=\"economic_variable\",\n                                     values_to = \"2019\")\n\nLet’s view world_bank_trade_long in the data Viewer to confirm that it has been successfully reshaped:\n\nView(world_bank_trade_long)\n\n\n\n\n\n\n\n\n\n\n4.5.4 Automating Data Processing with Functions\nWhen working with multiple datasets, we may need to carry out identical operations on those datasets, in which case we could save time by wrapping up the relevant code in a function and iterating over the dataset elements we’d like to transform. Let’s say, for example, that we want to clean up our World Bank dataset by deleting a column, renaming others, and removing the rows where the country code is NA. Rather than carrying out these operations individually, let’s create a function, called worldbank_cleaning_function, that implements these changes and returns a clean dataset:\n\n# write function to clean World Bank dataset\nworldbank_cleaning_function&lt;-function(input_dataset){\n  modified_dataset&lt;-input_dataset %&gt;% \n                      select(-\"Series Code\") %&gt;% \n                      rename(\"Country\"=\"Country Name\",\n                             \"CountryCode\"=\"Country Code\",\n                             \"Series\"=\"Series Name\",\n                             \"2019\"=\"2019 [YR2019]\") %&gt;% \n                      drop_na(CountryCode)\n  return(modified_dataset)\n}\n\nLet’s test the function using wdi_trade:\n\n# passes \"wdi_trade\" to \"worldbank_cleaning_function\"\nworldbank_cleaning_function(wdi_trade)\n\n# A tibble: 266 × 4\n   Country             CountryCode Series           `2019`          \n   &lt;chr&gt;               &lt;chr&gt;       &lt;chr&gt;            &lt;chr&gt;           \n 1 Afghanistan         AFG         Trade (% of GDP) ..              \n 2 Albania             ALB         Trade (% of GDP) 76.2791946495763\n 3 Algeria             DZA         Trade (% of GDP) 51.8097384415762\n 4 American Samoa      ASM         Trade (% of GDP) 156.568778979907\n 5 Andorra             AND         Trade (% of GDP) ..              \n 6 Angola              AGO         Trade (% of GDP) 57.8295381183036\n 7 Antigua and Barbuda ATG         Trade (% of GDP) 137.625175755884\n 8 Argentina           ARG         Trade (% of GDP) 32.6306150458499\n 9 Armenia             ARM         Trade (% of GDP) 96.1141541288708\n10 Aruba               ABW         Trade (% of GDP) 145.343572735289\n# ℹ 256 more rows\n\n\nThat looked like it worked, so lets go ahead and apply worldbank_cleaning_function to all of the data frames in world_bank_list. We’ll use the familiar map() function to do so; below, world_bank_list is the list we’re iterating over, while worldbank_cleaning_function() is the function we’re applying:\n\n# Iteratively apply \"worldbank_cleaning_function\" to all of the datasets in \"world_bank_list\", and deposit the cleaned datasets into a new list named \"world_bank_list_cleaned\"\nworld_bank_list_cleaned&lt;-map(.x=world_bank_list, .f=worldbank_cleaning_function)\n\nLet’s print out the list and confirm that the operation worked:\n\n# prints contents of \"world_bank_list_cleaned\"\nworld_bank_list_cleaned\n\n$wdi_debt2019\n# A tibble: 266 × 4\n   Country             CountryCode Series                                 `2019`\n   &lt;chr&gt;               &lt;chr&gt;       &lt;chr&gt;                                  &lt;chr&gt; \n 1 Afghanistan         AFG         Central government debt, total (% of … ..    \n 2 Albania             ALB         Central government debt, total (% of … 75.69…\n 3 Algeria             DZA         Central government debt, total (% of … ..    \n 4 American Samoa      ASM         Central government debt, total (% of … ..    \n 5 Andorra             AND         Central government debt, total (% of … ..    \n 6 Angola              AGO         Central government debt, total (% of … ..    \n 7 Antigua and Barbuda ATG         Central government debt, total (% of … ..    \n 8 Argentina           ARG         Central government debt, total (% of … ..    \n 9 Armenia             ARM         Central government debt, total (% of … 50.02…\n10 Aruba               ABW         Central government debt, total (% of … ..    \n# ℹ 256 more rows\n\n$wdi_fdi2019\n# A tibble: 266 × 4\n   Country             CountryCode Series                                 `2019`\n   &lt;chr&gt;               &lt;chr&gt;       &lt;chr&gt;                                  &lt;chr&gt; \n 1 Afghanistan         AFG         Foreign direct investment, net inflow… 0.124…\n 2 Albania             ALB         Foreign direct investment, net inflow… 7.797…\n 3 Algeria             DZA         Foreign direct investment, net inflow… 0.804…\n 4 American Samoa      ASM         Foreign direct investment, net inflow… ..    \n 5 Andorra             AND         Foreign direct investment, net inflow… ..    \n 6 Angola              AGO         Foreign direct investment, net inflow… -5.78…\n 7 Antigua and Barbuda ATG         Foreign direct investment, net inflow… 7.433…\n 8 Argentina           ARG         Foreign direct investment, net inflow… 1.485…\n 9 Armenia             ARM         Foreign direct investment, net inflow… 0.736…\n10 Aruba               ABW         Foreign direct investment, net inflow… -2.21…\n# ℹ 256 more rows\n\n$wdi_trade2019\n# A tibble: 266 × 4\n   Country             CountryCode Series           `2019`          \n   &lt;chr&gt;               &lt;chr&gt;       &lt;chr&gt;            &lt;chr&gt;           \n 1 Afghanistan         AFG         Trade (% of GDP) ..              \n 2 Albania             ALB         Trade (% of GDP) 76.2791946495763\n 3 Algeria             DZA         Trade (% of GDP) 51.8097384415762\n 4 American Samoa      ASM         Trade (% of GDP) 156.568778979907\n 5 Andorra             AND         Trade (% of GDP) ..              \n 6 Angola              AGO         Trade (% of GDP) 57.8295381183036\n 7 Antigua and Barbuda ATG         Trade (% of GDP) 137.625175755884\n 8 Argentina           ARG         Trade (% of GDP) 32.6306150458499\n 9 Armenia             ARM         Trade (% of GDP) 96.1141541288708\n10 Aruba               ABW         Trade (% of GDP) 145.343572735289\n# ℹ 256 more rows\n\n$wdi_urban2019\n# A tibble: 266 × 4\n   Country             CountryCode Series                                 `2019`\n   &lt;chr&gt;               &lt;chr&gt;       &lt;chr&gt;                                  &lt;chr&gt; \n 1 Afghanistan         AFG         Urban population (% of total populati… 25.754\n 2 Albania             ALB         Urban population (% of total populati… 61.229\n 3 Algeria             DZA         Urban population (% of total populati… 73.189\n 4 American Samoa      ASM         Urban population (% of total populati… 87.147\n 5 Andorra             AND         Urban population (% of total populati… 87.984\n 6 Angola              AGO         Urban population (% of total populati… 66.177\n 7 Antigua and Barbuda ATG         Urban population (% of total populati… 24.506\n 8 Argentina           ARG         Urban population (% of total populati… 91.991\n 9 Armenia             ARM         Urban population (% of total populati… 63.219\n10 Aruba               ABW         Urban population (% of total populati… 43.546\n# ℹ 256 more rows\n\n\nAs expected, each of the processed datasets is an element in world_bank_list_cleaned.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transferring, Processing, and Wrangling Data</span>"
    ]
  },
  {
    "objectID": "session3.html#exporting-processed-data",
    "href": "session3.html#exporting-processed-data",
    "title": "4  Transferring, Processing, and Wrangling Data",
    "section": "4.6 Exporting Processed Data",
    "text": "4.6 Exporting Processed Data\nAfter we have processed our datasets, it’s often necessary to get the transformed data out of the R environment. There are a variety of functions that can export data frames from R to your local disk in various file formats. Because CSV files are so flexible and commonly used, we’ll explore how to export R data frames to your local disk as CSV files; if you need to export your data frames into another file format (for example .xlsx or .dta files), you would need to look up the relevant packages and functions that enable this.\nTo write out an R data frame to disk as a CSV, we can use the read_csv() function. Below, we export the east_asia data frame we created earlier as a CSV to the “outputs” folder in our working directory. The first argument is the name of the object we want to export, while the second argument specifies the file path, name, and extension of the desired output file.\n\n# exports \"east_asia\" to a local directory (i.e. the \"outputs\" sub-directory of our working directory)\nwrite_csv(east_asia, \"outputs/east_asia.csv\")\n\nIn order to export multiple data frames (for example, we may want to export a bunch of cleaned data frames out of R to use in another package) we can use the walk() function and its relatives; these functions are a part of the purrr package, and work similarly to the map() family of functions.\nLet’s say we want to export the cleaned World Bank data frames in world_bank_list_cleaned. First, we’ll create a vector of file names for the exported files using the paste0() function. We’ll assign this vector to a new object named WB_filenames_export:\n\n# create file names for exported World Bank files\nWB_filenames_export&lt;-paste0(\"outputs/\", worldbank_filenames_base, \"_cleaned.csv\")\n\nLet’s see what this looks like:\n\n# prints \"WB_filenames_export\" contents\nWB_filenames_export\n\n[1] \"outputs/wdi_debt2019_cleaned.csv\"  \"outputs/wdi_fdi2019_cleaned.csv\"  \n[3] \"outputs/wdi_trade2019_cleaned.csv\" \"outputs/wdi_urban2019_cleaned.csv\"\n\n\nNow, we’ll use the walk2() function to iteratively pass the data frames (contained in world_bank_list_cleaned and the file names contained in WB_filenames_export to the write_csv() function. The code below takes the first elements from world_bank_list_cleaned and WB_filenames_export, and passes them to write_csv() which exports the first data frame with the first file name; then, it takes the second elements from world_bank_list_cleaned and WB_filenames_export, and passes them to write_csv() which exports the second data frame with the second file name; and so on.\n\n# exports datasets in \"world_bank_list_cleaned\" to \"outputs\" directory using filenames in \"WB_filenames_export\"\nwalk2(.x=world_bank_list_cleaned, .y=WB_filenames_export, write_csv)\n\nCheck your “outputs” directory to ensure that the files have been written out as expected.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transferring, Processing, and Wrangling Data</span>"
    ]
  },
  {
    "objectID": "session3.html#end-of-lesson-exercises",
    "href": "session3.html#end-of-lesson-exercises",
    "title": "4  Transferring, Processing, and Wrangling Data",
    "section": "4.7 End-of-Lesson Exercises",
    "text": "4.7 End-of-Lesson Exercises\nExercise 1\nWrite a function to perform some operation(s) on one of the World Bank datasets, then iteratively apply that function to all of the World Bank datasets. Write out the transformed files to a local directory on your computer.\nExercise 2\nApply the filter() AND the mutate() function to one of the datasets we’ve worked with in this lesson (chaining together operations with the %&gt;% operator), and assign the modified dataset to a new object that you write out to a local directory on your computer as a CSV file.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transferring, Processing, and Wrangling Data</span>"
    ]
  },
  {
    "objectID": "session4.html",
    "href": "session4.html",
    "title": "5  Elementary Data Visualization and Analysis",
    "section": "",
    "text": "5.1 Introduction\nIn this session, we’ll turn from tasks related to data processing and wrangling to creating basic visualization and analysis products in R. We will cover descriptive statistics, data visualization using the ggplot2 package (part of the tidyverse suite), and linear regression, and also explore how to export analysis and visualization objects related to such tasks (i.e. plots, regression and summary statistics tables etc.) out of R for use in external applications. Our focus will be on practical issues related to implementing analysis workflows in R, rather than conceptual or methodological issues related to visualization or statistical techniques (which is beyond our curren scope)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Elementary Data Visualization and Analysis</span>"
    ]
  },
  {
    "objectID": "session4.html#preliminaries-and-set-up",
    "href": "session4.html#preliminaries-and-set-up",
    "title": "5  Elementary Data Visualization and Analysis",
    "section": "5.2 Preliminaries and Set-Up",
    "text": "5.2 Preliminaries and Set-Up\nWe will be using the following packages. Please install any packages that are not already installed (using the install.packages() function, and load them into memory using the library() function:\n\n# load packages\nlibrary(tidyverse)\nlibrary(psych)\nlibrary(janitor)\nlibrary(fastDummies)\nlibrary(summarytools)\nlibrary(stargazer)\nlibrary(gtsummary)\nlibrary(ggeffects)\nlibrary(effects)\nlibrary(interplot)\n\nWe will continue working with the Quality of Government Institute’s basic cross-sectional dataset, which we introduced and began exploring in the previous lesson. Please go ahead and read in that data if it is not already in memory, and assign it to an object named qog:\n\n# read in qog data and assign to object named \"qog\"\nqog&lt;-read_csv(\"data/quality_of_government/qog_bas_cs_jan25.csv\")\n\nRows: 194 Columns: 331\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): cname_qog, cname, ccodealp\ndbl (328): ccode_qog, ccodecow, ccode, ajr_settmort, atop_ally, atop_number,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAs before, we’ll make a copy of qog to work with:\n\n# make a copy of the \"qog\" data and assign to \"qog_copy\"\nqog_copy&lt;-qog\n\nNow, we’ll go ahead and select some variables of interest to work with, and assign the modified dataset to a new object named qog_copy_selection:\n\n# select qog variables and assign modified dataset to object named \"qog_copy_selection\"\nqog_copy_selection &lt;- \n  qog_copy %&gt;% \n   dplyr::select(cname_qog, \n          cname, \n          ccodealp, \n          undp_hdi, \n          wdi_expedu,\n          wdi_acel,\n          wdi_area,\n          wdi_taxrev,\n          wdi_expmil,\n          wdi_fdiin,\n          wdi_trade,\n          cbie_index,\n          ht_region,\n          wbgi_rle,\n          bmr_dem,\n          atop_ally,\n          gol_est,\n          mad_gdppc,\n          mad_gdppc1900,\n          bci_bci,\n          lis_gini,\n          top_top1_income_share,\n          wdi_wip)\n\nCurrently, the “ht_region” variable contains numeric codes that specify a country’s region in the world (see the QOG dataset codebook for more details). We will use this variable to make a new categorical variable that encodes the region information as a string, which will make it easier to interpret in the course of making visualizations and computing relevant statistics. To do so, we will use the case_when() function introduced in the previous session. We’ll assign the change back to the qog_copy_selection object:\n\n# Create new character variable named \"region\" based on \"ht_region\" variable that contains region information encoded as strings\nqog_copy_selection&lt;-\n  qog_copy_selection %&gt;% \n    mutate(region=case_when(ht_region==1~\"EasternEuropePostSoviet\",\n                          ht_region==2~\"LatinAmerica\",\n                          ht_region==3~\"NorthAfricaMiddleEast\",\n                          ht_region==4~\"SubSaharanAfrica\",\n                          ht_region==5~\"WesternEuropeNorthAmerica\",\n                          ht_region==6~\"EastAsia\",\n                          ht_region==7~\"SouthEastAsia\",\n                          ht_region==8~\"SouthAsia\",\n                          ht_region==9~\"Pacific\",\n                          ht_region==10~\"Caribbean\"))",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Elementary Data Visualization and Analysis</span>"
    ]
  },
  {
    "objectID": "session4.html#missing-data",
    "href": "session4.html#missing-data",
    "title": "5  Elementary Data Visualization and Analysis",
    "section": "5.3 Missing Data",
    "text": "5.3 Missing Data\nBefore proceeding, it is important to briefly acquaint ourselves with how R handles missing data, which has implications for our main topics of interest below. Most real-world social science datasets (including the QOG dataset we are working with) have missing data, and when they are read into R, “blank” cells in a dataset are automatically coded as “NA” by R. To confirm this, view qog_copy_selection in the data viewer:\n\n# view \"qog_copy_selection\" in Viewer; note NA values\nView(qog_copy_selection)\n\n\n\n\n\n\n\nWe’ll begin by developing some basic intuitions about missing data in R using a simple toy dataset, which we’ll create below and assign to the student_scores data frame:\n\n# makes toy dataset, assigned to object named \"student_scores\"\nstudent_scores&lt;-data.frame(Age=c(25, NA, 30, 22, NA),\n                           Score=c(85, 90, NA, 78, 88))\n\nLet’s print our toy student_scores data frame to get a clear sense of what it looks like:\n\n# prints \"student_scores\"\nstudent_scores\n\n  Age Score\n1  25    85\n2  NA    90\n3  30    NA\n4  22    78\n5  NA    88\n\n\nNote the “NA” values, which indicate that data corresponding to those cells is missing.\nIf we want to identify missing data, we can do so with the is.na() function, which returns a logical matrix with the value TRUE for missing values:\n\n# uses \"is.na\" to return a logical matrix indicating missing values (TRUE for missing values)\nis.na(student_scores)\n\n       Age Score\n[1,] FALSE FALSE\n[2,]  TRUE FALSE\n[3,] FALSE  TRUE\n[4,] FALSE FALSE\n[5,]  TRUE FALSE\n\n\nIf we want the total number of missing values in the dataset, we can take the sum of is.na(student_scores) :\n\n# calculates total number of missing values in \"student_scores\"\nsum(is.na(student_scores))\n\n[1] 3\n\n\nIf we want the total number of missing values per column, we can pass is.na(student_scores) as an argument to the colSum() function, which we can do because in R, logical values can be used in numeric operations; when they’re used in this way, TRUE=1 and FALSE=0.\n\n# calculates total number of missing values per column\ncolSums(is.na(student_scores))\n\n  Age Score \n    2     1 \n\n\nIf we wanted to calculate the percentage of missing data in the dataset, we could use our count of the number of NA values in the dataset sum(is.na(student_scores)) and divide it by the total number of cells in the dataset, derived by multiplying the dataset’s rows and columns:\n\n# calculates missing data percentage in \"student_scores\"\n# first calculates count of missing values and assigns it to \"total_missing\"\ntotal_missing&lt;-sum(is.na(student_scores))\n# calculates total number of cells and assigns it to \"total_values\"\ntotal_values&lt;-prod(dim(student_scores))\n# calculates percentage of missing data and assigns it to \"missing_pct\"\nmissing_pct&lt;-(total_missing/total_values)*100\n\n# prints contents of \"missing_pct\"\nmissing_pct\n\n[1] 30\n\n\nCalculating the percentage of data missing in a dataset can be useful, and something we may want to do frequently, so it could be useful to wrap this code into a function, which we’ll do below, and assign to a new object named missing_data_percentage():\n\n# creates function to calculate the percentage of missing data in a dataset\nmissing_data_percentage&lt;-function(dataset){\n  # generates count of missing values\n  total_missing&lt;-sum(is.na(dataset))\n  # calculates total number of cells\n  total_values&lt;-prod(dim(dataset))\n  # calculates percentage of missing data\nmissing_pct&lt;-(total_missing/total_values)*100\nreturn(missing_pct)\n}\n\nLet’s test out the function on student_scores:\n\n# passes \"student_scores\" as an argument to custom function \"missing_data_percentage\" which yields the percentage of missing data in the \"student_scores\" dataset\nmissing_data_percentage(student_scores)\n\n[1] 30\n\n\nWe can now use this function for any other datasets we might create or work with, without having to retype a bunch of code. For example, if we wanted to calculate the percentage of missing data in qog_copy, we could pass it as an argument to missing_data_percentage:\n\n# calculates missing data percentage in \"qog_copy\"\nmissing_data_percentage(qog_copy)\n\n[1] 33.78858\n\n\nIf we wanted to calculate the percentage of missing data in the modified qog_copy_selection dataset, we could pass it as an argument to the missing_data_percentage function:\n\n# calculates missing data percentage in \"qog_copy_selection\"\nmissing_data_percentage(qog_copy_selection)\n\n[1] 13.10137\n\n\nIt could also be useful to get a sense of the percentage of missing data at more granular levels. For example, if we wanted to uncover the percentage of missing data per column, we could carry out a simple calculation using the colSums() and nrow() functions:\n\n# calculates percentage of missing data per column in \"student_scores\" and assigns the resulting vector to an object named \"missing_pct_per_col\"\nmissing_pct_per_col&lt;-colSums(is.na(student_scores))/nrow(student_scores)*100\n\n# prints contents of \"missing_pct_per_col\"\nmissing_pct_per_col\n\n  Age Score \n   40    20 \n\n\nIn many cases, after identifying patterns in the missing data, we may want to remove “NA” values from a dataset or a certain section of a dataset. If we want to remove missing data, the drop_na() function from the tidyverse is useful. The drop_na() function will remove all rows from the dataset with NA values in any column. For example, the following removes all rows with NA values from the “student_scores” data frame.\n\n# removes all rows with NA values from \"student_scores\"\ndrop_na(student_scores)\n\n  Age Score\n1  25    85\n2  22    78\n\n\nThe default behavior of the drop_na() function is to drop all rows with NA values in any column (i.e. only rows with complete data are kept in the dataset). However, it’s possible to change this default behavior by specifying column/variable names after passing the data frame object as an argument; when we do this, drop_na() no longer drops all rows with missing data in any column, but all rows with missing data in any specified column. For example, the code below drops all rows where “Age” values are NA, but not all rows where “Score” scores are NA\n\n# removes all rows where \"Age\" has NA values in \"student_scores\"\ndrop_na(student_scores, Age)\n\n  Age Score\n1  25    85\n2  30    NA\n3  22    78\n\n\nIf, instead, we specify “Score” as an argument, the function drops all rows where “Score” values are NA, but not all rows where “Age” values are NA.\n\n# removes all rows where \"Score\" has NA values in \"student_scores\"\ndrop_na(student_scores, Score)\n\n  Age Score\n1  25    85\n2  NA    90\n3  22    78\n4  NA    88\n\n\nNote that we can specify more than one column argument to drop_na(), in which case rows which have NA values associated with those specified columns will be dropped, but rows which have NA values with other (non-specified) columns are kept.\nImputing missing values is a complex topic beyond the scope of our workshop, but it’s worth briefly noting that for whatever reason, NA values may be incorrectly coded, or used as placeholders for other values. For example, you may know from a dataset’s codebook, or from context, that for a particular column in the dataset, observations that appear as missing/NA should actually be coded as “0”. We can use the replace_na() function to replace such NA values with their proper values. For example, let’s say that NA values in the “Score” column should actually be “0” (perhaps NA was being used as a placeholder, and needs to be converted to 0 since the student never turned in their assignment). In the replace_na() function, the first argument is the name of the data frame object, while the second is a list that indicates the column(s) with NA values that need replacement, and a specification for what they will be replaced with. In our case, the syntax looks something like this:\n\n# replace NA values in the \"Score\" column with 0\nreplace_na(student_scores, list(Score=0))\n\n  Age Score\n1  25    85\n2  NA    90\n3  30     0\n4  22    78\n5  NA    88\n\n\nSometimes, we may need to make even more targeted replacements of “NA” values. For example, let’s say we want to replace the “NA” value associated with the “Age” variable that is in row #5, with the numeric value “22”, but do not want to change the “NA” in row #2 for that column. In such scenarios, using the mutate() and if_else() functions in conjunction may provide more flexibility than the replace_na() function:\n\n# changes NA values in Age column to 22 where ID is equal to 5, and makes no changes otherwise; assigns modified data frame to \"student_scores_modified\"\nstudent_scores_modified&lt;-student_scores %&gt;% \n                          mutate(Age = if_else(is.na(Age) & row_number()==5, 22, Age))\n\n# prints \"student_scores_modified\"\nstudent_scores_modified\n\n  Age Score\n1  25    85\n2  NA    90\n3  30    NA\n4  22    78\n5  22    88\n\n\nIn the code above, note the use of row_number() in our conditional expression; row_number() is a handy dplyr function that allows us to quickly reference row positions within data processing pipelines.\nFinally, it’s important to note that base R functions like mean() and sum() will return NA if there are missing values. For example:\n\n# calculates mean of \"Score\" (NA values are not excluded; default behavior)\nmean(student_scores$Score)\n\n[1] NA\n\n\nIf we want such functions to carry out their calculations on non-NA values (while ignoring NA values), we must set na.rm=TRUE as a function argument.\n\n# calculates mean of \"Score\" (NA values are excluded due to na.rm=TRUE specification; as a result, the function computes an average based on non-NA values)\nmean(student_scores$Score, na.rm=TRUE)\n\n[1] 85.25\n\n\nIt is important to emphasize that when working in R, different packages or functions may handle missing data differently, so it’s useful to consult the documentation of the packages you use for more information (especially when something is not working as expected).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Elementary Data Visualization and Analysis</span>"
    ]
  },
  {
    "objectID": "session4.html#descriptive-statistics",
    "href": "session4.html#descriptive-statistics",
    "title": "5  Elementary Data Visualization and Analysis",
    "section": "5.4 Descriptive Statistics",
    "text": "5.4 Descriptive Statistics\nOnce we have a dataset loaded into R, and we have wrangled it into a usable form that is appropriate for analysis (the main subject of the previous lesson), the next step is usually to get a sense of the basic structure of the dataset by calculating summary statistics. This section reviews some summary statistics functions and tools we can call on for this purpose.\n\n5.4.1 Summary Statistics Tables\nA quick way to generate a table of summary statistics is to use the describe() function from the psych package. Below, we’ll generate summary statistics for the qog_copy_selection data frame by passing it as an argument to the describe() function. We’ll assign the resulting table of summary statistics to a new object named qog_copy_selection_summarystats1:\n\n# Generate summary statistics for \"qog_copy_selection\" and assign table of \n# summary statistics to a new object named \"qog_copy_selection_summarystats1\"\nqog_copy_selection_summarystats1&lt;-describe(qog_copy_selection)\n\nLet’s print the first few rows of qog_copy_selection_summarystats1 to the console:\n\n# prints first few rows of \"qog_copy_selection_summarystats1\" to console\nhead(qog_copy_selection_summarystats1)\n\n           vars   n  mean    sd median trimmed   mad  min    max  range  skew\ncname_qog*    1 194 97.50 56.15  97.50   97.50 71.91 1.00 194.00 193.00  0.00\ncname*        2 194 97.50 56.15  97.50   97.50 71.91 1.00 194.00 193.00  0.00\nccodealp*     3 194 97.50 56.15  97.50   97.50 71.91 1.00 194.00 193.00  0.00\nundp_hdi      4 190  0.72  0.15   0.74    0.73  0.17 0.38   0.96   0.58 -0.34\nwdi_expedu    5 174  4.58  2.07   4.31    4.39  1.75 0.38  14.20  13.81  1.34\nwdi_acel      6 192 85.84 24.47 100.00   91.30  0.00 7.70 100.00  92.30 -1.66\n           kurtosis   se\ncname_qog*    -1.22 4.03\ncname*        -1.22 4.03\nccodealp*     -1.22 4.03\nundp_hdi      -0.82 0.01\nwdi_expedu     3.51 0.16\nwdi_acel       1.55 1.77\n\n\nWe can also view it in the R Studio data viewer:\n\n# view \"qog_copy_selection_summarystats1\" in Viewer\nView(qog_copy_selection_summarystats1)\n\n\n\n\n\n\n\nNote that the describe() function returns statistics for non-numeric variables (marked with a “*” in the summary statistics table output), but these results often do not have an intuitive or meaningful interpretation. We could limit the summary statistics output to numeric variables by first modifying the data frame to remove non-numeric columns and assigning the result to a new object named qog_copy_selection_numeric:\n\n# removes non-numeric variables and assigns modified data frame to new object named \"qog_copy_selection_numeric\"\nqog_copy_selection_numeric&lt;-\n  qog_copy_selection %&gt;% \n    dplyr::select(-ht_region) %&gt;% \n    dplyr::select(where(is.numeric))\n\nNow, let’s pass qog_copy_selection_numeric to the describe() function and create our summary statistics table, which we’ll assign to a new object named qog_copy_selection_numeric_summarystats2:\n\n# Generates summary statistics for numeric variables \n# (i.e. those in qog_copy_selection_numeric) using \"describe()\nqog_copy_selection_numeric_summarystats2&lt;-describe(qog_copy_selection_numeric)\n\nLet’s now view the modified “numeric variables only” summary statistics table:\n\n# views \"qog_copy_selection_numeric_summarystats2\" in data viewer\nView(qog_copy_selection_numeric_summarystats2)\n\n\n\n\n\n\n\nRecall that we can view the documentation for any function (including those from external packages) by printing a “?” before the name of the function in the R console:\n\n# pulls up documentation for describe() function in the \"Help\" tab in the bottom-right window of R Studio\n?describe\n\nOne thing to note from the documentation is that the describe() function defaults to setting na.rm=TRUE; under this setting, the describe() function simply omits NA (i.e. missing) values when calculating summary statistics. If, instead, we set na.rm=FALSE, the function deletes all rows that contain missing data, and calculates summary statistics with reference to this truncated dataset that has been excised of missing values. In practical terms, it will typically make the most sense to go with the default na.rm=TRUE option, but it’s important to be clear about these different options for handling missing data in the context of the describe() function.\nIf you’re still struggling to understand the difference, we can explore how this works in the context of our toy dataset, student_scores:\n\n# prints \"student_scores\"\nstudent_scores\n\n  Age Score\n1  25    85\n2  NA    90\n3  30    NA\n4  22    78\n5  NA    88\n\n\nLet’s pass student_scores as an argument to the describe() function, and set na.rm=TRUE; we’ll assign the result to a new object named student_scores_summarystats:\n\n# generates summary statistics with \"describe()\" function \n# and assigns it to \"df_sample_summary_default\"; \n# na.rm=TRUE ignores NA values when calculating summary statistics\nstudent_scores_summarystats&lt;-describe(student_scores, na.rm=TRUE)\n\nLet’s now print student_scores_summarystats:\n\n# prints \"student_scores_summarystats\"\nstudent_scores_summarystats\n\n      vars n  mean   sd median trimmed  mad min max range  skew kurtosis   se\nAge      1 3 25.67 4.04   25.0   25.67 4.45  22  30     8  0.16    -2.33 2.33\nScore    2 4 85.25 5.25   86.5   85.25 3.71  78  90    12 -0.44    -1.91 2.63\n\n\nNote that the calculations are carried out by simply ignoring NA values. For example, the mean for the “Age” variable is (25+30+22)/3=25.67, while the mean for the “Score” variable is (85+90+78+88)/4=85.25. Now, let’s see how these calculations change when na.rm=FALSE:\n\n# generates summary statistics with describe function and assigns\n# it to \"df_sample_summary_B\"; na.rm=FALSE removes rows with any NA \n# values  before calculating summary statistics (in other words, \n# summary statistics are computed on rows with complete data)\nstudent_scores_summarystats_B&lt;-describe(student_scores, na.rm=FALSE)\n\n# prints \"student_scores_summarystats_B\"\nstudent_scores_summarystats_B\n\n      vars n mean   sd median trimmed  mad min max range skew kurtosis  se\nAge      1 2 23.5 2.12   23.5    23.5 2.22  22  25     3    0    -2.75 1.5\nScore    2 2 81.5 4.95   81.5    81.5 5.19  78  85     7    0    -2.75 3.5\n\n\nNote that the mean of the “Age” column is now (25+22)/2=23.5, since na.rm=FALSE deletes all rows with NA values (here, rows 2, 3, and 5) before implementing the calculation. Analogously, the mean of the “Score” column is now (85+78)/2=81.5\n\n\n5.4.2 Customizing Summary Statistics Tables\nThere are a variety of other packages that can help you generate summary statistics tables, beyond psych. For example, the summarytools package provides the descr() , which is similar to describe() from the psych package. The summarytools package defaults to providing information as a matrix, which we haven’t covered, so we pass descr(qog_copy_selection) to the as.data.frame() function to get the summary statistics table output as a data frame, which we’ll assign to a new object named qog_copy_selection_numeric_ST:\n\n# uses \"descr\" function from summarytools package to \n# create a table of summary statistics as a data frame \n# and assigns it to \"qog_copy_selection_numeric_ST\"\nqog_copy_selection_numeric_ST&lt;-as.data.frame(descr(qog_copy_selection_numeric))\n\nLet’s go ahead and view qog_copy_selection_numeric_ST in the data viewer:\n\n# views \"qog_copy_selection_numeric_ST\" in Viewer\nView(qog_copy_selection_numeric_ST)\n\n\n\n\n\n\n\nAnother handy package for generating summary statistics is stargazer. Though stargazer is most useful for creating and exporting regression tables (which we’ll explore further below), it can also produce a well-formatted summary statistics table that can be exported as a text file. For example, the code below uses stargazer to create a summary statistics table for qog_copy_selection_numeric (we’ll export it out of R as a text file in a later section):\n\n# uses stargazer package to generate summary statistics for qog_copy_selection_numeric\nstargazer(as.data.frame(qog_copy_selection_numeric), type = \"text\")\n\n\n=============================================================================\nStatistic              N     Mean       St. Dev.       Min          Max      \n-----------------------------------------------------------------------------\nundp_hdi              190    0.719        0.153       0.380        0.965     \nwdi_expedu            174    4.579        2.066       0.382        14.195    \nwdi_acel              192   85.840       24.466       7.700       100.000    \nwdi_area              192 663,647.400 1,839,053.000   2.084    16,376,870.000\nwdi_taxrev            141   16.211        6.855       0.0001       44.347    \nwdi_expmil            152    1.873        1.337       0.110        7.581     \nwdi_fdiin             181   -2.866       97.408     -1,303.108     32.752    \nwdi_trade             169   89.973       57.016       24.345      393.141    \ncbie_index            153    0.694        0.154       0.302        0.912     \nwbgi_rle              193   -0.066        0.996       -2.301       2.013     \nbmr_dem               193    0.606        0.490         0            1       \natop_ally             184    1.000        0.000         1            1       \ngol_est               142    1.810        0.714         1            3       \nmad_gdppc             162 19,024.630   20,243.310    606.859    143,468.800  \nmad_gdppc1900         47   2,924.333    2,007.795    817.743     8,037.571   \nbci_bci               191   44.262       19.486       -3.497       78.942    \nlis_gini              35     0.333        0.061       0.236        0.485     \ntop_top1_income_share 193    0.159        0.045       0.060        0.274     \nwdi_wip               192   24.511       12.944       0.000        61.250    \n-----------------------------------------------------------------------------\n\n\nDespite the variety of options available for generating summary statistics, it is important to emphasize that if the available options do not provide exactly what you are looking for, it is possible to customize summary statistics functions to produce outputs tailored to your specific needs. For example, it could be nice to have a column in the student_scores_summarystats summary statistics table that provides information on the number of NA values there are for each variable. The describe() function does not provide this information, but that is something we can add with a little bit of extra work on our own. To get that information into student_scores_summarystats, we’ll first write a very simple function, count_missing(), to count the number of NA values in a vector:\n\n# Define a named function to count missing values\ncount_missing &lt;- function(x) {\n  sum(is.na(x))\n}\n\nNext, we’ll iteratively apply the count_missing function to the columns of the original student_scores data frame, and generate a new vector that contains the number of NA values for each column; we will assign this vector to a new object named missing_values_vector:\n\n# applies \"count_missing\" function to the columns of \"student_scores\",\n# and deposits the results (i.e. count of missing values in each \n# column of \"student_scores\") to a numeric vector assigned to the object \"missing_values_vector\"\nmissing_values_vector &lt;- map_dbl(.x=student_scores, .f=count_missing)\n\nRecall that map() family functions iteratively apply a function to elements of a list or vector. It might seem surprising, then, that we used a map() function to apply a function across the columns of a data frame, but under the hood, a data frame is a kind of list, where the elements (columns) are vectors. This is what allows us to use map_dbl() across the columns of student_scores.\nNow, we’ll add this vector as a column to student_scores_summarystats:\n\n# adds \"missing_values_vector\" as a column named \"missing_values\" to \"student_scores_summarystats\" summary stats table\nstudent_scores_summarystats&lt;-\n  student_scores_summarystats %&gt;% \n      mutate(missing_values=missing_values_vector)\n\nLet’s view the updated student_scores_summarystats object in the R Studio data viewer, and confirm that a new “missing_values” column that indicates the number of NA values for each variable has been added to the data frame:\n\nView(student_scores_summarystats)\n\n\n\n\n\n\n\nIn case we expect to carry out this procedure for several datasets, we can wrap up this process for adding a “missing_values” column to the standard summary statistics table generated by describe() into a custom function that we’ll call summary_stats_na:\n\n# makes function to automate the creation of a \"missing_value\" column in summary statistics\n# generated. by describe()\nsummary_stats_na&lt;-function(dataset_input){\n  \n# create summary stats table and assign to \"summary_stats\"\nsummary_stats&lt;-describe(dataset_input)\n  \n# create a missing values vector and adds it as a column to \"summary_stats\"; the result\n# is assigned to \"summary_stats_missing_values\"\nsummary_stats_missing_values&lt;-\n  summary_stats %&gt;% \n      mutate(missing_values=map_dbl(.x=dataset_input, .f=count_missing))\n  \n  return(summary_stats_missing_values)\n}\n\nLet’s test out summary_stats_na() by using it to generate a summary statistics table with a “missing_values” column for the data in qog_copy_selection_numeric. We’ll assign the result to a new object named qog_copy_selection_numeric_summaryNA:\n\n# creates a summary statistics table for the data in \"qog_copy_selection_numeric\" that includes a \"missing_values\" column that indicates the number of NA values for each variable by passing \"qog_copy_selection_numeric\" as an argument to the \"summary_stats_na\" function; the resulting summary statistics table is assigned to \"qog_copy_selection_numeric_summaryNA\" \nqog_copy_selection_numeric_summaryNA&lt;-summary_stats_na(qog_copy_selection_numeric)\n\nNow, let’s view qog_copy_selection_numeric_summaryNA in the data viewer and confirm the existence of the “missing_values” column:\n\n# views \"qog_copy_selection_numeric_summaryNA\" in data viewer\nView(qog_copy_selection_numeric_summaryNA)\n\n\n\n\n\n\n\n\n\n5.4.3 Frequency tables and cross-tabulations\nFrequency tables and cross-tabulations (often referred to as “crosstabs”) are especially useful ways to quickly convey the basic structure and relevant patterns in qualitative data. A frequency table shows how often each value of a single variable occurs, while a crosstab is essentially a bivariate frequency table that shows how often different combinations of two different variables appear in a given dataset.\nWe can quickly create a frequency table using the count() function in dplyr. Below, we use count() to create a table that displays the number of observations associated with each value of the “region” variable:\n\n# creates frequency table for the region variable\nqog_copy_selection %&gt;% \n  count(region)\n\n# A tibble: 10 × 2\n   region                        n\n   &lt;chr&gt;                     &lt;int&gt;\n 1 Caribbean                    13\n 2 EastAsia                      6\n 3 EasternEuropePostSoviet      28\n 4 LatinAmerica                 20\n 5 NorthAfricaMiddleEast        20\n 6 Pacific                      12\n 7 SouthAsia                     8\n 8 SouthEastAsia                11\n 9 SubSaharanAfrica             49\n10 WesternEuropeNorthAmerica    27\n\n\nNow, let’s say that we’d like to add a column to this table, based on the information about the number of observations associated with each regional category, that displays the percentage associated with each regional category (as a share of the overall dataset). We can do so by using mutate() to define a “percent” column; we’ll add the resulting frequency table to a new object named region_frequency:\n\n# adds percentage column and assigns modified frequency\n# table to new object called \"region_frequency\"\nregion_frequency&lt;-qog_copy_selection %&gt;% \n                    count(region) %&gt;% \n                      mutate(percent=n/sum(n)*100)\n\nLet’s view region_frequency in the data viewer:\n\n# Views \"region_frequency\" in data viewer\nView(region_frequency)\n\n\n\n\n\n\n\nWe can create crosstabs by passing two variable names to count(). The following creates a “long” crosstab of region and democracy status (the dichotomous “bmr_dem” variable), in which the combinations of variables are displayed as separate rows:\n\n# creates long crosstab of region and democracy status (bmr_dem)\n# variables from \"qog_copy_selection\" data frame\nqog_copy_selection %&gt;% \n  count(region, bmr_dem)\n\n# A tibble: 19 × 3\n   region                    bmr_dem     n\n   &lt;chr&gt;                       &lt;dbl&gt; &lt;int&gt;\n 1 Caribbean                       1    13\n 2 EastAsia                        0     2\n 3 EastAsia                        1     4\n 4 EasternEuropePostSoviet         0     8\n 5 EasternEuropePostSoviet         1    20\n 6 LatinAmerica                    0     5\n 7 LatinAmerica                    1    15\n 8 NorthAfricaMiddleEast           0    17\n 9 NorthAfricaMiddleEast           1     3\n10 Pacific                         0     2\n11 Pacific                         1    10\n12 SouthAsia                       0     5\n13 SouthAsia                       1     3\n14 SouthEastAsia                   0     8\n15 SouthEastAsia                   1     3\n16 SubSaharanAfrica                0    29\n17 SubSaharanAfrica                1    19\n18 SubSaharanAfrica               NA     1\n19 WesternEuropeNorthAmerica       1    27\n\n\nIf, instead, we want a “wide” crosstab in which the combinations are displayed across columns, we can pass the “long” crosstab we just created to the pivot_wider() function introduced in the previous session:\n\n# creates wide crosstab of region and democracy status (bmr_dem)\n# variables from \"qog_copy_selection\" data frame\nqog_copy_selection %&gt;% \n  count(region, bmr_dem) %&gt;% \n  pivot_wider(names_from=bmr_dem,\n              values_from=n,\n              values_fill=0)\n\n# A tibble: 10 × 4\n   region                      `1`   `0`  `NA`\n   &lt;chr&gt;                     &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1 Caribbean                    13     0     0\n 2 EastAsia                      4     2     0\n 3 EasternEuropePostSoviet      20     8     0\n 4 LatinAmerica                 15     5     0\n 5 NorthAfricaMiddleEast         3    17     0\n 6 Pacific                      10     2     0\n 7 SouthAsia                     3     5     0\n 8 SouthEastAsia                 3     8     0\n 9 SubSaharanAfrica             19    29     1\n10 WesternEuropeNorthAmerica    27     0     0\n\n\nWe might further refine the appearance of this crosstab by adding rows and columns containing information on the total number of observations associated with each value of the two variables, as well as modifying the column names so that they are more intuitive and descriptive. We can do the former using the adorn_totals() function from the janitor package, while we can modify the column names using the familiar rename() function. We’ll assign the result to a new object named region_demo_crosstab:\n\n# creates wide cross-tab of region and democracy status, with\n# row and column totals and modified column names and assigns the \n# result to \"region_demo_crosstab\"\nregion_demo_crosstab&lt;-\n  qog_copy_selection %&gt;% \n  count(region, bmr_dem) %&gt;% \n  pivot_wider(names_from=bmr_dem,\n              values_from=n,\n              values_fill=0) %&gt;% \n  adorn_totals(where=c(\"row\", \"col\")) %&gt;% \n  rename(Region=region,\n         Democracy = `1`,\n         `Non-Democracy` = `0`,\n         Missing = `NA`)\n\nYou may have noticed the backticks in some of the arguments to the rename() function, which may be confusing at a first glance. In general, such notation is not required to specify arguments within the rename() function (note, for example, the absence of such notation when we rename “region” to “Region”), but such backticks are required when referencing non-syntactic (i.e. invalid) variable names. Numeric column names, as well as “NA” and column names with symbols such as a hyphen, are considered non-syntactic, which is why the “1”, “0”, “NA”, and “Non-Democracy” are enclosed by backticks. If non-syntactic variable names were not flagged with backticks, R would not know what exactly you were referring to. For example, if we wrote Democracy=1, R would read that as “rename the value 1 to ‘Democracy’” which makes no sense; writing Democracy=`1`, ensures that R correctly interprets it as “rename the variable named 1 to ‘Democracy’”, which is what we want.\nLet’s go ahead and view region_demo_crosstab in the data viewer:\n\n# views \"region_demo_crosstab\" in crosstab\nView(region_demo_crosstab)\n\n\n\n\n\n\n\nIf we wanted to create wide crosstab in which the regions are arrayed across columns (rather than rows), we can modify the argument to pivot_wider(); we’ll assign the crosstab structured in this way to a new object named demo_region_crosstab:\n\n# creates wide cross-tab of democracy status and region (with regional # categories spread across columns), with row and column totals and modified column names and assigns the result to \"demo_region_crosstab\"\ndemo_region_crosstab&lt;-\n  qog_copy_selection %&gt;% \n    count(bmr_dem, region) %&gt;% \n    pivot_wider(names_from=region,\n                values_from=n,\n                values_fill=0) %&gt;% \n    adorn_totals(where=c(\"row\", \"col\")) %&gt;% \n    rename(Democracy=bmr_dem)\n\n\n# views \"demo_region_crosstab\" in Viewer\nView(demo_region_crosstab)\n\n\n\n\n\n\n\nAnother handy function for making frequency tables and crosstabs is the tabyl() function from the janitor package. If we want to make a frequency table, we can pass a data frame and variable of interest to tabyl() as arguments. For example, the following makes a frequency table for the “region” variable:\n\n# makes frequency table of region variable using tabyl()\ntabyl(qog_copy_selection, region)\n\n                    region  n    percent\n                 Caribbean 13 0.06701031\n                  EastAsia  6 0.03092784\n   EasternEuropePostSoviet 28 0.14432990\n              LatinAmerica 20 0.10309278\n     NorthAfricaMiddleEast 20 0.10309278\n                   Pacific 12 0.06185567\n                 SouthAsia  8 0.04123711\n             SouthEastAsia 11 0.05670103\n          SubSaharanAfrica 49 0.25257732\n WesternEuropeNorthAmerica 27 0.13917526\n\n\nNote that the frequency table generated by tabyl() automatically includes a column that includes the percentage of observations associated with each category.\nTo create a wide crosstab using tabyl(), we can supply the names of the relevant data frame, followed by the names of the variables of interest, as arguments to the function:\n\n# makes crosstab of region and democracy status using tabyl(); adds \n# row and column totals using \"adorn_totals\" function\ntabyl(qog_copy_selection, region, bmr_dem) %&gt;% \n  adorn_totals(where=c(\"row\", \"col\"))\n\n                    region  0   1 NA_ Total\n                 Caribbean  0  13   0    13\n                  EastAsia  2   4   0     6\n   EasternEuropePostSoviet  8  20   0    28\n              LatinAmerica  5  15   0    20\n     NorthAfricaMiddleEast 17   3   0    20\n                   Pacific  2  10   0    12\n                 SouthAsia  5   3   0     8\n             SouthEastAsia  8   3   0    11\n          SubSaharanAfrica 29  19   1    49\n WesternEuropeNorthAmerica  0  27   0    27\n                     Total 76 117   1   194\n\n\nWithin tabyl() the first variable argument specifies the variable that will form the crosstab’s rows, while the second specifies the variable that will form its columns; so, if we wanted to create a crosstab in which the regions are spread across columns (as in demo_region_crosstab, we could simply reverse the order of “region” and “bmr_dem” in the code above.\n\n\n5.4.4 Group-level Summary Statistics\nIn many cases, it is useful to generate summary statistics for subgroups in a dataset, in addition to summary statistics for the dataset as a whole (which we discussed above). One way to generate group-level summary statistics is to use the describeBy() function (from the psych package), where the first argument is the data frame we would like to generate group-level summary statistics for, and the second argument is the name of the column that contains the relevant groups for which we want disaggregated summary statistics. Below, we use describeBy() to generate summary statistics for each of the different regional categories that comprise the “region” variable (referenced using dollar sign notation) within qog_copy_selection. The output of the describeBy() function is a list in which the various elements are summary statistics tables for each group; we’ll assign this output list to a new object named summary_stats_by_region:\n\n# Creates summary statistics for each regional grouping, \n# and puts results in list object named \"summary_stats_by_region\"\nsummary_stats_by_region&lt;-describeBy(qog_copy_selection, qog_copy_selection$region)\n\nYou may notice that the function throws a warning (along the lines of “no missing arguments…”), which is driven by the fact that for some groups, there is no valid data for certain variables, which makes it impossible to compute the desired statistic. In this case, this warning can be safely ignored.\nThe summary_stats_by_region list object contains summary statistics for each regional grouping, which we can access by name using double bracket notation. For example, the following extracts the summary statistics table for the Pacific region observations:\n\n# Accessing continent-level summary statistics for \n# The Pacific from the \"summary_stats_by_region\" list\nsummary_stats_by_region[[\"Pacific\"]]\n\n\n\n           vars  n   mean    sd median trimmed   mad   min   max  range  skew\ncname_qog     1 12 133.92 38.69 134.00  135.90 34.84 59.00 189.0 130.00 -0.26\ncname         2 12 134.42 38.94 134.00  136.50 37.06 59.00 189.0 130.00 -0.28\nccodealp      3 12 134.83 46.29 139.50  137.00 54.11 58.00 190.0 132.00 -0.41\nundp_hdi      4 12   0.67  0.07   0.67    0.67  0.08  0.56   0.8   0.24  0.06\nwdi_expedu    5 12   7.50  3.83   6.88    7.45  3.68  1.35  14.2  12.85  0.25\nwdi_acel      6 12  86.12 22.95  95.55   91.26  6.60 20.90 100.0  79.10 -1.84\n           kurtosis    se\ncname_qog     -1.00 11.17\ncname         -1.03 11.24\nccodealp      -1.30 13.36\nundp_hdi      -1.20  0.02\nwdi_expedu    -1.19  1.11\nwdi_acel       2.52  6.63\n\n\nRecall that we can extract an element from a list and assign it to a separate object. For example, the following extracts the summary statistics for observations from Western Europe and North America (“WesternEuropeNorthAmerica”) and assigns it to a new object named we_na_summary; after creating that object, we’ll view the corresponding summary statistics table in the data viewer.\n\n# Extracts group level summary statistics table for \"WesternEuropeNorthAmerica\" from \"summary_stats_by_region\" list and assigns it to a new object named \"we_na_summary\"\nwe_na_summary&lt;-summary_stats_by_region[[\"WesternEuropeNorthAmerica\"]]\n\n\n# views \"we_na_summary\" in data viewer\nView(we_na_summary)\n\n\n\n\n\n\n\nIn addition to calculating separate summary statistics for different subgroups in a dataset, it could also be useful calculate summary statistics at different levels of aggregation. For example, the qog_copy_selection data frame is a country-level dataset (i.e. each row in the dataset represents a country), and the summary statistics we calculated above were calculated using countries as the unit of analysis. However, if we are interested in analyzing phenomena at the regional level, we can calculated summary statistics for selected variables using regions as the unit of analysis. To do this, we can use the handy group_by() and summarise() functions of dplyr. The group_by() function specifies a grouping variable that defines the unit of analysis, while summarise() defines the relevant summary statistics to compute for each group.\nFor example, the following code generates a table presenting the mean, standard deviation, and number of observations for the “wdi_trade” and “wdi_fdiin” variables, aggregated by region. The resulting table is assigned to an object named trade_fdi_by_region:\n\n# Generate a table that displays summary statistics for \"wdi_trade\" # and \"wdi_fdiin\" at the regional level and assign to object named # \"trade_fdi_by_region\"\ntrade_fdi_by_region&lt;-\n  qog_copy_selection %&gt;% \n  group_by(region) %&gt;% \n  summarise(meanTrade=mean(wdi_trade, na.rm=TRUE),\n            sdTrade=sd(wdi_trade, na.rm=TRUE),\n            meanFDI=mean(wdi_fdiin, na.rm=TRUE), \n            sdFDI=sd(wdi_fdiin, na.rm=TRUE),\n            n=n())\n\nLet’s go ahead and view trade_fdi_by_region in the data viewer:\n\n# views \"trade_fdi_by_region\" in data viewer\nView(trade_fdi_by_region)\n\n\n\n\n\n\n\nAs we can see, trade_fdi_by_region summarizes variation in trade and foreign direct investment (FDI) across world regions. Each row now corresponds to a region, and the columns display the regional mean and standard deviation of the “wdi_trade” and “wdi_fdiin” variables, along with the number of countries (“n”) within that region.\nIt’s worth noting that we can explicitly control the number of decimal places to which values in a data frame are rounded by embedding the functions that define the summary statistics within the round() function. For example, the following code modifies trade_fdi_by_region by rounding the values in the output table to two digits:\n\n# round to two decimal places\ntrade_fdi_by_region&lt;-qog_copy_selection %&gt;% \n  group_by(region) %&gt;% \n  summarise(meanTrade=round(mean(wdi_trade, na.rm=TRUE), 2),\n            sdTrade=round(sd(wdi_trade, na.rm=TRUE), 2),\n            meanFDI=round(mean(wdi_fdiin, na.rm=TRUE), 2), \n            sdFDI=round(sd(wdi_fdiin, na.rm=TRUE), 2),\n            n=n())\n\nLet’s view the modified version of trade_fdi_by_region:\n\n# views \"trade_fdi_by_region\" in data viewer\nView(trade_fdi_by_region)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Elementary Data Visualization and Analysis</span>"
    ]
  },
  {
    "objectID": "session4.html#exploratory-visualization",
    "href": "session4.html#exploratory-visualization",
    "title": "5  Elementary Data Visualization and Analysis",
    "section": "5.5 Exploratory Visualization",
    "text": "5.5 Exploratory Visualization\nIn this section, we’ll discuss how to use ggplot2 to visualize our data. ggplot2 is the tidyverse’s visualization package, and is rooted in a framework known as the “grammar of graphics” (the “gg” in ggplot2 stands for “grammar of graphics”).\nThe central idea behind the grammar of graphics is to create plots by systematically layering different visualization elements on top of each other. The foundational layer is always the data used to create the plot. In relation to this foundational data layer, we define a visualization’s aesthetic mappings (often referred to as “aes”), which specifies how to connect the underlying data to the visual properties of the visualization (such as the x and y axes, position, color, size, and shape). In other words, aesthetic mappings tell ggplot2 how to represent the underlying data visually.\nNext, on top of the data layer, we add geometries (or “geoms”) which determine the visual symbols used to represent the data, such as points, lines, or bars. Other layers, such as themes, can further refine the plot, by specifying aspects of its appearance not directly tied to the data (like background color, text size, or font) but which affect readability and style.\nThe syntax of ggplot2 flows from the logic of layering that is at the heart of the grammar of graphics: each component of a plot (i.e. data, aesthetics, geometries, and so on) is added to the plot by chaining together relevant functions with a “+” symbol. Complex visualizations are thereby constructed piece by piece, one layer at a time.\nggplot2 is a remarkable package, and builds on R’s longstanding strengths as a data visualization platform. Though it’s possible to make beautiful and sophisticated publication-quality visualizations using ggplot2, our focus here will be on getting acquainted with the basic syntax of the package, and making some quick exploratory visualizations based on data from the qog_copy_selection dataset. In this regard, this section follows naturally from the previous section’s discussion of descriptive and summary statistics, since the creation of quick visualizations is another important tool of exploratory data analysis.\n\n5.5.1 Bar Charts\nWe’ll start our exploration of ggplot2, and get a sense of how the grammar of graphics works in practice, by making some simple bar charts that display the “wdi_trade” data from qog_copy_selection. A bar chart with all of the country observations in the dataset would be too crowded and cluttered, so we’ll focus on plotting the observations from South Asia. Our first step will be to extract South Asian observations with non-“NA” values for “wdi_trade”:\n\n# filters South Asia observations and drops countries with \"na\" values for \"wdi_trade\"\nqog_south_asia&lt;-qog_copy_selection %&gt;% \n                  filter(region==\"SouthAsia\") %&gt;% \n                  drop_na(wdi_trade)\n\nNow that we have the data object with the data we want to plot, let’s go ahead and create our bar chart that compares trade openness (“wdi_trade”) across countries in South Asia, and assign the plot to a new object named trade_southasia:\n\n# Creates a bar chart of the \"wdi_trade\" variable (central government expenditure as a share of GDP) \n# for the South Asia observations and assigns the plot to an object named \"trade_southasia\"\ntrade_southasia&lt;-\n  ggplot(data=qog_south_asia)+\n  geom_col(aes(x=cname, y=wdi_trade))+\n  labs(\n    title=\"Trade as a Percentage of GDP in South Asia\\n(2017-2020)\",\n    caption = \"Source: Quality of Government Institute\", \n    x=\"Country\", \n    y=\"Trade as a Percentage of GDP\")+\n  theme(plot.title=element_text(hjust=0.5),\n        axis.text.x = element_text(angle = 90))\n\nLet’s print trade_southasia and see what the plot looks like:\n\n# prints \"trade_southasia\"\ntrade_southasia\n\n\n\n\n\n\n\n\nLet’s unpack the code we used to create trade_southasia:\n\nThe expression ggplot(qog_south_asia) specifies that we want to initialize ggplot2, and establishes qog_south_asia as the data object that contains the data we want to plot. In other words, in terms of the grammar of graphics, it sets qog_south_asia as the plot’s foundational data layer.\ngeom_col() is a geometry function, which we use use because we want to represent the underlying data with data with a bar/column chart. Within geom_col(), we specify the x and y axes of the plot within aes(), the function used to set the aesthetic mappings that describe how variables in the data are translated into visual properties of the chosen geom.\nWithin the labs() function, we set labels for the x and y axes. We also indicate our desired title and caption.\nWe can use the theme() function to control aspects of the plot’s appearance that are not directly related to the data itself. Here, our arguments within theme() specify the need for a center-justified position for the plot title, and an orientation for the x-axis labels.\n\nThis is a nice start, but it may look a slightly cleaner if we arrayed the chart in ascending order with respect to the “wdi_trade” variable. We can rearrange the visual representation of the data in this way by by using the reorder() function within our aesthetic mapping to specify that we want observations on the x-axis to be arrayed in ascending order with respect to “wdi_trade”. Below, we create a bar chart with the “wdi_trade” values arrayed in ascending order and assign the modified plot to a new object named trade_southasia_ascending:\n\n# Creates a bar chart of the \"wdi_trade\" variable\n# for the South Asia observations; countries are on the \n# x axis and arrayed in ascending order with respect to the \n# trade variable, which is on the y-axis; assigns the plot to an \n# object named \"trade_southasia_ascending\"\ntrade_southasia_ascending&lt;-\n  ggplot(qog_south_asia)+\n  geom_col(aes(x=reorder(cname, wdi_trade), y=wdi_trade))+\n  labs(\n    title=\"Trade as a Percentage of GDP in South Asia\\n(2017-2020)\",\n    caption = \"Source: Quality of Government Institute\", \n    x=\"Country\", \n    y=\"Trade as a Percentage of GDP\")+\n  theme(plot.title=element_text(hjust=0.5),\n        axis.text.x = element_text(angle = 90))\n\nLet’s print trade_southasia_ascending and confirm that the data is now plotted in ascending order:\n\n# prints \"trade_southasia_ascending\"\ntrade_southasia_ascending\n\n\n\n\n\n\n\n\nIf, instead, we want to array the data in descending order, we can simply add a minus sign in front of “wdi_trade”. Below, we create a bar chart in which the countries are arrayed in descending order with respect to “wdi_trade”, and assign the result to a new object named trade_southasia_descending:\n\n# Creates a bar chart of the \"wdi_trade\" variable \n# for the South Asia observations; countries are on the x axis and arrayed in descending order with respect to the \n# trade variable, which is on the y-axis; assigns the plot to an object named \"trade_southasia_descending\"\ntrade_southasia_descending&lt;-\n  ggplot(qog_south_asia)+\n  geom_col(aes(x=reorder(cname, -wdi_trade), y=wdi_trade))+\n  labs(\n    title=\"Trade as a Percentage of GDP in South Asia\\n(2017-2020)\",\n    caption = \"Source: Quality of Government Institute\", \n    x=\"Country\", \n    y=\"Trade as a Percentage of GDP\")+\n  theme(plot.title=element_text(hjust=0.5),\n        axis.text.x = element_text(angle = 90))\n\nLet’s now print trade_southasia_descending and confirm that the data is now in descending order:\n\n# prints \"trade_southasia_descending\"\ntrade_southasia_descending\n\n\n\n\n\n\n\n\nWe can also flip a bar chart on its axis to create a “sideways” bar chart by using thecoord_flip() function. The code below takes the trade_southasia_ascending we created above, inverts the axes using coord_flip(), and assigns the result to a new object named, wdi_trade_inverted:\n\n# creates inverted bar chart of \"wdi_trade\" for South Asian Countries\n# and assigns to \"wdi_trade_inverted\"\nwdi_trade_inverted&lt;-trade_southasia_ascending+\n                      coord_flip()\n\nLet’s now print wdi_trade_inverted and view the reoriented bar chart:\n\n# prints \"wdi_trade_inverted\"\nwdi_trade_inverted\n\n\n\n\n\n\n\n\nWhen we use coord_flip() in ggplot2 it flips the axes (i.e. the x-axis becomes the y-axis and vice versa). As a result, the (now) x-axis labels in wdi_trade_inverted are difficult to read, and need to be adjusted. We can do so by modifying the “axis.text.x” argument within the theme() function:\n\n# fixes x axis labels\nwdi_trade_inverted&lt;-wdi_trade_inverted+\n                      theme(axis.text.x=element_text(angle=0))\n\nLet’s see what the plot looks like now:\n\n# prints updated \"wdi_trade_inverted\"\nwdi_trade_inverted\n\n\n\n\n\n\n\n\n\n\n5.5.2 Scatterplots\nNow, let’s see how we can use similar principles and syntax to build scatterplots using ggplot2.\nBelow, we create a scatterplot of the wdi_taxrev and wdi_trade variables; we put the former on the x-axis and the latter variable on the y-axis. Instead of using geom_col() to create a bar chart, we use geom_point(); the remaining elements are similar to the bar charts we created above. We’ll assign the scatterplot to a new object named tax_trade_scatter:\n\n# Creates scatterplot with \"wdi_taxrev\" variable on x-axis and \"wdi_trade\" \n# variable on y-axis and assigns to object named \"tax_trade_scatter\"\ntax_trade_scatter&lt;-\n  ggplot(qog_copy_selection)+\n    geom_point(aes(x=wdi_taxrev, y=wdi_trade))+\n    labs(title=\"Relationship Between Trade and Tax Revenue as % of GDP\\n(2017-2021)\",\n       x=\"Tax Revenue as a % of GDP\", \n       y=\"Trade as a % of GDP\",\n       caption = \"Source: Quality of Government Institute\")+\n    theme(plot.title=element_text(size=11, hjust=0.5),\n        axis.title.x=element_text(size=10),\n        axis.title.y=element_text(size=10))\n\nLet’s print tax_trade_scatter and see what the plot looks like:\n\n# prints \"tax_trade_scatter\"\ntax_trade_scatter\n\nWarning: Removed 59 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nSometimes, we may wish to distinguish between different groups in a scatterplot. One way to do that is to assign different colors to different groups of interest. For example, if we wanted to distinguish continents in the scatterplot, we could specify color=region in the aesthetic mapping. The code below does so, and assigns the result to a new object named tax_trade_scatter_color:\n\n# uses color to distinguish between observations from different regions in the scatterplot \ntax_trade_scatter_color&lt;-\n  ggplot(qog_copy_selection)+\n  geom_point(aes(x=wdi_taxrev, y=wdi_trade, color=region))+\n  labs(title=\"Relationship Between Trade and Tax Revenue as % of GDP\\n(2017-2021)\",\n       x=\"Tax Revenue as a % of GDP\", \n       y=\"Trade as a % of GDP\",\n       caption = \"Source: Quality of Government Institute\")+\n  theme(plot.title=element_text(size=11, hjust=0.5),\n        axis.title.x=element_text(size=10),\n        axis.title.y=element_text(size=10))\n\nLet’s print tax_trade_scatter_color, and confirm that observations from different regions have been assigned different colors:\n\n# prints \"tax_trade_scatter_color\"\ntax_trade_scatter_color\n\nWarning: Removed 59 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nAn alternative way of parsing categories is to use facets, which create separate visualizations for each of the different categories in a dataset. Below, for example, we use facets to create separate scatterplots for each region; we take the tax_revenue_scatter plot that we created above, and then call the facet_wrap() function to facet by region, and distribute the resulting plots across two different rows:\n\n# uses facets to make panel of different scatter plot ofs \"wdi_trade\" and \"wdi_taxrev\" \n# for each region\ntax_trade_scatter_facets&lt;-\n tax_trade_scatter+\n  facet_wrap(~region, nrow=2)\n\nLet’s print the newly created scatter plot, faceted by region:\n\n# prints \"tax_trade_scatter_facets\"\ntax_trade_scatter_facets\n\nWarning: Removed 59 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nFinally, it’s important to note that it’s possible to layer different geometries over each other. For example, the code below layers a line of best fit (using the geom_smooth() function) over the scatterplot of “wdi_taxrev” and “wdi_trade”, and assigns the resulting plot to a new object named tax_trade_scatter_line:\n\n# layers line of best fit over scatterplot; wdi_trade on y axis axis \n# and wdi_taxrev on x axis; assigns new plot to object named \n# \"tax_trade_scatter_line\"\ntax_trade_scatter_line&lt;-\n  ggplot(data=qog_copy_selection)+\n  geom_point(aes(x=wdi_taxrev, y=wdi_trade))+\n  geom_smooth(aes(x=wdi_taxrev, y=wdi_trade), method=\"lm\")+\n  labs(title=\"Relationship Between Trade and Tax Revenue as % of GDP\\n(2017-2021)\",\n       x=\"Tax Revenue as a % of GDP\", \n       y=\"Trade as a % of GDP\",\n       caption = \"Source: Quality of Government Institute\")+\n  theme(plot.title=element_text(size=11, hjust=0.5),\n        axis.title.x=element_text(size=10),\n        axis.title.y=element_text(size=10))\n\nLet’s print tax_trade_scatter_line and confirm that the scatterplot now has a line of best fit superimposed on the data:\n\n# prints \"tax_trade_scatter_line\"\ntax_trade_scatter_line\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 59 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 59 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nNote that the geom_smooth() function that we used to create the line of best fit automatically draws 95% confidence intervals around the line; this default behavior can be modified using the “se” and “level” arguments within geom_smooth() (for more information, see the function’s documentation).\nIn some cases, we may want to different overlay geometries on a single plot, but those geometries may be based on different datasets (unlike the tax_trade_scatter_line plot, in which both geometries are drawn from a single underlying dataset). The syntax of ggplot2 can accommodate this in fairly straightforward fashion. For example, suppose we want to draw a horizontal line on trade_southasia_descending to indicate the average value of trade as a percentage of GDP for the countries in the qog_south_asia dataset; this will allow the viewer to easily tell whether a given country’s trade share of GDP is above or below the average value for all the countries in the dataset.\nTo add this horizontal dashed line, we’ll first create a separate data frame that contains the average value for “wdi_trade” within qog_south_asia and assign it to a new object named south_asia_trade_average:\n\n# creates new single-row data frame with mean value of \"wdi_trade\"\n# variable from \"south_asia_trade_average\" data frame, and sets the\n# name of the column containing this value to \"meanSA_trade\"\nsouth_asia_trade_average&lt;-\n  as.data.frame(mean(qog_south_asia$wdi_trade)) %&gt;% \n    rename(meanSA_trade=`mean(qog_south_asia$wdi_trade)`)\n\nWe’ll print south_asia_trade_average to confirm it looks as expected:\n\n# prints \"south_asia_trade_average\"\nsouth_asia_trade_average\n\n  meanSA_trade\n1     44.77935\n\n\nNow, let’s create our plot, in which a horizontal line based on the information in south_asia_trade_average is overlaid on trade_southasia_descending :\n\n# makes bar chart of \"wdi_trade\" variable from \"qog_south_asia\" data\n# frame arrayed in descending order, along with a dark red horizontal \n# line indicating the average \"wdi_trade\" value in the dataset, taken \n# from \"south_asia_trade_average\" \nggplot(data=qog_south_asia)+\n  geom_col(aes(x=reorder(cname, -wdi_trade), y=wdi_trade))+\n  geom_hline(data=south_asia_trade_average,\n             aes(yintercept=meanSA_trade),\n             linetype=\"dashed\",\n             color=\"darkred\")+\nlabs(title=\"Trade as a Percentage of GDP in South Asia\\n(2017-2020)\",\n     caption = \"Source: Quality of Government Institute\", \n     x=\"Country\", \n    y=\"Trade as a Percentage of GDP\")+\ntheme(plot.title=element_text(hjust=0.5),\n      axis.text.x = element_text(angle = 90))\n\n\n\n\n\n\n\n\nThe key point to note is that data=qog_south_asia is set in ggplot(), and the geom_col() function therefore knows to draw the columns with respect to this dataset. However, we want to create the line geometry in geom_hline() using the south_asia_trade_average data frame, so we explicitly specify this within that function. If we did not do this, geom_hline() would assume that the relevant reference data is qog_south_asia. The final result is a plot with different geometries that are created using different reference datasets.\nAs we have already mentioned, our discussion of ggplot2 here scratches the surface of its capabilities. However, you will be able to build on this introduction to the grammar of graphics and corresponding ggplot2 functions and syntax to make more complex exploratory and publication-quality plots that are relevant to your own work.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Elementary Data Visualization and Analysis</span>"
    ]
  },
  {
    "objectID": "session4.html#basic-statistics-and-linear-regression",
    "href": "session4.html#basic-statistics-and-linear-regression",
    "title": "5  Elementary Data Visualization and Analysis",
    "section": "5.6 Basic Statistics and Linear Regression",
    "text": "5.6 Basic Statistics and Linear Regression\nIn this section, we’ll review some functions that can implement some basic data analysis tasks, with a focus on linear regression (given its importance in empirical social science). Our focus is not on the methodologies themselves, or deeper questions about drawing inferences from data and the appropriateness of various models in different contexts. Our goal is simply to provide you with a tour of how to implement some standard statistical procedures in R; if you continue to use R, you will quickly come to appreciate the enormous resources if offers for statistical work. Indeed, it is in this domain that R really shines. As with the section on data visualization, our goal here is to provide a brief introduction that provides a starting point for your own exploration.\n\n5.6.1 Correlations\nBefore turning to regression analysis, it can be useful to compute simple bivariate correlations between variables of interest. In the section on visualization, we created a scatterplot showing the relationship between the “wdi_trade” and “wdi_taxrev” variables from qog_copy_selection; now, let’s quantify this relationship by computing the correlation coefficient between these variables. We can do so by passing the variables to the cor.test() function; we’ll then assign the output a new object named tax_trade_cc:\n\n# computes correlation coefficient between \"wdi_taxrev\" and \"wdi_trade\" variables and assigns \n# the result to a new object named \"trade_cgexp_cc\"\ntax_trade_cc&lt;-cor.test(qog_copy_selection$wdi_trade, qog_copy_selection$wdi_taxrev)\n\nLet’s print tax_trade_cc to see what this output looks like:\n\n# prints results of \"tax_trade_cc\"\ntax_trade_cc\n\n\n    Pearson's product-moment correlation\n\ndata:  qog_copy_selection$wdi_trade and qog_copy_selection$wdi_taxrev\nt = 3.2268, df = 133, p-value = 0.001576\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.1052899 0.4193207\nsample estimates:\n      cor \n0.2694536 \n\n\nThis provides us with the relevant information that we need, but it could be helpful if the output was formatted in a more streamlined fashion. To generate a “cleaner” output, we can pass tax_trade_cc as an argument to the broom package’s tidy() function; we’ll assign this output to a new object named tax_trade_clean_corr and then print it to the console:\n\n# assigns well-formatted model output to \"trade_cgexp_cc_clean\"\ntax_trade_clean_corr&lt;-broom::tidy(tax_trade_cc)\n\n# prints contents of \"tax_trade_clean_corr\"\ntax_trade_clean_corr\n\n# A tibble: 1 × 8\n  estimate statistic p.value parameter conf.low conf.high method     alternative\n     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      \n1    0.269      3.23 0.00158       133    0.105     0.419 Pearson's… two.sided  \n\n\nIf we want to quickly inspect the correlations between several variables in a dataset, we can use the the cor() function to generate a correlation matrix. To illustrate the use of this function, we’ll generate a correlation matrix that concisely displays the correlations between all of the continuous variables in qog_copy_selection_numeric. First we’ll generate a new dataset that contains only the continuous variables of interest, by dropping the dichotomous variables from qog_copy_selection_numeric using the select() function; we’ll assign this dataset to an object named qog_copy_selection_numeric_continuous:\n\n# removes dummy variables from \"qog_copy_selection_numeric\" \n# before making correlation matrix\nqog_copy_selection_numeric_continuous&lt;-\n  qog_copy_selection_numeric %&gt;% \n    dplyr::select(-c(atop_ally, bmr_dem, gol_est))\n\nNow, we’ll pass qog_copy_selection_numeric_continuous to the cor() function to generate our correlation and matrix, rounding to two digits.\n\n# creates correlation matrix for observations in \n# \"qog_copy_selection_numeric_continuous\" and assigns result \n# to object named \"qog_copy_selection_numeric_cor_matrix\"\nqog_copy_selection_numeric_cor_matrix&lt;-round(cor(qog_copy_selection_numeric_continuous, use=\"complete.obs\"), 2)\n\nWhen we print the correlation matrix, it looks something like this:\n\n# prints \"qog_copy_selection_numeric_cor_matrix\"\nqog_copy_selection_numeric_cor_matrix\n\n                      undp_hdi wdi_expedu wdi_acel wdi_area wdi_taxrev\nundp_hdi                  1.00       0.66     0.44    -0.32       0.46\nwdi_expedu                0.66       1.00     0.25    -0.29       0.64\nwdi_acel                  0.44       0.25     1.00     0.05       0.09\nwdi_area                 -0.32      -0.29     0.05     1.00      -0.47\nwdi_taxrev                0.46       0.64     0.09    -0.47       1.00\nwdi_expmil               -0.04      -0.20     0.15     0.56      -0.17\nwdi_fdiin                -0.25       0.10    -0.06     0.06       0.16\nwdi_trade                 0.41       0.31     0.16    -0.57       0.35\ncbie_index                0.17      -0.04    -0.07    -0.59      -0.03\nwbgi_rle                  0.92       0.70     0.38    -0.40       0.47\nmad_gdppc                 0.86       0.64     0.35    -0.18       0.34\nmad_gdppc1900             0.77       0.47     0.32    -0.19       0.27\nbci_bci                  -0.89      -0.76    -0.42     0.41      -0.51\nlis_gini                 -0.81      -0.45    -0.46     0.36      -0.46\ntop_top1_income_share    -0.76      -0.37    -0.55     0.46      -0.33\nwdi_wip                   0.44       0.48    -0.08    -0.63       0.38\n                      wdi_expmil wdi_fdiin wdi_trade cbie_index wbgi_rle\nundp_hdi                   -0.04     -0.25      0.41       0.17     0.92\nwdi_expedu                 -0.20      0.10      0.31      -0.04     0.70\nwdi_acel                    0.15     -0.06      0.16      -0.07     0.38\nwdi_area                    0.56      0.06     -0.57      -0.59    -0.40\nwdi_taxrev                 -0.17      0.16      0.35      -0.03     0.47\nwdi_expmil                  1.00      0.15     -0.48      -0.37    -0.18\nwdi_fdiin                   0.15      1.00     -0.34      -0.10    -0.21\nwdi_trade                  -0.48     -0.34      1.00       0.57     0.37\ncbie_index                 -0.37     -0.10      0.57       1.00     0.13\nwbgi_rle                   -0.18     -0.21      0.37       0.13     1.00\nmad_gdppc                   0.03     -0.30      0.26       0.06     0.81\nmad_gdppc1900               0.09     -0.36      0.25      -0.11     0.76\nbci_bci                     0.22      0.22     -0.40      -0.07    -0.97\nlis_gini                   -0.02      0.10     -0.60      -0.34    -0.69\ntop_top1_income_share       0.20      0.15     -0.47      -0.32    -0.73\nwdi_wip                    -0.58     -0.12      0.46       0.40     0.40\n                      mad_gdppc mad_gdppc1900 bci_bci lis_gini\nundp_hdi                   0.86          0.77   -0.89    -0.81\nwdi_expedu                 0.64          0.47   -0.76    -0.45\nwdi_acel                   0.35          0.32   -0.42    -0.46\nwdi_area                  -0.18         -0.19    0.41     0.36\nwdi_taxrev                 0.34          0.27   -0.51    -0.46\nwdi_expmil                 0.03          0.09    0.22    -0.02\nwdi_fdiin                 -0.30         -0.36    0.22     0.10\nwdi_trade                  0.26          0.25   -0.40    -0.60\ncbie_index                 0.06         -0.11   -0.07    -0.34\nwbgi_rle                   0.81          0.76   -0.97    -0.69\nmad_gdppc                  1.00          0.63   -0.78    -0.63\nmad_gdppc1900              0.63          1.00   -0.73    -0.47\nbci_bci                   -0.78         -0.73    1.00     0.66\nlis_gini                  -0.63         -0.47    0.66     1.00\ntop_top1_income_share     -0.60         -0.46    0.70     0.77\nwdi_wip                    0.40          0.29   -0.41    -0.33\n                      top_top1_income_share wdi_wip\nundp_hdi                              -0.76    0.44\nwdi_expedu                            -0.37    0.48\nwdi_acel                              -0.55   -0.08\nwdi_area                               0.46   -0.63\nwdi_taxrev                            -0.33    0.38\nwdi_expmil                             0.20   -0.58\nwdi_fdiin                              0.15   -0.12\nwdi_trade                             -0.47    0.46\ncbie_index                            -0.32    0.40\nwbgi_rle                              -0.73    0.40\nmad_gdppc                             -0.60    0.40\nmad_gdppc1900                         -0.46    0.29\nbci_bci                                0.70   -0.41\nlis_gini                               0.77   -0.33\ntop_top1_income_share                  1.00   -0.26\nwdi_wip                               -0.26    1.00\n\n\nWe can also view the correlation matrix in the data viewer:\n\nView(qog_copy_selection_numeric_cor_matrix)\n\n\n\n\n\n\n\n\n\n5.6.2 Bivariate and Multiple Regression\nWe can run a linear regression model in R using the lm() function, where the first argument is an expression that takes the form dependent_variable~independent_variable, and the second argument specifies the underlying dataset that contains the relevant variables. In cases where there is more than one independent variable (i.e. in a multiple regression context), the various independent variables can be separated with a “+” sign (i.e. dependent_variable~independent_variable1 + independent_variable2 + independent_variable3~). Below, we demonstrate how to implement a bivariate regression, by regressing “wdi_trade” on “wdi_taxrev” (using the data from qog_copy_selection). We assign the regression output to a new object named regression1:\n\n# implements bivariate regression with \"wdi_trade\" as DV and \"wdi_taxrev\" as IV; \n# regresion output assigned to \"regression1\" object\nregression1&lt;-lm(wdi_trade~wdi_taxrev, data=qog_copy_selection)\n\nNow that we’ve run the regression, and assigned its corresponding output to the regression1 object, we can print the output (which contains the relevant regression coefficients and standard errors) by passing regression1 to the summary() function:\n\n# prints output of \"regresion1\"\nsummary(regression1)\n\n\nCall:\nlm(formula = wdi_trade ~ wdi_taxrev, data = qog_copy_selection)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-67.50 -30.49 -17.67  10.61 279.40 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  54.1326    12.6885   4.266 3.75e-05 ***\nwdi_taxrev    2.3047     0.7142   3.227  0.00158 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 57.07 on 133 degrees of freedom\n  (59 observations deleted due to missingness)\nMultiple R-squared:  0.07261,   Adjusted R-squared:  0.06563 \nF-statistic: 10.41 on 1 and 133 DF,  p-value: 0.001576\n\n\nNow, we’ll add some additional independent variables using a “+” sign, and assign the output to regression2:\n\n# Implements multiple regression with \"wdi_trade\" as DV, \n# and assigns output to object named \"regression2\"\nregression2&lt;-lm(wdi_trade~+wdi_taxrev+wdi_area+wdi_expmil+bmr_dem+top_top1_income_share+undp_hdi, data=qog_copy_selection)\n\nAs before, we can pass the regression output object as an argument to the summary() function to print the regression results:\n\n# prints regression2 output\nsummary(regression2)\n\n\nCall:\nlm(formula = wdi_trade ~ +wdi_taxrev + wdi_area + wdi_expmil + \n    bmr_dem + top_top1_income_share + undp_hdi, data = qog_copy_selection)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-82.299 -25.942  -6.451  17.967 237.258 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           -2.826e+01  3.480e+01  -0.812  0.41852    \nwdi_taxrev             2.687e+00  8.646e-01   3.107  0.00240 ** \nwdi_area              -6.050e-06  2.101e-06  -2.880  0.00478 ** \nwdi_expmil            -8.393e+00  4.180e+00  -2.008  0.04706 *  \nbmr_dem               -3.441e+01  1.246e+01  -2.761  0.00675 ** \ntop_top1_income_share -6.164e+01  1.093e+02  -0.564  0.57373    \nundp_hdi               1.711e+02  3.689e+01   4.639 9.64e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 48.54 on 111 degrees of freedom\n  (76 observations deleted due to missingness)\nMultiple R-squared:  0.3342,    Adjusted R-squared:  0.2982 \nF-statistic: 9.286 on 6 and 111 DF,  p-value: 3.055e-08\n\n\nSometimes, it is desirable or necessary to transform variables before they are included in a regression model. Of course, one could add the transformed variable to the dataset using mutate(), and then add it to the regression model, but it’s also possible to make simple variable transformations “on the fly”. For instance, instead of adding “wdi_area”, let’s say we want to add the natural logarithm of “wdi_area” to the model; we can do so by simply adding log(wdi_area) to the model, as below (we’ll assign the resulting output to regression2, and thereby override the previously created object):\n\n# Implements multiple regression with \"wdi_trade\" as DV, \n# and assigns output to object named \"regression2\"\nregression2&lt;-lm(wdi_trade~wdi_taxrev+log(wdi_area)+wdi_expmil+bmr_dem+top_top1_income_share+undp_hdi, data=qog_copy_selection)\n\n# prints updated output\nregression2\n\n\nCall:\nlm(formula = wdi_trade ~ wdi_taxrev + log(wdi_area) + wdi_expmil + \n    bmr_dem + top_top1_income_share + undp_hdi, data = qog_copy_selection)\n\nCoefficients:\n          (Intercept)             wdi_taxrev          log(wdi_area)  \n              163.730                  1.807                -14.472  \n           wdi_expmil                bmr_dem  top_top1_income_share  \n               -8.028                -27.183                -12.786  \n             undp_hdi  \n              140.767  \n\n\nNote that we can also use the broom package’s tidy() function to organize and view the regression output:\n\n# prints regression output using \"tidy\" function\nbroom::tidy(regression2)\n\n# A tibble: 7 × 5\n  term                  estimate std.error statistic  p.value\n  &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)             164.      37.5       4.37  2.84e- 5\n2 wdi_taxrev                1.81     0.742     2.43  1.65e- 2\n3 log(wdi_area)           -14.5      1.95     -7.41  2.63e-11\n4 wdi_expmil               -8.03     3.54     -2.27  2.54e- 2\n5 bmr_dem                 -27.2     10.6      -2.56  1.18e- 2\n6 top_top1_income_share   -12.8     91.7      -0.139 8.89e- 1\n7 undp_hdi                141.      30.5       4.62  1.04e- 5\n\n\nLater, we’ll learn how to assemble regression results into publication-quality regression tables.\n\n\n5.6.3 Categorical Variables in Regression Models\nIf we want to add categorical variables to a regression model, we can directly include variables that are of the class “character” without running into any issues. Under the hood, R will convert those character variables into dichotomous variables, and calculate the regression coefficients and standard errors accordingly. To see this, let’s try adding the “region” variable to regression2 above. First, we’ll confirm that the “region” variable is of the character class:\n\n# confirms that \"region\" is of class character\nclass(qog_copy_selection$region)\n\n[1] \"character\"\n\n\n\n# adds \"region\" categorical variable (of class \"character\") in \n# regression model and assigns it to a new object named \"regression3\"\nregression3&lt;-lm(wdi_trade~+wdi_taxrev+log(wdi_area)+wdi_expmil+bmr_dem+top_top1_income_share+undp_hdi+region, data=qog_copy_selection)\n\nLet’s now print the regression3 output:\n\n# prints contents of \"regression3\" object\nsummary(regression3)\n\n\nCall:\nlm(formula = wdi_trade ~ +wdi_taxrev + log(wdi_area) + wdi_expmil + \n    bmr_dem + top_top1_income_share + undp_hdi + region, data = qog_copy_selection)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-66.240 -23.213  -2.547  20.048 199.484 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                     128.0267    63.6460   2.012   0.0469 *  \nwdi_taxrev                        1.5045     0.7972   1.887   0.0620 .  \nlog(wdi_area)                   -15.1387     2.1516  -7.036 2.33e-10 ***\nwdi_expmil                       -7.6143     4.0386  -1.885   0.0622 .  \nbmr_dem                         -17.2052    11.5473  -1.490   0.1393    \ntop_top1_income_share           101.6392   110.6312   0.919   0.3604    \nundp_hdi                        103.9597    53.2017   1.954   0.0534 .  \nregionEastAsia                   50.0052    48.6743   1.027   0.3067    \nregionEasternEuropePostSoviet    63.4546    43.7913   1.449   0.1504    \nregionLatinAmerica               34.6228    43.4997   0.796   0.4279    \nregionNorthAfricaMiddleEast      42.0853    45.8175   0.919   0.3605    \nregionPacific                    17.0738    58.1295   0.294   0.7696    \nregionSouthAsia                  20.3102    46.7917   0.434   0.6652    \nregionSouthEastAsia              84.2277    44.7907   1.880   0.0629 .  \nregionSubSaharanAfrica           43.9737    42.4805   1.035   0.3030    \nregionWesternEuropeNorthAmerica  60.8143    45.4060   1.339   0.1834    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 40.67 on 102 degrees of freedom\n  (76 observations deleted due to missingness)\nMultiple R-squared:  0.5704,    Adjusted R-squared:  0.5072 \nF-statistic: 9.028 on 15 and 102 DF,  p-value: 5.891e-13\n\n\nNote that “Caribbean” is the excluded category that serves as the reference with against which the effects of the other regional categories are interpreted. If we are okay with accepting the default excluded category (which is always the first category by alphabetical order, hence “Caribbean” as the excluded category in this case) running the regression with a character variable is perfectly fine and provides valid results.\nHowever, if we want to change the reference category, we’ll have to either use a factor variable or create and include dummy variables in our regression. In R, a factor is a data type that’s specifically designed for categorical variables; factors consider each separate category within a categorical variable as a distinct “level”, which allows them to be treated as dummy variables in regression models. Indeed, when we include a categorical variable of the “character” class, R converts that variable into a factor under the hood before including it in the regression, with the “levels” being treated as dummy variables, and the excluded level being the category that is first in alphabetical order. If we want to change the excluded level, we have to get under the hood and “relevel” the factor, so that the desired excluded category is first in the factor order.\nTo see how this works, let’s say that we want to make “LatinAmerica” the reference variable. First, we’ll first change the region variable from a “character” variable to a “factor” variable:\n\n# Set \"region\" variable as factor\nqog_copy_selection$region&lt;-as.factor(qog_copy_selection$region)\n\nBefore proceeding, well confirm that the conversion has successfully taken place:\n\n# confirm conversion\nclass(qog_copy_selection$region)\n\n[1] \"factor\"\n\n\nNow, we’ll check the levels of the “region” factor variable using the levels() function:\n\n# check levels of \"region\" factor variable\nlevels(qog_copy_selection$region)\n\n [1] \"Caribbean\"                 \"EastAsia\"                 \n [3] \"EasternEuropePostSoviet\"   \"LatinAmerica\"             \n [5] \"NorthAfricaMiddleEast\"     \"Pacific\"                  \n [7] \"SouthAsia\"                 \"SouthEastAsia\"            \n [9] \"SubSaharanAfrica\"          \"WesternEuropeNorthAmerica\"\n\n\nNote that by default, the levels are arrayed in alphabetical order. Let’s relevel the region variable, and set “LatinAmerica” as the excluded/reference category using the relevel() function:\n\n# Relevels \"region\" factor variable to set \"LatinAmerica\" as reference category\nqog_copy_selection$region&lt;-relevel(qog_copy_selection$region, ref=\"LatinAmerica\")\n\nLet’s confirm that the releveling has successfully taken place:\n\n# check levels of \"region\" factor variable\nlevels(qog_copy_selection$region)\n\n [1] \"LatinAmerica\"              \"Caribbean\"                \n [3] \"EastAsia\"                  \"EasternEuropePostSoviet\"  \n [5] \"NorthAfricaMiddleEast\"     \"Pacific\"                  \n [7] \"SouthAsia\"                 \"SouthEastAsia\"            \n [9] \"SubSaharanAfrica\"          \"WesternEuropeNorthAmerica\"\n\n\nNote that “LatinAmerica” is now the first category, which means that it will be used as the reference/excluded category in a regression. Let’s confirm this by running a regression with the “region” factor variable and assigning the output to a new object named regression4:\n\n# runs regression with releveled factor variable with \"LatinAmerica\" as # reference and assigns output to \"regression4\"\nregression4&lt;-lm(wdi_trade~+wdi_taxrev+log(wdi_area)+wdi_expmil+bmr_dem+top_top1_income_share+undp_hdi+region, data=qog_copy_selection)\n\nLet’s print the regression output and confirm that “LatinAmerica” is the excluded regional category:\n\n# prints model output for \"regression4\"\nbroom::tidy(regression4)\n\n# A tibble: 16 × 5\n   term                            estimate std.error statistic  p.value\n   &lt;chr&gt;                              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)                       163.      54.0       3.01  3.28e- 3\n 2 wdi_taxrev                          1.50     0.797     1.89  6.20e- 2\n 3 log(wdi_area)                     -15.1      2.15     -7.04  2.33e-10\n 4 wdi_expmil                         -7.61     4.04     -1.89  6.22e- 2\n 5 bmr_dem                           -17.2     11.5      -1.49  1.39e- 1\n 6 top_top1_income_share             102.     111.        0.919 3.60e- 1\n 7 undp_hdi                          104.      53.2       1.95  5.34e- 2\n 8 regionCaribbean                   -34.6     43.5      -0.796 4.28e- 1\n 9 regionEastAsia                     15.4     25.3       0.608 5.45e- 1\n10 regionEasternEuropePostSoviet      28.8     17.1       1.68  9.56e- 2\n11 regionNorthAfricaMiddleEast         7.46    22.3       0.335 7.38e- 1\n12 regionPacific                     -17.5     42.9      -0.410 6.83e- 1\n13 regionSouthAsia                   -14.3     23.9      -0.598 5.51e- 1\n14 regionSouthEastAsia                49.6     20.2       2.46  1.57e- 2\n15 regionSubSaharanAfrica              9.35    17.1       0.548 5.85e- 1\n16 regionWesternEuropeNorthAmerica    26.2     19.8       1.32  1.89e- 1\n\n\nIf we want full control over the excluded/reference category when including categorical variables, another option is to simply create dichotomous/dummy variables based on the categorical variable, and explicitly decide which dichotomous variable to exclude as the reference category. To make these dummy variables, we can (as we have learned), use the dummy_cols() function from the fastDummies package.\nTo illustrate, let’s make dummy variables based on the “region” variable:\n\n# Use \"region\" field to make region dummy variables in \"qog_copy_selection\"\nqog_copy_selection&lt;-qog_copy_selection %&gt;% dummy_cols(\"region\")\n\nNow, we will generate another regression, assigned to the new object named regression5, that adds these dummy variables, while excluding “LatinAmerica” as the reference variable:\n\n# includes dummy variables in regression with \"LatinAmerica\" as the \n# excluded category; model output assigned to object named \n# \"regression5\"\nregression5&lt;-lm(wdi_trade~wdi_taxrev+log(wdi_area)++wdi_expmil+bmr_dem+top_top1_income_share+undp_hdi+region_Caribbean+region_EastAsia+region_EasternEuropePostSoviet+region_NorthAfricaMiddleEast+region_Pacific+region_SouthAsia+region_SouthEastAsia+region_SubSaharanAfrica+region_WesternEuropeNorthAmerica, data=qog_copy_selection)\n\nLet’s print the results from regression5:\n\n# prints model output for \"regression5\"\nbroom::tidy(regression5)\n\n# A tibble: 16 × 5\n   term                             estimate std.error statistic  p.value\n   &lt;chr&gt;                               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)                        163.      54.0       3.01  3.28e- 3\n 2 wdi_taxrev                           1.50     0.797     1.89  6.20e- 2\n 3 log(wdi_area)                      -15.1      2.15     -7.04  2.33e-10\n 4 wdi_expmil                          -7.61     4.04     -1.89  6.22e- 2\n 5 bmr_dem                            -17.2     11.5      -1.49  1.39e- 1\n 6 top_top1_income_share              102.     111.        0.919 3.60e- 1\n 7 undp_hdi                           104.      53.2       1.95  5.34e- 2\n 8 region_Caribbean                   -34.6     43.5      -0.796 4.28e- 1\n 9 region_EastAsia                     15.4     25.3       0.608 5.45e- 1\n10 region_EasternEuropePostSoviet      28.8     17.1       1.68  9.56e- 2\n11 region_NorthAfricaMiddleEast         7.46    22.3       0.335 7.38e- 1\n12 region_Pacific                     -17.5     42.9      -0.410 6.83e- 1\n13 region_SouthAsia                   -14.3     23.9      -0.598 5.51e- 1\n14 region_SouthEastAsia                49.6     20.2       2.46  1.57e- 2\n15 region_SubSaharanAfrica              9.35    17.1       0.548 5.85e- 1\n16 region_WesternEuropeNorthAmerica    26.2     19.8       1.32  1.89e- 1\n\n\nNote that the coefficients and standard errors are the same as the results in regression5; this is expected since both regressions ultimately use dummy variables with “LatinAmerica” as the excluded reference category (even though they set it as the reference category in different ways).\n\n\n5.6.4 Interaction Terms in a Regression\nIt is often useful to include interaction terms in our regression models. Interaction terms allow us to explore situations in which the effect of one independent variable depends on the value of another independent variable. In R, interaction terms can be defined with a “*” between the two components of the interaction. When an interaction term is included in a regression model using the “*” operator, there is no need to include the individual components of the interaction separately in the model, because R automatically includes the main effects by default.\nLet’s explore a simple regression model with an interaction term between “wdi_taxrev” and “bmr_dem”, which is a dichotomous variable that indicates whether a country is a democracy. The dependent variable remains “wdi_trade”. Below, we’ll run the model, and assign the output to an object named taxrev_democracy_interaction:\n\n# run regression with interaction term between \"wdi_taxrev\" and \"bmr_dem\"\ntaxrev_democracy_interaction&lt;-lm(wdi_trade~wdi_taxrev*bmr_dem, data=qog_copy_selection)\n\nLet’s now print the regression results:\n\n# prints regression results of \"taxrev_democracy_interaction\"\nsummary(taxrev_democracy_interaction)\n\n\nCall:\nlm(formula = wdi_trade ~ wdi_taxrev * bmr_dem, data = qog_copy_selection)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-71.74 -30.47 -13.44  13.19 272.78 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         78.5060    19.2650   4.075 7.93e-05 ***\nwdi_taxrev           0.1516     1.4607   0.104   0.9175    \nbmr_dem            -39.4475    27.0224  -1.460   0.1467    \nwdi_taxrev:bmr_dem   2.9917     1.7501   1.709   0.0897 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 56.87 on 131 degrees of freedom\n  (59 observations deleted due to missingness)\nMultiple R-squared:  0.09307,   Adjusted R-squared:  0.0723 \nF-statistic: 4.481 on 3 and 131 DF,  p-value: 0.004982\n\n\nThe interpretation of regression results in the context of an interaction term is of course tricky, since the coefficients on the individual variables that are part of the interaction term can no longer be interpreted in isolation. They can only be interpreted in conjunction with the other component of the interaction. Let’s say, for example, that we’re interested in the impact of democracy (“bmr_dem”) on trade as a share of GDP (“wdi_trade”). Given the interaction term, we cannot simply infer that the trade share of GDP is 39.4 percentage points lower in democracies, on average, than non-democracies. The coefficient on “bmr_dem” tells us that the trade share of GDP is on average 39.4 points lower for democracies when “wdi_taxrev” equals 0. However, this information is of limited substantive value, since all governments collect at least some tax revenue. Conversely, the coefficient on “wdi_taxrev” tells us the impact of a unit change in “wdi_taxrev” on “wdi_trade” for non-democracies (where “bmr_dem” is 0) but not for democracies (where “bmr_dem” is 1).\nInstead of trying to interpret the impact of “wdi_taxrev” and “bmr_dem” on “wdi_trade” from just looking at the regression table, it would be more useful to get a sense of the substantive impact of each of these variables while accounting for the interaction term by assigning meaningful values to the moderating variable. In particular, we’ll calculate predicted values that demonstrate the substantive impact of each of these variables in the context of the interaction, and also plot these predicted values to visualize the impact of the independent variables after accounting for the interactive effect.\nWe’ll begin by calculating the predicted values of “wdi_trade” for democracies and non-democracies, while holding “wdi_taxrev” at its mean. First, we’ll calculate the mean value of “wdi_taxrev”:\n\n# Finds mean value of \"wdi_taxrev\" variable and assigns to\n# object named \"mean_taxrev\" \nmean_taxrev&lt;-mean(qog_copy_selection$wdi_taxrev, na.rm=TRUE)\n\nNow, we’ll use the ggeffects package’s ggpredict() function to calculate the predicted values of “wdi_trade” for different values of “bmr_dem” (i.e. for democracies and non-democracies) while holding “wdi_taxrev” at its mean:\n\n# Calculates predicted values of \"wdi_trade\" for different values of \n# \"bmr_dem\", with \"wdi_taxrev\" held at mean\npredicted_values_democracy&lt;-ggpredict(model=taxrev_democracy_interaction, term=\"bmr_dem\", condition=c(wdi_taxrev=mean_taxrev))\n\nIn the code above, the first argument specifies the regression model for which we want to calculate predicted values; the second argument is the independent variable whose impact on the dependent variable we want to predict; and the third argument specifies the value at which the moderating variable should be held when calculating the predicted values. We assigned the predicted values output to a new object named predicted_values_democracy, which we’ll now inspect:\n\n# Prints \"predicted_values_democracy\" table\npredicted_values_democracy\n\n# Predicted values of wdi_trade\n\nbmr_dem | Predicted |        95% CI\n-----------------------------------\n      0 |     80.96 | 59.97, 101.95\n      1 |     90.01 | 77.28, 102.75\n\n\nThese predicted values are generated by taking the regression equation and coefficients from taxrev_democracy_interaction, and plugging in the mean value of “wdi_taxrev” when “bmr_dem” is set to 0 and when it is set to 1.\nWe can plot these values, along with their 95% confidence intervals, using ggplot2. In order to more explicitly connect the arguments used to create the plot to the values in predicted_values_democracy, it is useful to print predicted_values_democracy as a data frame:\n\n# prints underlying structure of \"predicted_values_democracy\"\nprint(as.data.frame(predicted_values_democracy))\n\n  x predicted std.error conf.low conf.high group\n1 0  80.96319 10.609727 59.97462  101.9518     1\n2 1  90.01373  6.438564 77.27671  102.7507     1\n\n\nNow, let’s go ahead and make our plot, which we’ll assign to a new object named predicted_values_democracy_plotted:\n\n# creates plot of \"predicted_values_democracy\"; shows predicted values\n# of \"wdi_trade\" for different values of democracy (\"bmr_dem\") when \n# \"wdi_taxrev\" is held at mean\npredicted_values_democracy_plotted&lt;-\n  ggplot(predicted_values_democracy)+\n  geom_point(aes(x=x, y=predicted))+\n  geom_errorbar(aes(x, ymin=conf.low, ymax=conf.high), width=0.05)+\n  scale_x_continuous(breaks=seq(0,1, by=1))+\n  labs(title=\"Predicted Effects of Democracy on Trade\\n(with tax revenue as a share of GDP set to mean)\",\n       y=\"Predicted Trade Share of GDP\",\n       x=\"Democracy\")\n\nLet’s print predicted_values_democracy_plotted:\n\n# prints \"predicted_values_democracy_plotted\"\npredicted_values_democracy_plotted\n\n\n\n\n\n\n\n\nNow, let’s calculate the predicted values of “wdi_trade” for different values of “wdi_taxrev” for both democratic and non-democratic countries, by using the same ggpredict() function. The first argument to the ggpredict() function is the same as before; the second argument, terms=c(\"wdi_taxrev\", \"bmr_dem), indicates that we want to calculate predicted values across a range of tax revenues, for both democracies and non-democracies. We’ll assign these predicted values to a new object named predicted_values_taxrev:\n\n# calculates predicted values for trade share of GDP for\n# both values of the democracy indicator (bmr_dem=0 and 1), \n# across the observed range of \"wdi_taxrev\" and assigns the result\n# to \"predicted_values_taxrev\" object\npredicted_values_taxrev &lt;- ggpredict(model=taxrev_democracy_interaction, terms = c(\"wdi_taxrev\", \"bmr_dem\"))\n\nWhen we print predicted_values_taxrev it looks something like this:\n\n# prints contents of \"predicted_values_taxrev\"\npredicted_values_taxrev\n\n# Predicted values of wdi_trade\n\nbmr_dem: 0\n\nwdi_taxrev | Predicted |         95% CI\n---------------------------------------\n         0 |     78.51 |  40.40, 116.62\n        10 |     80.02 |  62.43,  97.62\n        20 |     81.54 |  52.61, 110.46\n        30 |     83.05 |  27.97, 138.13\n        40 |     84.57 |   1.50, 167.64\n        50 |     86.08 | -25.44, 197.61\n\nbmr_dem: 1\n\nwdi_taxrev | Predicted |         95% CI\n---------------------------------------\n         0 |     39.06 |   1.57,  76.54\n        10 |     70.49 |  50.18,  90.80\n        20 |    101.92 |  89.79, 114.06\n        30 |    133.36 | 108.67, 158.04\n        40 |    164.79 | 122.38, 207.20\n        50 |    196.22 | 135.27, 257.17\n\n\nBefore creating a plot, let’s print predicted_values_taxrev as a data frame:\n\n# prints contents of \"predicted_values_taxrev\" as data frame\nas.data.frame(predicted_values_taxrev)\n\n    x predicted std.error   conf.low conf.high group\n1   0  78.50602 19.265036  40.395182 116.61686     0\n2   0  39.05852 18.949079   1.572717  76.54432     1\n3  10  80.02177  8.895043  62.425258  97.61829     0\n4  10  70.49129 10.267926  50.178878  90.80369     1\n5  20  81.53753 14.622377  52.610982 110.46408     0\n6  20 101.92405  6.134634  89.788284 114.05982     1\n7  30  83.05329 27.842736  27.973714 138.13286     0\n8  30 133.35682 12.477095 108.674153 158.03949     1\n9  40  84.56904 41.992070   1.498713 167.63937     0\n10 40 164.78959 21.437415 122.381270 207.19791     1\n11 50  86.08480 56.375188 -25.438770 197.60837     0\n12 50 196.22236 30.810524 135.271794 257.17293     1\n\n\nNow, let’s go ahead and create a plot of these predicted values and assign the result to a new object named predicted_values_taxrev_plotted:\n\n# creates plot of \"predicted_values_taxrev\"; shows predicted values\n# of \"wdi_trade\" for both values of the democracy indicator across the \n# observed range of \"wdi_taxrev\" and assigns the result to \"predicted_values_taxrev_plotted\"\npredicted_values_taxrev_plotted &lt;-\n  ggplot(predicted_values_taxrev)+\n  geom_line(aes(x = x, y = predicted, color = group), linewidth = 1) +\n  geom_ribbon(aes(x=x, ymin = conf.low, ymax = conf.high, fill = group), alpha = 0.2, color = NA) +\n  labs(title = \"Predicted Effect of Tax Revenue on Trade Share of GDP\\nby Democracy Status\",\n       x = \"Tax Revenue (% of GDP)\",\n       y = \"Predicted Trade Share of GDP\",\n      color = \"Democracy\",\n      fill = \"Democracy\")+\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\nNote that since we are plotting a line, rather than single points, we use the geom_ribbon() geometry to show the confidence intervals. Let’s see what the plot looks like:\n\n# prints \"predicted_values_taxrev_plotted\"\npredicted_values_taxrev_plotted\n\n\n\n\n\n\n\n\nLet’s refine this plot by modifying the labels and colors of the legend, and how they map onto the lines and confidence intervals. We’ll start by creating vectors to store the desired colors and labels:\n\n# defines colors and labels\npv_colors&lt;-c(\"0\" = \"#1f77b4\", \"1\" = \"#d62728\")\npv_labels&lt;-c(\"0\" = \"Non-democracy\", \"1\" = \"Democracy\")\n\nNow, we’ll modify the plot using this styling. We’ll take the existing predicted_values_taxrev_plotted plot, and add this styling to the legend and the line (via scale_color_manual() and confidence intervals (via scale_fill_manual()). We’ll assign the modified plot to a new object named predicted_values_taxrev_plotted_refined:\n\n# refines appearance of \"predicted_values_taxrev_plotted\" by modifying # legend and colors\npredicted_values_taxrev_plotted_refined&lt;-\n  predicted_values_taxrev_plotted+\n  scale_color_manual(values=pv_colors, labels=pv_labels, name=\"Regime Type\")+\n  scale_fill_manual(values=pv_colors, labels=pv_labels, name=\"Regime Type\" )\n\nLets print predicted_values_taxrev_plotted_refined:\n\n# prints \"predicted_values_taxrev_plotted_refined\"\npredicted_values_taxrev_plotted_refined\n\n\n\n\n\n\n\n\nThe plot suggests that democracies tend to trade more as tax revenue as a share of GDP increases, while tax revenue does not have much of an impact on trade for non-democracies; however, the confidence intervals look like they overlap substantially, suggesting that the difference between regime types is likely small and that the interaction effect is weak. In other words, there does not appear to be a strong and unique “democracy effect” in the relationship between tax revenue as a share of GDP and trade as a share of GDP.\nSo far, we’ve tried to interpret our regression results in the presence of an interaction term by generating and plotting predicted values. The predicted values plots we created, in particular, show the expected outcomes for trade as a percentage of GDP for countries with different characteristics with respect to democracy and tax revenue. It is also useful to generate marginal effects plots; unlike a predicted values plot, which shows predicted values of the dependent variable on the y-axis, a marginal effects plot shows the partial derivative/slope of the independent variable of interest on the y-axis, and values of the moderating variable on the x-axis. This plot helps us visualize how a small change in the independent variable impacts the dependent variable for different values of the moderating variable, which allows us to get a sense of the strength of the interaction. That is, if the marginal effect changes meaningfully across values of the moderating variable, it suggests a powerful interaction effect; on the other hand, if the marginal effect does not meaningfully change across values of the moderating variable, it suggests a weak interaction effect.\nThe confidence intervals displayed on a marginal effects plot are especially useful. When the confidence intervals overlap with zero, it suggests that the impact of the independent variable of interest on the dependent variable of interest for a given level of the moderating variable is weak. On the other hand, in regions for the moderating variable where the confidence intervals do NOT include zero, it suggests a statistically significant impact of X on Y. Importantly, the impact of an independent variable of interest on the dependent variable may be statistically significant for some levels of the moderating variable but not others, and a marginal effects plot is especially useful in quickly identifying these “zones of significance”.\nThere are many ways to create a marginal effects plot, but the interplot package allows us to quickly generate useful marginal effects plots using the interplot() function. Below, we demonstrate the use of this interplot() function by creating a marginal effects plot that shows the impact of democracy on trade as a share of GDP across different levels of the moderating variable, tax revenues as a share of GDP (“wdi_taxrev”). We’ll assign this marginal effects plot to a new object named marginal_effect_democracy_plot:\n\n# Marginal effect of democracy (bmr_dem) on trade share of GDP across \n# different levels of the moderating variable (tax revenue as a share\n# of GDP)\nmarginal_effect_democracy_plot &lt;- \n  interplot(\n  m = taxrev_democracy_interaction, # model object\n  var1 = \"bmr_dem\",      # independent variable of interest\n  var2 = \"wdi_taxrev\") +    # moderator\n  labs(x = \"Tax Revenue (% of GDP)\",\n       y = \"Marginal Effect of Democracy on Trade\",\n       title = \"Marginal Effect of Democracy on Trade Across Tax Revenue\")+\n  theme_minimal()\n\nLet’s now print marginal_effect_democracy_plot:\n\n# prints \"marginal_effect_democracy_plot\"\nmarginal_effect_democracy_plot\n\n\n\n\n\n\n\n\nThe plot allows us to visualize the impact of regime type on trade at different levels of tax revenue; it suggests that the marginal effect of democracy increases as tax revenue rises, but the confidence intervals include zero across most of the observed range of the moderating variable, indicating that this relationship is not statistically distinguishable from zero at conventional confidence levels.\nNow, let’s visualize the marginal effect of tax revenue as a share of GDP on trade for different levels of democracy:\n\ninterplot(\n  m = taxrev_democracy_interaction,\n  var1 = \"wdi_taxrev\",   # independent variable of interest\n  var2 = \"bmr_dem\") +       # moderator (0 = non-democracy, 1 = democracy)) +\n  labs(x = \"Democracy (0 = Non-democracy, 1 = Democracy)\",\n       y = \"Marginal Effect of Tax Revenue on Trade\",\n       title = \"Marginal Effect of Tax Revenue on Trade by Regime Type\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis plot suggests that “wdi_taxrev” exerts a positive and statistically significant impact on “wdi_trade” for democracies, but not for non-democracies. However, although the marginal effect for democracies is statistically distinguishable from zero, the interaction term in the regression model is not statistically significant at the 95% level, indicating that we cannot conclude that the effect of tax revenue on trade is significantly different between democracies and non-democracies (this is reflected in the plot by the overlap of the regime-specific confidence intervals). In other words, while tax revenue appears to matter for trade in democracies, we cannot be confident that this difference across regime types is not due to random chance.\nWe’ve just gone through some techniques to interpret regression results that include an interaction between a continuous independent variable, and a dichotomous one. We can also use these techniques to make sense of regression results that include an interaction between two continuous independent variables. To illustrate, let’s consider another regression model, this time with “wdi_taxrev” and “undp_hdi” (the human development index), and an interaction between these variables, as the independent variables, and “wdi_trade” as the dependent variable. We’ll assign the regression results to an object named taxrev_hdi_interaction:\n\n# run regression with \"wdi_trade\" as DV, and interaction term between \n# \"wdi_taxrev\" and \"undp_hdi\" (two continuous variables) as IVs\ntaxrev_hdi_interaction&lt;-lm(wdi_trade~wdi_taxrev*undp_hdi, data=qog_copy_selection)\n\nLet’s print the regression results:\n\n# prints regression results\nsummary(taxrev_hdi_interaction)\n\n\nCall:\nlm(formula = wdi_trade ~ wdi_taxrev * undp_hdi, data = qog_copy_selection)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-89.430 -32.099  -9.118  17.897 262.709 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)         -30.35740   53.88275  -0.563   0.5741  \nwdi_taxrev            1.42787    3.25988   0.438   0.6621  \nundp_hdi            131.81632   74.14701   1.778   0.0778 .\nwdi_taxrev:undp_hdi   0.06938    4.28513   0.016   0.9871  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 54.21 on 131 degrees of freedom\n  (59 observations deleted due to missingness)\nMultiple R-squared:  0.1758,    Adjusted R-squared:  0.1569 \nF-statistic: 9.315 on 3 and 131 DF,  p-value: 1.258e-05\n\n\nWe can see that the regression results show an interaction term that is not significant at conventional thresholds, but we can further unpack this with some predicted values and",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Elementary Data Visualization and Analysis</span>"
    ]
  },
  {
    "objectID": "session4.html#exporting-analysis-objects",
    "href": "session4.html#exporting-analysis-objects",
    "title": "5  Elementary Data Visualization and Analysis",
    "section": "5.7 Exporting Analysis Objects",
    "text": "5.7 Exporting Analysis Objects",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Elementary Data Visualization and Analysis</span>"
    ]
  },
  {
    "objectID": "session5.html",
    "href": "session5.html",
    "title": "6  Tools for Reproducibility and Reporting",
    "section": "",
    "text": "6.1 Preliminaries\nPlease load the tidyverse. Below, we’ll also eventually install and load a library called here, but it is not necessary to do so at the outset.\n# load library\nlibrary(tidyverse)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Tools for Reproducibility and Reporting</span>"
    ]
  },
  {
    "objectID": "session5.html#introduction",
    "href": "session5.html#introduction",
    "title": "6  Tools for Reproducibility and Reporting",
    "section": "6.2 Introduction",
    "text": "6.2 Introduction\nIn this lesson, we’ll learn about some tools that can help you write reproducible R code and manage your projects, as well as communicate your results with others (whether collaborators, students, the broader scholarly community, or the public) in a transparent and compelling way. In particular, we will introduce R Studio’s Projects feature, which provides a useful container for the various components of an R project (i.e. raw data, analysis outputs and processed data, scripts etc) and helps keep these components organized and sharable. We will also introduce Quarto, an open-source publishing system that enables you to produce articles, websites, slides, books, and other documents. The Quarto ecosystem is too vast for us to explore in a comprehensive here, so our focus will be on using Quarto as a platform for literate programming, which refers to the practice of writing code as human readable scripts that integrate narrative text, code, and code outputs into cohesive and accessible documents.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Tools for Reproducibility and Reporting</span>"
    ]
  },
  {
    "objectID": "session5.html#r-projects",
    "href": "session5.html#r-projects",
    "title": "6  Tools for Reproducibility and Reporting",
    "section": "6.3 R Projects",
    "text": "6.3 R Projects\nAs you move forward in using R, the scope and complexity of your work will increase, which means that it will become increasingly important (and challenging) to systematically track the various components of your projects, and to share these projects with others. R Studio’s Project functionality can make these data and project management tasks more tractable and streamlined, which in turn facilitates the reproducibility of your work.\n\n6.3.1 What is an R Project?\nAn R Studio Project, quite simply, is a folder/directory in which you can store all of the materials associated with an R-based project, such as your raw data, your scripts, outputs (i.e. visualizations, processed data etc.), and reports. For each of these project components, you should create dedicated sub-directories within the main R Project directory; to make this more concrete, your R Project directory should look something like this:\n\n\n\n\n\n\n\n\nFigure 6.1: R Project Directory\n\n\n\n\n\nNote the .Rproj file within the directory. It is this file that defines a directory as an R Project directory that functions as a self-contained workspace for a given project. File paths within an R Project can be defined in relative terms with respect to this main project directory (i.e. the directory which has the .Rproj file), which is a point we’ll return to below.\n\n\n6.3.2 What are the benefits of using R Projects?\nOne of the primary benefits of an R Project is that it creates a standard working directory. When you create an R project, and subsequently use it as a container for your project files, R automatically sets the working directory to the root directory of the project, ensuring that relative paths work consistently and reliably regardless of where in the folder your scripts or files are located. In other words, this feature allows you to not worry about managing file directories; everything in the project file can be referenced in your script with respect to the root directory of the project (i.e. the project’s top-level directory that contains the .Rproj file).\nLet’s say, for example, that your project directory looks like the one above, in Figure 1. First, note the .Rproj file within the directory, which indicates that this directory (r-crash-course-class-example) is the root directory of this R Project. Let’s say, for the sake of argument, that you are storing your scripts in the scripts sub-directory, and your raw data in the raw_data sub-directory. Because the working directory is standardized to be the root directory of the project, a script in the scripts sub-directory can refer to data living in the raw_data sub-directory using a relative path that is defined with respect to the Project’s root directory. So, for example, assuming the raw_data folder contains another folder named cc-data (for “crash course data”), which in turn contains two more sub-directories (pt for “persson-tabellini” and wb for “world bank”), with the persson_tabellini_workshop.csv file residing in pt, we could read in the Persson-Tabellini data with read_csv(\"raw_data/cc-data/pt/persson_tabellini_workshop.csv\"). If we weren’t working within an R Project environment, this would not be possible, since the persson_tabellini_workshop.csv file is not within the scripts sub-directory.\nThe standardization of the working directory makes project management more convenient, and also enables sharing. For example, if you needed to share your work with a collaborator, you could zip up the R Project directory and send it to them. When they run your scripts, everything should work as they did on your own computer even though their directory structure is different, since all the file paths are defined in relative terms with respect to the root of the project directory. In addition, GitHub recognizes .RProj files, which allows you to push an R project directory and its components to GitHub. When a collaborator clones the repository to their local machine, they will be able to run your scripts (since the working directory is the Project’s root directory, and all file paths are defined in relation to it), add to your scripts, and push the changes back up to GitHub. When you update your local repository, everything should continue to work seamlessly.\nSecond, each R Project is self-contained, which means that variables and objects in one project do not interfere with another. In addition, you can have multiple RStudio windows open for different projects, and they won’t share variables or loaded packages, which is helpful if you’re working on multiple research projects at a time.\nThird, each Project can have its own set of package versions, which prevents conflicts between projects that require different package versions. More generally, R Projects allow for a lot of customization that defines R’s behavior for that specific project, without generalizing to other projects and R-related files.\nFinally, working within a project allows for more effective and organized file management. Instead of dispersing relevant files and directories across your computer, which makes it difficult to keep track of everything, a project allows us to create sub-directories for scripts, data, results, and documents and reports that are centrally located and easy to find.\nIn short, R Projects offer meaningful benefits in the realm of project and data management, and facilitate sharing, collaboration, and reproducibility.\n\n\n6.3.3 How do you initiate an R Project?\nTo start an R Project, first go to File and click New Project:\n\n\n\n\n\n\n\n\nFigure 6.2: Start a Project\n\n\n\n\n\nThen select the option to start a project in a new working directory:\n\n\n\n\n\n\n\n\nFigure 6.3: Create Project in New Directory\n\n\n\n\n\nAfter that, select the New Project option:\n\nYou will then specify the location of the new R Project on your computer’s directory:\n\n\n\n\n\n\n\n\nFigure 6.4: Specify directory location\n\n\n\n\n\nAt this point, your project will be created (to confirm this, go to your project directory and confirm the existence of the .RProj file). You should configure your project directory something like in Figure 6.1 , with sub-directories for your raw or unprocessed data, scripts, R outputs (like processed data and visualizations), and reports and documents. This will help you keep track of a project’s many moving parts, and stay organized.\nOnce the project is set up, you can open your project by double-clicking the .RProj files, within R Studio or from your project directory; this will launch R Studio with the correct settings and working directory.\nOnce a project is created, you can also set the project options by going to Tools in the R Studio menu bar, and then clicking Project Options:\n\n\n\n\n\n\n\n\nFigure 6.5: Project Options\n\n\n\n\n\nThis will bring you to a menu interface that looks like the following:\n\n\n\n\n\n\n\n\nFigure 6.6: Project Options Menu\n\n\n\n\n\nYou can explore the various options, but it’s generally recommended to set all of the workspace options to “No”, especially if you are working on a research project that will ultimately be shared and published. .RData is a binary file that R uses to save your workspace (which includes all of the R objects you create) across multiple sessions. Hadley Wickham, a leading R developer (particularly on the tidyverse suite we’ve been using extensively the past few days), recommends avoiding .RData, and saving all of your work in reproducible scripts that can precisely regenerate all of your work. Using scripts, rather than .RData, to keep track of your objects and work (and regenerate them as necessary) will make your work more reproducible, since it reduces the likelihood that you unknowingly carry over old objects into new work and create hidden dependencies in your code ( by relying on objects from a previous session that were not explicitly created in your current script). In addition, carrying over the workspace session to session may end up leading to a cluttered environment, with a lot of superfluous objects you can’t keep track of. In short, you will generally be best-served by relying on well-documented scripts, rather than .RData to track your work and restore your environment after closing a session; using .RData to save your workspace could be more convenient in the short run, but will likely be more painful in the long run.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Tools for Reproducibility and Reporting</span>"
    ]
  },
  {
    "objectID": "session5.html#making-a-new-quarto-document",
    "href": "session5.html#making-a-new-quarto-document",
    "title": "6  Tools for Reproducibility and Reporting",
    "section": "7.1 Making a New Quarto Document",
    "text": "7.1 Making a New Quarto Document\nTo start a new Quarto Document, open up R Studio, then click New File, then select Quarto Document:\n\n\n\n\n\n\n\n\nFigure 7.1: Create New Quarto Document\n\n\n\n\n\nOnce you do so, it will bring up a menu like the one below; go ahead and give your document a name, and list your name as the author, then click OK:\n\n\n\n\n\n\n\n\nFigure 7.2: Create New Quarto Document\n\n\n\n\n\nOnce you click OK, a new Quarto document, with file extension “.qmd” will be created. It’ll look something like this:\n\n\n\n\n\n\n\n\nFigure 7.3: Create New Quarto Document\n\n\n\n\n\nThe document comes prepopulated with some text that can serve as a useful guide to some relevant syntax.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Tools for Reproducibility and Reporting</span>"
    ]
  },
  {
    "objectID": "session5.html#writing-the-document",
    "href": "session5.html#writing-the-document",
    "title": "6  Tools for Reproducibility and Reporting",
    "section": "7.2 Writing the Document",
    "text": "7.2 Writing the Document\nA Quarto document is comprised of three main elements. First, there is the YAML header, which contains metadata for the entire document, and allows us to define document settings and set rules for how the document will behave. Among many other things, we can use the YAML header to specify the desired output type (i.e. html, pdf, word), and define a table of contents. For example, see the YAML header associated for the first lesson plan we worked through on the first day of the workshop:\n\n\n\n\n\n\n\n\nFigure 7.4: Sample YAML Header\n\n\n\n\n\nNote that this is a pretty simple YAML header, and it is possible to customize a document in complex ways using the YAML header; however, this is beyond the scope of our lesson.\nSecond, there is document text, which is formatted in the Markdown language. Markdown is extremely simple, and if you are not familiar with it, can quickly get started by consulting this guide. You also have the option of formatting your text using the Quarto toolbar; from there, you can do all of the things you could also do with Markdown, such as add headers, add bullet points, format your text, add hyperlinks, and add images (among other things):\n\n\n\n\n\n\n\n\nFigure 7.5: Formatting Toolbar\n\n\n\n\n\nFinally, the third main components of a Quarto file are “code chunks”, where you can create blocks of code which generate outputs embedded in the document. You can also comment the code added within these blocks, just as you would comment code in a script. To create a code chunk you can go to to Code in the R Studio Menu bar up top, then click Insert Chunk. Another way, perhaps easier, is to click the green “C” button in the Quarto menu:\n\n\n\n\n\n\n\n\nFigure 7.6: Adding a Code Chunk\n\n\n\n\n\nThen, you can add code (and code comments) within the code chunk, and run it by clicking the green arrow:\n\n\n\n\n\n\n\n\nFigure 7.7: Running a Code Chunk\n\n\n\n\n\nAfter you click the “Run” button, the, code will run and the result will print immediately below:\n\n\n\n\n\n\n\n\nFigure 7.8: Output of Code Chunk\n\n\n\n\n\nThere are various ways to customize your code blocks and specify their behavior. For example, you can hide code blocks so that only the output is shown; you can also create code blocks that don’t execute, so that the final report shows the code block without the output; you can suppress code warnings; and so on. For more information on the relevant syntax needed to customize code chunks in these (and other) ways, see this guide to Quarto.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Tools for Reproducibility and Reporting</span>"
    ]
  },
  {
    "objectID": "session5.html#rendering-the-document",
    "href": "session5.html#rendering-the-document",
    "title": "6  Tools for Reproducibility and Reporting",
    "section": "7.3 Rendering the Document",
    "text": "7.3 Rendering the Document\nLet’s go ahead and modify the document; we’ll delete the pre-populated text, and add our own heading, as well as another code chunk. The document looks something like this:\n\n\n\n\n\n\n\n\nFigure 7.9: Updated File\n\n\n\n\n\nNow, let’s go ahead and save this .qmd file to the documents-reports directory within the R Project we created earlier. We can do so by clicking File, then Save As, then navigating to the directory and saving. We’ll save the file as “quarto-example.qmd”. Now that it’s saved in the desired directory, we can render the html file by clicking the Render button in the Quarto Menu:\n\n\n\n\n\n\n\n\nFigure 7.10: Render File\n\n\n\n\n\nThe rendered document should appear in either a separate window, or in your R Studio Viewer pane. You can choose where the document renders by clicking the small downward-pointing arrow next to the Render button, and clicking either Preview in Window or Preview in Viewer Pane:\n\n\n\n\n\n\n\n\nFigure 7.11: Render File\n\n\n\n\n\nIf you choose to preview in the viewer pane, it’ll look something like what you see below. Note the HTML preview on the right. This is a nice way of keeping track of what the rendered document looks like as you write your document within the .qmd file:\n\n\n\n\n\n\n\n\nFigure 7.12: Preview\n\n\n\n\n\nNote that after rendering, an html file will also be created in the same directory as your .qmd file, and will update each time you render the .qmd file by clicking the Render button.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Tools for Reproducibility and Reporting</span>"
    ]
  },
  {
    "objectID": "session5.html#r-projects-quarto-and-the-here-package",
    "href": "session5.html#r-projects-quarto-and-the-here-package",
    "title": "6  Tools for Reproducibility and Reporting",
    "section": "7.4 R Projects, Quarto, and the here() package",
    "text": "7.4 R Projects, Quarto, and the here() package\nR Projects and Quarto are two essential R tools that enable data management, sharing, and communication, both within the scholarly community and with the broader public. Though we’ve introduced these tools separately, it’s likely you’ll want to use them in conjunction (for instance, by placing your Quarto files and rendered documents within the reports-documents subdirectory of your R Project directory, as we did above).\nAs we discussed above, the R Project environment is a self-contained directory, where file paths can be set relative to the project’s root directory (i.e. the highest-level directory within the R project, which contains the .RProj file). When working with Quarto, the program automatically sets the root directory for the code that’s executed within the document to the same location as the .qmd file. When Quarto files are in an R Project, the working directory set by the location of the Quarto file overrides the working directory set by the R Project. For example, if the .qmd file is in the documents-reports directory (as it is here), it will set that as its root directory; as a result, it would be impossible to access the data (in the raw_data folder) from the Quarto document using a file path that is set relative to the Project’s root directory.\nTo make this more concrete, let’s first note the directory structure of the R Project root directory:\n\n\n\n\n\n\n\n\nFigure 7.13: The R Project Root Directory\n\n\n\n\n\nWIthin the raw-data sub-directory, there is another directory called cc-data, and within cc-data, there is a directory named pt, within which the persson_tabellini_workshop.csv data that we’ve been using resides. Thus, the path to the data from the Project’s root directory runs as follows:\nraw_data–&gt;cc-data–&gt;pt–&gt;persson_tabellini_workshop.csv\nWe can use this file path to read in the Persson-Tabellini data from a script stored in the scripts subdirectory. In particular, we could read the data in with the following:\n\nread_csv(\"raw_data/cc-data/pt/persson_tabellini_workshop.csv\")\n\nWithin our sample R script, it looks like this:\n\n\n\n\n\n\n\n\nFigure 7.14: Reading in data from a script in the script folder\n\n\n\n\n\nNow, let’s try to read the data in from within a .qmd file in the report-documents subdirectory:\n\n\n\n\n\n\n\n\nFigure 7.15: Error when running code chunk to set working directory in Quarto\n\n\n\n\n\nNote that trying to run the code chunk throws an error, since the code chunk is interpreting the location of the .qmd file (the report-documents directory) as the working directory. As a result, the file path doesn’t work; the code chunk is looking for the data in the reports-documents directory, but it doesn’t exist there. As expected, attempts to render the document fail for the same reason; when the rendering process hits the code chunk that tries to read in the data, it fails, and the rendering process terminates:\n\n\n\n\n\n\n\n\nFigure 7.16: Error when trying to render document as html\n\n\n\n\n\nThe easiest solution to this problem is to use the here() function from the here package, which automatically finds the root directory of the R Project you’re working in (remember that the root directory of your R project is the directory in which the .Rproj file is located) and builds paths from there. To see how it works, go ahead and install this package with the following:\n\ninstall.packages(\"here\")\n\nThen, load the here package at the top of your Quarto document by passing it to the library() function:\n\nlibrary(here)\n\nThen, whenever you need to read in data from your raw_data directory into a .qmd file in another (i.e. report-documents) directory, simply use the here() function within that code chunk to set the working directory as the Project’s root directory. After setting the working directory as the root directory, go ahead and read in your data as you would in a script (i.e. using a path defined relative to the root directory), and it should successfully read in. In short, the here() function overrides the default behavior within Quarto documents to set the working directory as the directory with the .qmd file, and forces these documents to follow the default behavior of R Project files and use the root directory of the R Project as the working directory that can be used to define relative file paths. Let’s see how it works; first, we’ll read in the data using a file path relative to the root directory by first using the here() function to set the working directory as the Project’s root directory:\n\nsetwd(here::here())\npt&lt;-read_csv(\"raw_data/cc-data/pt/persson_tabellini_workshop.csv\")\n\nNow, when you run the code chunk, it should successfully execute:\n\n\n\n\n\n\n\n\nFigure 7.17: Code chunk works when using here() to set working directory\n\n\n\n\n\nAfter this, the file will also successfully render:\n\n\n\n\n\n\n\n\nFigure 7.18: Rendering works when using here() to set working directory within code chunk\n\n\n\n\n\nSo, to summarize:\n\nIn an R Project, the working directory is automatically set to be the root of the R Project directory, and files can be read into the R environment in scripts that use file paths that are defined relative to the root directory\nHowever, when working in Quarto documents, Quarto defaults to setting the working directory as the directory in which the .qmd file exists, which overrides the behavior of an R Project (which defaults to setting the working directory as the Project’s root directory). As a result, while one could read in data from the raw_data folder into a script in the scripts folder using a relative path defined with respect to the Project’s root directory, it would not be possible to read in data from the raw_data folder into a Quarto document in the reports-documents using a relative path defined with respect to the Project’s root directory.\nIn order to force Quarto to use the root directory of the R Project as the working directory, we can use the here() function. By using the here() function to set the working directory as the Project’s root directory (within a code block right before reading in data), we can read in the data using a file path that is defined with respect to the root of the R Project directory, rather one that is defined with respect to the directory in which the .qmd file is located.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Tools for Reproducibility and Reporting</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "7  Conclusion and Future Reading",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Conclusion and Future Reading</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  }
]